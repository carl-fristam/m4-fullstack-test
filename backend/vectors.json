[{"id": "694f10bc2ef7fd944bcee9dc", "user_id": "CarlFristam", "title": "Privacy-Aware Graph Embeddings for Anti-Money ...", "text": "9 PagesPosted: 27 Jun 2025\n\nDate Written: June 05, 2025\n\n### Abstract\n\nThis article introduces a novel approach to anti-money laundering (AML) that combines graph neural networks (GNNs) with homomorphic encryption (HE) to detect suspicious financial patterns while preserving personally identifiable information (PII). Current AML systems face significant challenges in cross-border financial networks due to privacy regulations and data protection concerns. The proposed architecture enables financial institutions to analyze encrypted transaction graphs using privacy-preserving GNN inference, generating intermediate embeddings that retain predictive value without exposing raw identities. By performing computations directly on encrypted data, the system prevents the disclosure of sensitive customer information while maintaining detection capabilities. Experimental results demonstrate complete elimination of PII exposure incidents while substantially improving detection precision compared to baseline methods. Additionally, the system achieves notable reductions in false positive alerts, decreasing the manual review burden for financial institutions. This work addresses a critical gap in existing AML pipelines by supporting encrypted, privacy-safe graph analytics at scale and presents a three-phase implementation roadmap for integration with international banking systems.\n\n**Keywords:** Homomorphic Encryption, Graph Neural Networks, Privacy-Preserving Machine Learning, Anti-Money Laundering, Cross-Border Collaboration\n\n**Suggested Citation:** [Suggested Citation](http://papers.ssrn.com/papers.ssrn.com)\n\n## Do you have a job opening that you would like to promote on SSRN?\n\n## Paper statistics", "embedding": [-0.08838976174592972, 0.02741623856127262, -0.03959038481116295, 0.019723165780305862, 0.004756160546094179, 0.0006410721689462662, 0.04522085562348366, -0.047583721578121185, 0.039605122059583664, -0.05901418626308441, -0.0046385591849684715, -0.025218991562724113, 0.03853019326925278, 0.005798424128443003, -0.06571641564369202, -0.03197448328137398, 0.04012342914938927, 0.05886783078312874, -0.08305571973323822, -0.030684148892760277, -0.01365911215543747, -0.05464838445186615, -0.016305973753333092, 0.011954344809055328, 0.026102177798748016, -0.023369451984763145, 0.027361154556274414, 0.002482350217178464, -0.03452128916978836, -0.0014096650993451476, 0.11724872142076492, 0.019922709092497826, -0.0027059621643275023, 0.059338267892599106, -0.03458681330084801, -0.06294553726911545, 0.0501253679394722, 0.0018190016271546483, 0.06803621351718903, -0.05150340124964714, 0.03822140768170357, -0.10736306756734848, -0.017344331368803978, 0.03967101499438286, 0.07544825971126556, 0.012846780009567738, 0.002919957274571061, 0.05262848362326622, -0.029171256348490715, 0.02746654488146305, -0.06342688947916031, -0.034948110580444336, -0.011283956468105316, 0.04474633187055588, -0.049220971763134, -0.04332274943590164, 0.02620702050626278, -0.02014695107936859, -0.025911446660757065, 0.0117680998519063, -0.013530255295336246, 0.0014325722586363554, 0.061239100992679596, 0.007643038872629404, -0.05491550639271736, 0.07398723810911179, -0.0285849180072546, 0.06829630583524704, 0.018999557942152023, 0.03075380064547062, 0.09158217161893845, -0.0046926080249249935, -0.12680357694625854, -0.0215914249420166, -0.024037886410951614, 0.08841156214475632, -0.001877428381703794, 0.02622169256210327, -0.031121497973799706, -0.03259604796767235, 0.002698207041248679, -0.06329523026943207, 0.04476074129343033, -0.012899927794933319, 0.05153649300336838, 0.013063219375908375, -0.04014909639954567, 0.020904378965497017, -0.025247624143958092, 0.018924064934253693, -0.030850399285554886, 0.04840996116399765, 0.07576480507850647, -0.043754320591688156, 0.0727008730173111, -0.034811146557331085, -0.011272137984633446, -0.00828566774725914, -0.014172585681080818, 0.058766406029462814, -0.037935059517621994, 0.04024910181760788, 0.039454709738492966, -0.015616053715348244, 0.031578823924064636, 0.06918362528085709, 0.06869963556528091, 0.038240160793066025, 0.023621493950486183, -0.058417417109012604, -0.020101813599467278, 0.058576952666044235, 0.028143519535660744, -0.03823152557015419, 0.027149640023708344, 0.013469751924276352, -0.07733424752950668, 0.048758186399936676, 0.027466241270303726, 0.12766793370246887, -0.0038825289811939, 0.09089187532663345, -0.03414427489042282, 0.014709044247865677, -0.051093731075525284, 0.0019490942358970642, -0.15781338512897491, 2.7504898239921375e-33, -0.042770374566316605, 0.035921987146139145, 0.0012504340847954154, -0.05126454681158066, -0.02224227413535118, 0.07248212397098541, -0.09002697467803955, 0.008373299613595009, -0.02502274513244629, 0.06614785641431808, -0.07458855956792831, 0.04257848486304283, -0.014835122972726822, 0.0499262697994709, -0.004997848067432642, 0.029687512665987015, 0.06040399149060249, -0.020394304767251015, 0.06984644383192062, -0.0731421634554863, 0.10521714389324188, -0.08933580666780472, 0.05899769067764282, 0.0106999846175313, 0.06995071470737457, 0.009298228658735752, 0.01666986756026745, -0.02491975575685501, 0.11707786470651627, 0.019761761650443077, -0.03626309707760811, 0.04304898902773857, 0.1273653358221054, 0.06099984794855118, 0.08582986146211624, -0.023520587012171745, -0.04234704002737999, -0.04351305961608887, 0.03137097880244255, -0.017893901094794273, -0.03973490372300148, 0.002551282523199916, 0.02260187454521656, -0.017324090003967285, -0.0513901524245739, 0.10441645979881287, -0.03392193093895912, 0.026798725128173828, 0.01605980284512043, -0.05484775826334953, 0.01946238800883293, 0.020416049286723137, -0.07681932300329208, -0.012110421434044838, -0.04880364611744881, -0.07969304919242859, 0.042718369513750076, 0.026164554059505463, -0.011885077692568302, -0.014410752803087234, -0.04811834543943405, 0.014622033573687077, -0.061023883521556854, 0.005722544156014919, -0.0907428041100502, 0.03082955814898014, -0.017553230747580528, 0.05395601689815521, 0.002631117356941104, 0.004418797791004181, -0.013921489007771015, 0.11571747809648514, 0.04294027015566826, 0.05182243138551712, -0.017503496259450912, -0.029380984604358673, 0.01000459585338831, 0.0072438716888427734, 0.005025669001042843, 0.012652352452278137, -0.001729211420752108, -0.005797642283141613, 0.052082452923059464, 0.05274023860692978, -0.07358580827713013, 0.0172079149633646, 0.0694134384393692, 0.021900314837694168, 0.030477453023195267, -0.012575619854032993, -0.01914229802787304, -0.07281926274299622, 0.011410834267735481, 0.03104088269174099, -0.013238978572189808, -3.287036689914286e-33, -0.06511899828910828, 0.04326251149177551, -0.02545878291130066, 0.01088623981922865, -0.056094031780958176, -0.0008658198639750481, 0.038685791194438934, -0.01575607806444168, 0.04095986485481262, 0.041570570319890976, -0.03906932473182678, -0.08072667568922043, 0.09295610338449478, -0.03883834555745125, 0.06166771054267883, -0.0030551389791071415, -0.022867605090141296, 0.014795846305787563, -0.0443689227104187, -0.01453821174800396, -0.023448677733540535, 0.02638924866914749, -0.04630906507372856, 0.05395263060927391, 0.05817963182926178, 0.015727097168564796, -0.0361042357981205, -0.026671383529901505, 0.04554133489727974, 0.03139859437942505, -0.09709037840366364, -0.009896256029605865, -0.0026219948194921017, -0.08075030148029327, -0.05539683252573013, -0.044076692312955856, 0.09974068403244019, -0.0051168762147426605, 0.006743129808455706, -0.0773308053612709, 0.008327530696988106, 0.017873626202344894, -0.13779839873313904, -0.01856241747736931, -0.042942531406879425, 0.041906241327524185, -0.028614556416869164, 0.08298632502555847, -0.01242789439857006, -0.057925328612327576, -0.05630294606089592, 0.017690123990178108, 0.018293019384145737, -0.0278667863458395, 0.0049117691814899445, -0.009456117637455463, 0.04624205082654953, 0.018462399020791054, -0.004084933549165726, -0.014560658484697342, -0.04936523362994194, 0.00703907897695899, 0.04067033529281616, 0.022259507328271866, 0.005573160946369171, -0.022158542647957802, -0.01041564904153347, 0.02609574981033802, 0.00267193466424942, -0.035598043352365494, 0.04120371490716934, -0.09039144217967987, -0.06957501173019409, 0.022739483043551445, 0.034935444593429565, -0.01543729193508625, -0.02829616703093052, -0.05724971741437912, -0.040180008858442307, 0.053914494812488556, 0.08732984960079193, -0.08557403832674026, 0.019691843539476395, 0.03778599947690964, 0.1304401159286499, -0.060575682669878006, 0.03480537235736847, -0.03290843218564987, 0.06805543601512909, 0.06609728932380676, -0.050700608640909195, 0.02862989529967308, -0.1441826969385147, 0.06049981713294983, -0.01296996884047985, -3.994681563312952e-08, -0.06376907974481583, -0.00015328435983974487, 0.016349302604794502, 0.033056531101465225, 0.039447564631700516, -0.01851695403456688, 0.0644674077630043, 0.032947197556495667, -0.06596440076828003, -0.007480308413505554, 0.06282725930213928, -0.08923433721065521, -0.09499915689229965, -0.10254322737455368, -0.04440414533019066, -0.02334485575556755, -0.004394426941871643, -0.07732659578323364, 0.06069106608629227, 0.021901041269302368, -0.05863916501402855, 0.0017634737305343151, -0.02486240677535534, -0.00498337484896183, 0.002265342976897955, -0.17591089010238647, -0.039252869784832, 0.08840778470039368, 0.03882765397429466, 0.05158419534564018, -0.07361266016960144, -0.07951176166534424, 0.08588168770074844, -0.030891193076968193, -0.05010237544775009, 0.12997008860111237, 0.052549201995134354, 0.008877571672201157, -0.01919679157435894, 0.024478953331708908, 0.02351669780910015, 0.032613735646009445, -0.0031983223743736744, -0.03170718252658844, -0.007878612726926804, -0.09494062513113022, 0.029699144884943962, -0.0644981637597084, 0.10364019125699997, -0.053696151822805405, 0.008053561672568321, -0.055444229394197464, 0.0679003894329071, 0.07556582242250443, 0.04800274595618248, 0.015570316463708878, -0.02438541315495968, -0.03379262983798981, 0.030484817922115326, 0.06796057522296906, 0.0756961926817894, -0.10367214679718018, -0.021933162584900856, -0.06735894829034805]}, {"id": "694f10e72ef7fd944bcee9df", "user_id": "CarlFristam", "title": "Self-Supervised Graph Representation Learning for Anti ...", "text": "# Computer Science > Machine Learning\n\n**arXiv:2210.14360** (cs)\n\n\\[Submitted on 25 Oct 2022\\]\n\n# Title:LaundroGraph: Self-Supervised Graph Representation Learning for Anti-Money Laundering\n\nAuthors: [M\u00e1rio Cardoso](https://arxiv.org/search/cs?searchtype=author&query=Cardoso,+M), [Pedro Saleiro](https://arxiv.org/search/cs?searchtype=author&query=Saleiro,+P), [Pedro Bizarro](https://arxiv.org/search/cs?searchtype=author&query=Bizarro,+P)\n\nView a PDF of the paper titled LaundroGraph: Self-Supervised Graph Representation Learning for Anti-Money Laundering, by M\\\\'ario Cardoso and 2 other authors\n\n[View PDF](https://arxiv.org/pdf/2210.14360)\n\n> Abstract:Anti-money laundering (AML) regulations mandate financial institutions to deploy AML systems based on a set of rules that, when triggered, form the basis of a suspicious alert to be assessed by human analysts. Reviewing these cases is a cumbersome and complex task that requires analysts to navigate a large network of financial interactions to validate suspicious movements. Furthermore, these systems have very high false positive rates (estimated to be over 95\\\\%). The scarcity of labels hinders the use of alternative systems based on supervised learning, reducing their applicability in real-world applications.\n>\n> In this work we present LaundroGraph, a novel self-supervised graph representation learning approach to encode banking customers and financial transactions into meaningful representations. These representations are used to provide insights to assist the AML reviewing process, such as identifying anomalous movements for a given customer. LaundroGraph represents the underlying network of financial interactions as a customer-transaction bipartite graph and trains a graph neural network on a fully self-supervised link prediction task. We empirically demonstrate that our approach outperforms other strong baselines on self-supervised link prediction using a real-world dataset, improving the best non-graph baseline by $12$ p.p. of AUC. The goal is to increase the efficiency of the reviewing process by supplying these AI-powered insights to the analysts upon review. To the best of our knowledge, this is the first fully self-supervised system within the context of AML detection.\n\n| | |\n| --- | --- |\n| Comments: | Accepted at ACM International Conference on AI in Finance 2022 (ICAIF'22) |\n| Subjects: | Machine Learning (cs.LG); Artificial Intelligence (cs.AI) |\n| Cite as: | [arXiv:2210.14360](https://arxiv.org/abs/2210.14360) \\[cs.LG\\] |\n| | (or [arXiv:2210.14360v1](https://arxiv.org/abs/2210.14360v1) \\[cs.LG\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2210.14360](https://doi.org/10.48550/arXiv.2210.14360) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Pedro Saleiro \\[ [view email](https://arxiv.org/show-email/017a37e7/2210.14360)\\]\n\n**\\[v1\\]**\nTue, 25 Oct 2022 21:58:02 UTC (504 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled LaundroGraph: Self-Supervised Graph Representation Learning for Anti-Money Laundering, by M\\\\'ario Cardoso and 2 other authors\n\n- [View PDF](https://arxiv.org/pdf/2210.14360)\n- [TeX Source](https://arxiv.org/src/2210.14360)\n- [Other Formats](https://arxiv.org/format/2210.14360)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2210.14360&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2210.14360&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2022-10](https://arxiv.org/list/cs.LG/2022-10)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2210.14360?context=cs)\n\n[cs.AI](https://arxiv.org/abs/2210.14360?context=cs.AI)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2210.14360)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2210.14360)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2210.14360)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2210.14360&description=LaundroGraph: Self-Supervised Graph Representation Learning for Anti-Money Laundering) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2210.14360&title=LaundroGraph: Self-Supervised Graph Representation Learning for Anti-Money Laundering)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2210.14360) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))", "embedding": [-0.0385102853178978, 0.022494958713650703, -0.0671054869890213, -0.0008046451839618385, 0.04759388417005539, 0.010420412756502628, 0.03649676963686943, 0.0015148129314184189, 0.008682524785399437, -0.006843137089163065, -0.018973644822835922, 0.024781158193945885, 0.05194713920354843, 0.040390871465206146, -0.032426975667476654, 0.05703718960285187, 0.05411478504538536, 0.0038171743508428335, -0.06332913041114807, -0.012517500668764114, 0.04316609725356102, -0.058436982333660126, -0.012112332507967949, -0.01690320484340191, -0.007047649472951889, -0.03724057599902153, -0.010539430193603039, 0.02101837657392025, 0.014170898124575615, -0.03817106410861015, 0.049973003566265106, 0.07534164935350418, 0.052733298391103745, 0.044760607182979584, -0.01484037097543478, -0.027247676625847816, 0.007487540598958731, 0.05485762283205986, 0.029054073616862297, 0.020367396995425224, 0.016514256596565247, -0.010682743974030018, -0.004291750956326723, -0.003472384996712208, 0.06904269009828568, -0.006517438217997551, -0.04162454232573509, 0.0506097637116909, -0.05006260424852371, 0.03030094876885414, -0.1472041755914688, 0.003255461808294058, -0.04804792255163193, 0.012293258681893349, -0.04210643470287323, -0.056736595928668976, 0.02346886321902275, -0.04951265826821327, -0.02476736158132553, -0.031709279865026474, 0.08371608704328537, -0.0040739914402365685, -0.02928532287478447, 0.00711438013240695, 0.01962989568710327, 0.05409930273890495, -0.014037253335118294, 0.07597023993730545, -0.02909962460398674, 0.0126891965046525, 0.0423620343208313, -0.053299352526664734, -0.12388187646865845, -0.0011357686016708612, 0.053458038717508316, 0.05262808874249458, 0.04011627659201622, 0.030551349744200706, 0.018639903515577316, -0.11448044329881668, -0.011908837594091892, 0.011434586718678474, 0.008379333652555943, -0.05212578549981117, 0.026104075834155083, -0.04191499575972557, -0.06101866066455841, -0.02133394218981266, 0.11791529506444931, 0.01310906931757927, -0.00811901967972517, 0.030430035665631294, 0.04240690544247627, -0.08262762427330017, 0.037903450429439545, -0.007586642634123564, 0.05336427316069603, -0.01845654658973217, 0.022343091666698456, 0.05938391387462616, 0.010736369527876377, -0.023822953924536705, -0.02698434144258499, -0.010638289153575897, 0.01865171082317829, -0.005903821904212236, 0.04742266982793808, 0.10518625378608704, 0.017098015174269676, -0.09366471320390701, -0.009490251541137695, 0.04307673126459122, -0.028990749269723892, -0.0674847885966301, 0.007886185310781002, 0.01460852101445198, -0.01853984035551548, -0.00028689074679277837, 0.02370738796889782, 0.038167014718055725, -0.03739332780241966, 0.014626199379563332, -0.05504883453249931, -0.009974343702197075, -0.0010856966255232692, -0.014308574609458447, -0.1603228598833084, 3.950923940506051e-33, -0.040275923907756805, 0.06757309287786484, -0.005404939409345388, -0.04450034722685814, -0.029981723055243492, 0.03288557752966881, -0.038251593708992004, -0.04383532702922821, -0.02819371595978737, 0.07040558010339737, -0.08446556329727173, 0.06052432581782341, 0.007223956286907196, 0.05065472424030304, -0.00737938703969121, -0.023529252037405968, -0.01559751108288765, -0.01737855188548565, 0.03120892494916916, -0.09201158583164215, 0.08627281337976456, -0.00764814019203186, 0.0004990855813957751, -0.028615741059184074, 0.06283991783857346, 0.03790228068828583, -0.03705969825387001, -0.03854791074991226, 0.085720494389534, 0.048078589141368866, -0.013201551511883736, 0.07915176451206207, 0.05190809443593025, 0.07872908562421799, 0.01629994809627533, -0.002102550119161606, -0.13945281505584717, -0.017758207395672798, 0.024766510352492332, -0.08363355696201324, -0.0685507282614708, 0.026558278128504753, 0.06661228090524673, -0.05693279206752777, -0.08780615031719208, 0.029493562877178192, -0.06571916490793228, 0.010685179382562637, -0.0002102917933370918, -0.05611567944288254, -0.01761644333600998, 0.003905410412698984, -0.05378545820713043, -0.05245446041226387, -0.007092354819178581, -0.0017664050683379173, -0.02295553870499134, 0.09452077746391296, -0.020203761756420135, 0.02740652672946453, 0.05057091265916824, 0.0076016527600586414, -0.05522720888257027, 0.08958356082439423, -0.0545741505920887, 0.0030504947062581778, 0.007166921626776457, 0.025643542408943176, 0.10182151943445206, -0.06460684537887573, -0.008476760238409042, 0.12606631219387054, 0.03566541150212288, -0.013428299687802792, 0.003056043991819024, -0.0637105256319046, 0.08363673090934753, 0.04070468991994858, -0.04521729797124863, -0.003920921590179205, -0.08019398152828217, -0.011276337318122387, 0.05786190927028656, -0.0034175284672528505, -0.04491833597421646, -0.03633033111691475, 0.07778678834438324, -0.06651240587234497, -4.6261873649200425e-05, 0.0013053356669843197, 0.02858491614460945, -0.036998044699430466, -0.03120322711765766, 0.12358659505844116, -0.008249273523688316, -4.5763299141557096e-33, -0.046339984983205795, 0.05962871387600899, 0.06311933696269989, -0.028365831822156906, -0.01577870361506939, 0.002240317640826106, 0.010390865616500378, -0.026817962527275085, 0.019478831440210342, 0.0140965785831213, -0.038751933723688126, -0.09689590334892273, 0.04273900017142296, -0.015916917473077774, -0.020276619121432304, -0.04034655913710594, 0.023245520889759064, -0.025600265711545944, -0.06453097611665726, 0.004178149625658989, -0.03391813486814499, 0.12735064327716827, -0.05087227746844292, 0.05997544899582863, 0.016573533415794373, 0.01029019895941019, -0.037086840718984604, -0.011757565662264824, -0.018782304599881172, 0.11485345661640167, -0.06094447150826454, 0.0036700707860291004, -0.06487751752138138, -0.02449558861553669, -0.0897141769528389, -0.012784576043486595, 0.0024949321523308754, -0.021744562312960625, -0.0103467907756567, 0.014111279509961605, -0.002907670335844159, 0.059398964047431946, -0.1310710310935974, -0.05116982385516167, -0.045259833335876465, -0.01578429900109768, -0.03104814700782299, 0.03554704785346985, 0.06694172322750092, -0.08405496925115585, -0.05508800968527794, -0.006127615924924612, 0.02721794694662094, -0.0016599090304225683, -0.07651860266923904, 0.028811709955334663, 0.08618790656328201, 0.010514641180634499, 0.006291851866990328, 0.004676452372223139, -0.0997772142291069, 0.029428761452436447, 0.04674633592367172, 0.011788450181484222, 0.03964605927467346, -0.07694162428379059, -0.037041328847408295, 0.007472688797861338, 0.045834749937057495, -0.04341577738523483, 0.0596349872648716, -0.001506621134467423, -0.018311982974410057, 0.041405413299798965, 0.055506061762571335, -0.041946906596422195, -0.02307332120835781, -0.00482485955581069, -0.07164669036865234, -0.0157620906829834, -0.00047465559327974916, -0.024153919890522957, 0.036370355635881424, 0.13978756964206696, 0.03306014835834503, -0.00792737677693367, 0.005471286363899708, 0.001363418297842145, 0.0665343850851059, 0.016247352585196495, 0.01771063171327114, -0.03326556831598282, -0.05486277490854263, 0.06493858247995377, -0.03891503065824509, -4.7959584748014095e-08, -0.13463492691516876, -0.0522538423538208, 0.0068703023716807365, 0.013654541224241257, 0.04930367320775986, 0.04174545034766197, 0.029227839782834053, 0.06782912462949753, -0.06171693280339241, 0.07103899866342545, 0.09367576241493225, 0.019179653376340866, -0.07720520347356796, -0.07110585272312164, -0.09603533148765564, -0.04240400344133377, 0.008967307396233082, 0.009174534119665623, -0.011542631313204765, 0.027638869360089302, 0.007686043623834848, -0.029647378250956535, -0.01098403986543417, -0.014257850125432014, 0.05396280810236931, -0.1491602510213852, -0.06923606991767883, 0.0016878393944352865, 0.056797854602336884, 0.08632072061300278, -0.10491112619638443, 0.06564326584339142, 0.07497937977313995, -0.010296406224370003, 0.02101208083331585, 0.09579306095838547, 0.05108758434653282, -0.007192751858383417, -0.09736093133687973, 0.06943279504776001, 0.043877921998500824, 0.10540197789669037, -0.038725316524505615, -0.007566096726804972, 0.10191753506660461, -0.037192460149526596, -0.04999566450715065, -0.024974294006824493, 0.0773957222700119, -0.07266942411661148, 0.07309585809707642, -0.07680666446685791, 0.05529846251010895, 0.012116828933358192, 0.07211215794086456, -0.024645449593663216, -0.025576235726475716, 0.04645194485783577, 0.060272183269262314, 0.06721201539039612, 0.06079452857375145, -0.023837970569729805, 0.04340154677629471, -0.03335472568869591]}, {"id": "694f11272ef7fd944bcee9e2", "user_id": "CarlFristam", "title": "(PDF) Enhancing Anti-Money Laundering Systems Using ...", "text": "In today's increasingly complex financial landscape, traditional anti-money laundering (AML) systems are often inadequate in combating sophisticated financial crimes. This research aims to bridge that gap by integrating knowledge graphs with graph neural networks (GNNs) to enhance AML detection capabilities. The study leverages financial transactional data to construct a knowledge graph, employing GNN architectures, particularly Graph Attention Networks (GAT), to predict and detect potential money laundering activities. Empirical results demonstrate that GNNs are highly effective at uncovering intricate transaction patterns that conventional methods frequently miss. However, the GAT model encounters issues with generalization and overfitting, especially on larger test datasets. Sensitivity analyses highlight the critical influence of features such as transaction timestamps and payment formats on model performance. This research provides a data-driven, Artificial Intelligence (AI)-enhanced approach to advancing AML systems, offering practical insights for optimizing models and improving detection accuracy. Additionally, the findings present valuable recommendations for financial institutions and regulatory bodies, aiming to enhance compliance and fortify the security of financial markets. Future research will focus on further optimizing these models to address existing challenges and improve generalization.\n\nContent may be subject to copyright.\n\n**Discover the world's research**\n\n- 25+ million members\n- 160+ million publication pages\n- 2.3+ billion citations\n\n[Join for free](https://www.researchgate.net/publication/signup.SignUp.html)\n\nEnhancing Anti-Money Laundering Systems Using\n\nKnowledge Graphs and Graph Neural Networks\n\nQilong Yu1,a,\\*\n\n1Department of economics, University College London, London, UK\n\na. uctpqyu@ucl.ac.uk\n\n\\*corresponding author\n\nAbstract:In today's increasingly complex financial landscape, traditional anti-money\n\nlaundering (AML) systems are often inadequate in combating sophisticated financial crimes.\n\nThis research aims to bridge that gap by integrating knowledge graphs with graph neural\n\nnetworks (GNNs) to enhance AML detection capabilities. The study leverages financial\n\ntransactional data to construct a knowledge graph, employing GNN architectures, particularly\n\nGraph Attention Networks (GAT), to predict and detect potential money laundering activities.\n\nEmpirical results demonstrate that GNNs are highly effective at uncovering intricate\n\ntransaction patterns that conventional methods frequently miss. However, the GAT model\n\nencounters issues with generalization and overfitting, especially on larger test datasets.\n\nSensitivity analyses highlight the critical influence of features such as transaction timestamps\n\nand payment formats on model performance. This research provides a data-driven, Artificial\n\nIntelligence (AI)-enhanced approach to advancing AML systems, offering practical insights\n\nfor optimizing models and improving detection accuracy. Additionally, the findings present\n\nvaluable recommendations for financial institutions and regulatory bodies, aiming to enhance\n\ncompliance and fortify the security of financial markets. Future research will focus on further\n\noptimizing these models to address existing challenges and improve generalization.\n\nKeywords:Anti-Money Laundering (AML), Graph Neural Networks (GNN), Knowledge\n\nGraph.\n\n1.Introduction\n\nData has become a crucial driver in modern finance, advancing quantitative finance and improving\n\ndecision-making. However, technological advancements have also facilitated more sophisticated\n\nfinancial crimes, such as money laundering. To address these threats, financial institutions must adopt\n\nadvanced risk monitoring tools. Regulatory measures like the Patriot Act in the U.S. and the anti-\n\nmoney laundering (AML) directive in Europe have imposed stricter compliance requirements,\n\nhighlighting the need for innovative AML strategies. Jack et al. \\[1\\] investigated graph neural\n\nnetworks (GNNs) and recurrent neural networks (RNNs) for analyzing transaction patterns to detect\n\nmoney laundering, while Akash et al. \\[2\\] compared various machine learning algorithms for fraud\n\ndetection. Yongshan et al. \\[3\\] proposed a method combining comparative learning with generative\n\nadversarial networks (GANs) for anomaly detection in multivariate time series. Despite AI's potential,\n\nchallenges such as model interpretability and reliance on labeled data remain.\n\nProceedings of the 3rd International Conference on Financial Technology and Business Analysis\n\nDOI: 10.54254/2754-1169/118/2024.18627\n\n\u00a9 2024 The Authors. This is an open access article distributed under the terms of the Creative Commons Attribution License 4.0\n\n(https://creativecommons.org/licenses/by/4.0/).\n\n280\n\nIn addition to traditional machine learning methods, GNN technology has increasingly been\n\napplied to the field of AML. Liyu & Qiang \\[4\\] explored how GNNs can capture complex\n\ndependencies between nodes in a graph and improve model accuracy through a message-passing\n\nmechanism that updates node features. Additionally, Simone & Stefano \\[5\\] applied various GNN\n\narchitectures, including Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs),\n\nChebyshev space Convolutional Neural Networks (ChebNet), and Graph Sample and Aggregated\n\n(GraphSAGE), to classify bitcoin transactions, demonstrating the effectiveness of GNNs in handling\n\ncomplex financial data. Moreover, Bin et al. \\[6\\] introduced multi-fraud, a heterogeneous learning\n\nframework that utilizes multi-view heterogeneous information GNNs for advanced fraud detection.\n\nThese studies indicate that integrating GNNs with knowledge graphs significantly enhances the\n\nintelligence and automation of AML systems.\n\nThis research aims to enhance AML systems by integrating knowledge graphs and GNNs. By\n\nmodeling financial transactions as knowledge graphs and applying GCNs and GATs, it identifies\n\nhidden money laundering patterns that traditional rule-based methods often miss. This approach\n\naddresses inefficiencies in existing systems and reduces compliance costs. Experimental results show\n\nthat combining GNNs with knowledge graphs significantly improves detection accuracy, especially\n\nwith GCNs. These findings offer financial institutions and regulators scalable tools to better detect\n\nsuspicious activities, streamline compliance, and strengthen financial market security.\n\n2.Methodology\n\n2.1.Dataset Description and Preprocessing\n\nThis research used a synthetic dataset provided by International Business Machines Corporation\n\n(IBM), which is designed to simulate financial transaction data while addressing privacy and\n\nproprietary concerns associated with real financial data \\[7\\]. The dataset comprises 1,243 detailed\n\ntransactions from various banks, starting from September 1, 2022. It includes information such as\n\ntransaction timestamps, involved accounts, banks of receipt and payment, transaction amounts,\n\ncurrencies, payment methods, and a label indicating whether a transaction is suspected of money\n\nlaundering. A description of the relevant variables is presented in Table 1. During the preprocessing\n\nphase, categorical variables such as payment method and currency type were encoded numerically,\n\nand timestamps were normalized. Account details were consolidated into unique identifiers to\n\nmaintain consistency.\n\nTable 1: Variable-related descriptions.\n\nProceedings of the 3rd International Conference on Financial Technology and Business Analysis\n\nDOI: 10.54254/2754-1169/118/2024.18627\n\n281\n\n2.2.Proposed Approach\n\nThis research aims to develop an efficient money laundering detection model by applying GNNs to a\n\nknowledge graph constructed from comprehensive financial transaction data. The process begins with\n\ndata preprocessing, which involves encoding categorical variables, normalizing timestamps, and\n\nmerging account details into unique identifiers (as illustrated in Figure 1). A knowledge graph is then\n\nconstructed, where nodes represent accounts and edges represent transactions, capturing complex\n\nrelationships and attributes such as transaction amounts, currencies, and payment methods. The model\n\nis based on GAT, chosen for its ability to learn node features through an attention mechanism. The\n\narchitecture consists of four graph attention layers with multiple heads to aggregate attention weights,\n\nfollowed by a fully connected layer for classification, using focus loss to handle class imbalance.\n\nPerformance is evaluated through standard metrics, and the structure of the knowledge graph is\n\nvisualized and analyzed. This study hypothesizes that GAT can effectively capture intricate\n\nrelationships within the data, leading to improved detection accuracy. While the model shows\n\npromising results during training, further optimization is needed to address overfitting and potential\n\ndata distribution discrepancies. Ultimately, this research seeks to provide a robust and scalable\n\nsolution that enhances the security and compliance capabilities of financial institutions.\n\nFigure 1: Research process.\n\n2.2.1.Knowledge Graph\n\nA Knowledge Graph is a structured semantic network that represents entities and their relationships\n\nthrough nodes and edges \\[8\\], adding semantic meaning to data for deeper insights and reasoning \\[9\\].\n\nKey features include semantic understanding, structured organization, scalability, and reasoning\n\ncapabilities, making Knowledge Graphs valuable for analyzing large, complex datasets in areas like\n\nrecommender systems and search engines (see in Figure 2). In this experiment, a knowledge graph is\n\nbuilt from financial transaction data, where nodes represent bank accounts, edges depict transactional\n\nrelationships, and attributes like transaction amounts and money laundering labels are included. The\n\nGAT model is used for classification, applying a four-layer attention mechanism and a fully\n\nconnected layer for final predictions. Focal loss is employed to handle class imbalance and improve\n\nperformance.\n\nProceedings of the 3rd International Conference on Financial Technology and Business Analysis\n\nDOI: 10.54254/2754-1169/118/2024.18627\n\n282\n\nFigure 2: Graph visualization.\n\n2.2.2.Graph Neural Networks (GNNs)\n\nGNNs are neural network models designed to process graph-structured data, capturing relationships\n\nbetween nodes and edges \\[10\\]. Unlike traditional networks, GNNs excel in learning node\n\nrepresentations by aggregating and updating information from neighboring nodes, making them\n\nhighly effective for tasks like classification and prediction. They capture both local and global\n\ninformation, handle irregular data structures, and adapt to graph topology \\[11\\], making them useful\n\nin fields like social network analysis and bioinformatics. Among GNN variants, GAT enhances\n\nflexibility by incorporating an attention mechanism that assigns different weights to nodes, improving\n\nperformance on heterogeneous graphs. In this experiment, a four-layer GAT model is trained on\n\nfinancial transaction data, with focal loss applied to address class imbalance. The model's\n\nperformance is evaluated using accuracy, precision, recall, and F1 score, with ongoing optimization\n\nto improve generalization.\n\n2.2.3.Focal Loss\n\nFocal loss is a loss function specially designed to solve the problem of category imbalance, especially\n\nin target detection and classification tasks. The core idea is to improve the model's ability to recognise\n\na small number of classes by decreasing the loss contribution to easy-to-categorise samples and thus\n\nincreasing the attention to difficult-to-categorise samples \\[12\\]. The formula for focal loss is as\n\nequation (1):\n\n\ued28\ued4b\ued3f\ued3d\ued48\ued48\ued4b\ued4f\ued4f\uf34c\uf346\ued3d\uf1e7\uf36b1\uf346\ued4c\uf1e7\uf36f\uf20alog\udb80\udddb\ued4c\uf1e7\udb80\udddc\uf36b1\uf36f\n\n\ued4c\uf1e7 represents the predicted probability: if the true label y = 1, then \ued4c\uf1e7\uf34c\ued4c; if y = 0, then \ued4c\uf1e7\uf34c\ue973\uf346\n\n\ued4c, where p is the model\u2019s predicted probability for the positive class. \u03b1t is an optional balancing factor\n\nused to adjust the balance between positive and negative samples, typically to control the weighting\n\nfor class imbalance. The parameter \u03b3 is a focusing parameter, which controls the rate at which easy\n\nand hard samples\u2019 loss decays. Generally, when \u03b3 \u2265 0, the harder-to-classify samples (i.e., smaller\n\npt ) have larger weights.\n\nProceedings of the 3rd International Conference on Financial Technology and Business Analysis\n\nDOI: 10.54254/2754-1169/118/2024.18627\n\n283\n\nFocal loss introduces the term \udb80\udddb\ue973\uf346\ued4c\uf1e7\udb80\udddc\uf20a, which dynamically adjusts the loss weight of each\n\nsample. For easy-to-classify samples (i.e., \ued4c\uf1e7 close to 1), this term approaches 0, reducing their loss\n\ncontribution; for hard-to-classify samples (i.e., smaller pt), this term is larger, increasing their loss\n\nweight. This mechanism ensures that the model focuses more on difficult-to-classify samples during\n\ntraining, thereby improving the recognition performance for minority classes. Focal Loss reduces the\n\nloss contribution from easy samples, allowing the model to better learn from minority class samples,\n\nand can be flexibly applied to different tasks by adjusting the parameters \u03b3 and \u03b1.\n\n3.Result and Discussion\n\n3.1.Model Performance\n\nThis research builds a model for money laundering detection using the GAT applied to knowledge\n\ngraph data. The process involves data preprocessing to convert the data into a graph structure,\n\nfollowed by model training and evaluation. Focal Loss is used to handle class imbalance, and the final\n\nresults include a classification report and graph visualization. The hypothesis is that the GAT can\n\ncapture complex relationships between nodes, enhancing the detection of money laundering activities.\n\nTable 2: Training set model performance.\n\nTable 3: Testing set model performance.\n\nAs displayed in Table 2 and Table 3, on the training set, the GAT model achieved a loss of 4.33\n\nand 75% accuracy, with better metrics for category 0 than category 1, indicating strong performance.\n\nHowever, on the test set, the model's loss increased to 4.88, and accuracy dropped to 70%, showing\n\nreduced generalization, likely due to overfitting or data distribution differences. Overall, while the\n\nGAT model shows promise for detecting money laundering (see in Figure 3), it requires further tuning\n\nto improve prediction performance on test data. Sensitivity analysis on different data volumes will\n\nhelp assess and enhance the model\u2019s robustness, improving stability and accuracy in practical\n\napplications.\n\nFigure 3: Confusion matrix of test set prediction results.\n\nProceedings of the 3rd International Conference on Financial Technology and Business Analysis\n\nDOI: 10.54254/2754-1169/118/2024.18627\n\n284\n\n3.2.Sensitivity Analysis\n\nIn financial data analysis, the stability and generalization ability of a model is very important \\[13\\]. In\n\norder to further assess the robustness of the GAT model in AML tasks, this research conducts a\n\ndetailed sensitivity analysis, which aims to determine the model's response to different data variations\n\nand assess its performance under various conditions.\n\n3.2.1.Volume Analysis\n\nTo test the model's sensitivity to variations in data volume, this research randomly generated subsets\n\nof 2000, 3000, and 4000 transaction records to evaluate the model's performance. This approach aims\n\nto assess the model's stability and check for signs of overfitting or underfitting.\n\nTable 4: Comparison of model performance with different amount of data.\n\nAs illustrated in the Table 4, with 2000 records, the model performs best, achieving an accuracy\n\nof 0.70, recall of 0.67, and an F1 score of 0.71, indicating that it classifies effectively with smaller\n\ndatasets. However, the superior performance suggests potential overfitting. As the data volume\n\nincreases to 3000 records, the accuracy drops slightly to 0.68, with recall at 0.64 and F1 score at 0.68,\n\nreflecting a more stable performance, and the model seems to generalize better at this data level.\n\nWhen the data volume increases to 4000 records, the model's performance declines further, with\n\naccuracy falling to 0.65, recall to 0.60, and the F1 score to 0.65, suggesting underfitting as the model\n\nstruggles to capture the complex patterns in larger datasets.\n\n3.2.2.Feature Importance Analysis\n\nIn order to further understand the behaviour of the model, this research analysed the importance of\n\nthe features and assessed the performance of the model after removing certain features by calculating\n\nthe extent to which each feature affects the model predictions. The analysis of the importance of\n\nfeatures helps to identify which features are most critical to model performance (as shown in Table\n\n5), thus providing further direction for optimisation.\n\nTable 5: Importance scores for different features.\n\nRecall Rate After\n\nRemoval\n\nProceedings of the 3rd International Conference on Financial Technology and Business Analysis\n\nDOI: 10.54254/2754-1169/118/2024.18627\n\n285\n\nThis table demonstrates that 'Timestamp' is the most critical feature, with its removal causing the\n\ngreatest performance drop (accuracy to 0.68, recall to 0.62, F1-score to 0.67). Removing 'Payment\n\nFormat' also leads to a significant decline (accuracy to 0.69), while 'Account' and 'Payment Amount'\n\ncause smaller reductions in performance. For instance, removing ' Amount Paid' drops accuracy to\n\n0.68, but has less impact overall. These findings highlight the importance of 'Timestamp' in\n\noptimizing the model, while 'Amount received' has the least effect, guiding better feature selection\n\nand model tuning.\n\n3.2.3.Time Period Analysis\n\nThe time period sensitivity analysis divides data into \"Morning\" (6:00-12:00), \"Afternoon\" (12:00-\n\n18:00), and \"Evening\" (18:00-24:00) intervals. Removing the \"Timestamp\" showed a more\n\nsignificant impact on model performance in the evening compared to morning and afternoon. This\n\nsuggests the model relies more on this feature in the evening, highlighting opportunities for\n\noptimizing performance based on time of day.\n\nTable 6: Importance scores for different time periods.\n\nRecall Rate After\n\nRemoval\n\nThe Table 6 reveals the feature importance scores, along with the accuracy, recall, and F1 score\n\nfor each time period. In the morning, the feature importance score is highest at 0.30, with the model\n\nperforming robustly\u2014achieving an accuracy and F1 score of 0.70. During midday, despite a lower\n\nfeature importance score of 0.20, the model achieves the highest accuracy (0.72), although the recall\n\nis lower at 0.66, indicating a potential bias in the predictions. In the evening, the feature importance\n\nscore is 0.25, with the model's performance slightly lower than midday, showing a decline in overall\n\nprediction effectiveness. These results highlight the significant impact of time-specific features on\n\nmodel accuracy, with morning characteristics contributing most to the model\u2019s success.\n\n3.3.Model Comparison\n\nIn this subsection, this research compares the performance of four graph neural network models: GAT,\n\nGCN, GraphSAGE, and GIN. By applying these models to the anti-money laundering detection task\n\non the test set data, the accuracy, recall and f1 score of each model are analyzed in detail and their\n\nperformance is evaluated (as shown in Figure 4).\n\nProceedings of the 3rd International Conference on Financial Technology and Business Analysis\n\nDOI: 10.54254/2754-1169/118/2024.18627\n\n286\n\nFigure 4: Comparison of different graph neural network models.\n\nThe GIN model outperforms others with the highest accuracy (0.72) and F1-score (0.71), showing\n\nits ability to classify effectively and balance precision and recall. In contrast, the GAT model excels\n\nin recall (0.68), making it particularly effective at detecting money laundering activities, but it has a\n\nslightly lower accuracy (0.70) and F1-score (0.70) compared to GIN. While both GIN and GAT\n\ndemonstrate strong performance, GIN's higher accuracy suggests better overall classification,\n\nwhereas GAT's higher recall highlights its superior detection of positive instances. Overall, GIN is\n\nbetter at capturing key features and managing complex, nonlinear relationships, while GAT offers\n\nenhanced sensitivity to detecting rare events.\n\n4.Conclusion\n\nThis research investigates the integration of knowledge graphs and GNNs to strengthen AML efforts,\n\naddressing the growing demand for advanced technological solutions in the financial sector. While\n\nthe GAT model demonstrated strong performance on the training data, it faced challenges in\n\ngeneralization and overfitting on the test data, particularly with larger datasets. Feature analysis\n\nunderscored the significance of variables like timestamps, offering valuable insights into model\n\noptimization and feature selection. Further analyses revealed that the GAT model performed more\n\neffectively during morning transaction periods, and suggested that the GIN model may offer superior\n\ndata processing capabilities under certain conditions. These findings provide practical\n\nrecommendations for enhancing AML systems through AI-driven methods. Future research could\n\nfocus on refining the models to improve generalization, paving the way for further advancements in\n\nAML technology.\n\nReferences\n\n\\[1\\]Jack, N., Aditya, K., & Nhien-An, L. (2021) Financial Cybercrime: A Comprehensive Survey of Deep Learning\n\nApproaches to Tackle the Evolving Financial Crime Landscape, IEEE Access, 9, 163965-163986.\n\n\\[2\\]Akash, G., Kapil, G., Aman Kumar, P., & Dharm, R. (2024) Fraud Detection Using Machine Learning and Deep\n\nLearning, SN Computer Science, 5(7), 1-1.\n\n\\[3\\]Yongshan, Z., Zhiyun, J., Cong, P., Xiumei, Z., & Gang, W. (2024) Management Analysis Method of Multivariate\n\nTime Series Anomaly Detection in Financial Risk Assessment, JOURNAL OF ORGANIZATIONAL AND END USER\n\nCOMPUTING, 36(1), 1-19.\n\n\\[4\\]Liyu, G., & Qiang, C. (2019) Exploiting Edge Features for Graph Neural Networks, Proceedings - IEEE Computer\n\nSociety Conference on Computer Vision and Pattern Recognition, 9211-9219\n\n\\[5\\]Simone, M., & Stefano, F. (2024) Anti-Money Laundering in Cryptocurrencies Through Graph Neural Networks:\n\nA Comparative Study, 2024 IEEE 21st Consumer Communications &amp; Networking Conference, 272-277.\n\n\\[6\\]Wu B, Chao K M, Li Y. (2024) Heterogeneous graph neural networks for fraud detection and explanation in supply\n\nchain finance. Information Systems, 121, 102335.\n\nProceedings of the 3rd International Conference on Financial Technology and Business Analysis\n\nDOI: 10.54254/2754-1169/118/2024.18627\n\n287\n\n\\[7\\]Ahmad Naser, E., Jacopo, B., David, A., David, P., Jo\u00e3o Tiago, A., Pedro, B., & Pedro, R. (2021) Anti-Money\n\nLaundering Alert Optimization Using Machine Learning with Graphs, CoRR, abs/2112.07508\n\n\\[8\\]Wu, Z., Pan, S., Long, G., Jiang, J., Chang, X., & Zhang, C. (2020) Connecting the Dots: Multivariate Time Series\n\nForecasting with Graph Neural Networks, KDD '20: The 26th ACM SIGKDD Conference on Knowledge Discovery\n\nand Data Mining Virtual Event CA USA July, 2020, abs/2005.11650, 753-763.\n\n\\[9\\]Qingyu, G., Fuzhen, Z., Chuan, Q., Hengshu, Z., Xing, X., Hui, X., & Qing, H. (2022) A Survey on Knowledge\n\nGraph-Based Recommender Systems, IEEE Transactions on Knowledge and Data Engineering, 34(8), 3549-3568.\n\n\\[10\\]Shaoxiong, J., Shirui, P., Erik, C., Pekka, M., & Philip S., Y. (2022) A Survey on Knowledge Graphs: Representation,\n\nAcquisition, and Applications, IEEE Transactions on Neural Networks and Learning Systems, 33(2), 494-514.\n\n\\[11\\]Rui, C., & Qing, L. (2021) Modeling The Momentum Spillover Effect For Stock Prediction Via Attribute-Driven\n\nGraph Attention Networks, AAAI Conference on Artificial Intelligence, 35, 55-62.\n\n\\[12\\]Nadia, P., Mirko, Z., Fabio, M., Muhammad Zohaib, S., & Stefano, F. (2023) Detecting anomalous cryptocurrency\n\ntransactions: An AML/CFT application of machine learning-based forensics, Electronic Markets, 33(1), 1-17.\n\n\\[13\\]Matthias, T., Carolina Raquel, M., & Edin, I. (2021) Measuring and Mitigating Systemic Risks: How the Forging\n\nof New Alliances Between Central Bank and Academic Economists Legitimize the Transnational Macroprudential\n\nAgenda, Review of international political economy, 28(6), 1433-1458.\n\nProceedings of the 3rd International Conference on Financial Technology and Business Analysis\n\nDOI: 10.54254/2754-1169/118/2024.18627\n\n288\n\nResearchGate has not been able to resolve any citations for this publication.\n\n- [Akash Gandhar](https://www.researchgate.net/scientific-contributions/Akash-Gandhar-2279485704)\n- [Kapil Gupta](https://www.researchgate.net/scientific-contributions/Kapil-Gupta-2279521044)\n- [Aman Kumar Pandey](https://www.researchgate.net/scientific-contributions/Aman-Kumar-Pandey-2279531949)\n- [Dharm Raj](https://www.researchgate.net/scientific-contributions/Dharm-Raj-2268939615)\n\nDetecting fraudulent activities is a major worry for businesses and financial organizations because they can result in significant financial losses and reputational harm. Traditional fraud detection a method frequently depend on present rules and patterns that skilled scammer can easily circumvent. Machine learning and deep learning algorithms have surfaced as promising methods for detecting fraud in order to handle this problem. Authors present a thorough overview of the most recent ML and DL techniques for fraud identification in this article. These approaches are classified based on their fundamental tactics, which include supervised learning, unsupervised learning, and reinforcement learning. We review recent developments in each area, as well as their strengths and weaknesses. Additionally, we draw attention to some of the major problems with imbalanced datasets, adversarial assaults, and the interpretability of models as well as other important research tasks and difficulties in fraud detection. We also stress the value of feature science and data pre-processing techniques in enhancing the effectiveness of scam detection systems. Finally, we show a case study on the use of DL and ML techniques in the financial sector for fraud detection. Authors show how these algorithms can successfully identify fraudulent transactions, minimize false positives, and keep high precision and scalability. The overall aim of this article is to provide a comprehensive evaluation of the most cutting-edge ML and DL techniques for fraud identification and to shed light on potential future paths for this field of study.\n\n- [Yongshan Zhang](https://www.researchgate.net/scientific-contributions/Yongshan-Zhang-2278757890)\n- [Zhiyun Jiang](https://www.researchgate.net/scientific-contributions/Zhiyun-Jiang-2278738081)\n- [Cong Peng](https://www.researchgate.net/scientific-contributions/Cong-Peng-2278752764)\n- [Gang Wang](https://www.researchgate.net/scientific-contributions/Gang-Wang-2278748989)\n\nThe significance of financial risk lies in its impact on economic stability and individual/institutional financial security. Effective risk management is crucial for market confidence and crisis prevention. Current methods for multivariate time series anomaly detection have limitations in adaptability and generalization. To address this, we propose an innovative approach integrating contrastive learning and Generative Adversarial Networks (GANs). We use geometric distribution masking for data augmentation to enhance dataset diversity. Within the GAN framework, we train a Transformer-based autoencoder to capture normal point distributions. We include contrastive loss in the discriminator to ensure robust generalization. Rigorous experiments on four real-world datasets show that our method effectively mitigates overfitting and outperforms state-of-the-art approaches. This enhances anomaly identification in risk management, paving the way for deep learning in finance, and offering insights for future research and practical use.\n\nIn shaping the Internet of Money, the application of blockchain and distributed ledger technologies (DLTs) to the financial sector triggered regulatory concerns. Notably, while the user anonymity enabled in this field may safeguard privacy and data protection, the lack of identifiability hinders accountability and challenges the fight against money laundering and the financing of terrorism and proliferation (AML/CFT). As law enforcement agencies and the private sector apply forensics to track crypto transfers across ecosystems that are socio-technical in nature, this paper focuses on the growing relevance of these techniques in a domain where their deployment impacts the traits and evolution of the sphere. In particular, this work offers contextualized insights into the application of methods of machine learning and transaction graph analysis. Namely, it analyzes a real-world dataset of Bitcoin transactions represented as a directed graph network through various techniques. The modeling of blockchain transactions as a complex network suggests that the use of graph-based data analysis methods can help classify transactions and identify illicit ones. Indeed, this work shows that the neural network types known as Graph Convolutional Networks (GCN) and Graph Attention Networks (GAT) are a promising AML/CFT solution. Notably, in this scenario GCN outperform other classic approaches and GAT are applied for the first time to detect anomalies in Bitcoin. Ultimately, the paper upholds the value of public\u2013private synergies to devise forensic strategies conscious of the spirit of explainability and data openness.\n\nMachine Learning and Deep Learning methods are widely adopted across financial domains to support trading activities, mobile banking, payments, and making customer credit decisions. These methods also play a vital role in combating financial crime, fraud, and cyberattacks. Financial crime is increasingly being committed over cyberspace, and cybercriminals are using a combination of hacking and social engineering techniques which are bypassing current financial and corporate institution security. With this comes a new umbrella term to capture the evolving landscape which is financial cybercrime. It is a combination of financial crime, hacking, and social engineering committed over cyberspace for the sole purpose of illegal economic gain. Identifying financial cybercrime-related activities is a hard problem, for example, a highly restrictive algorithm may block all suspicious activity obstructing genuine customer business. Navigating and identifying legitimate illicit transactions is not the only issue faced by financial institutions, there is a growing demand of transparency, fairness, and privacy from customers and regulators, which imposes unique constraints on the application of artificial intelligence methods to detect fraud-related activities. Traditionally, rule based systems and shallow anomaly detection methods have been applied to detect financial crime and fraud, but recent developments have seen graph based techniques and neural network models being used to tackle financial cybercrime. There is still a lack of a holistic understanding of the financial cybercrime ecosystem, relevant methods, and their drawbacks and new emerging open problems in this domain in spite of their popularity. In this survey, we aim to bridge the gap by studying the financial cybercrime ecosystem based on four axes: (a) different fraud methods adopted by criminals; (b) relevant systems, algorithms, drawbacks, constraints, and metrics used to combat each fraud type; (c) the relevant personas and stakeholders involved; (d) open and emerging problems in the financial cybercrime domain.\n\nTo solve the information explosion problem and enhance user experience in various online applications, recommender systems have been developed to model users' preferences. Although numerous efforts have been made toward more personalized recommendations, recommender systems still suffer from several challenges, such as data sparsity and cold-start problems. In recent years, generating recommendations with the knowledge graph as side information has attracted considerable interest. Such an approach can not only alleviate the above mentioned issues for a more accurate recommendation, but also provide explanations for recommended items. In this paper, we conduct a systematical survey of knowledge graph-based recommender systems. We collect recently published papers in this field, and group them into three categories, i.e., embedding-based methods, connection-based methods, and propagation-based methods. Also, we further subdivide each category according to the characteristics of these approaches. Moreover, we investigate the proposed algorithms by focusing on how the papers utilize the knowledge graph for accurate and explainable recommendation. Finally, we propose several potential research directions in this field.\n\nAfter the great financial crisis of 2007\u20132009, central banks were handed a macroprudential mandate to contain systemic risks, a mandate seen as endangering their independence due to expected distributional conflicts. At the same time, depoliticization through scientific expertise was largely foreclosed, as systemic risk was a largely undefined concept. This paper focuses on how central banks dealt with this conundrum. It examines the scientific debate on systemic risk and macroprudential regulation post-crisis, focusing on the debate\u2019s impact on final regulation. Employing author-topic-modeling on a unique dataset of 2397 published economic papers on the relevant topics, we detect the formation of a new alliance between central bankers and academic economists working jointly on developing systemic risk measures. Centered around a hinge of systemic risk contribution by individual banks, this new alliance expresses itself by incorporating the macroprudential concerns of practitioners into abstract market-based systemic risk measures. These measures develop incrementally, using and repurposing techniques from financial economics pre-crisis to legitimize and justify macroprudential interventions post-crisis. This alliance allows us to account for the incremental change witnessed post-crisis and point to its potential for long-term fundamental change.\n\nHeterogeneous graph neural networks for fraud detection and explanation in supply chain finance. Information Systems, 121, 102335\n\n- B Wu\n- K M Chao\n- Y Li\n\nWu B, Chao K M, Li Y. (2024) Heterogeneous graph neural networks for fraud detection and explanation in supply\nchain finance. Information Systems, 121, 102335.\nProceedings of the 3rd International Conference on Financial Technology and Business Analysis\nDOI: 10.54254/2754-1169/118/2024.18627\n\nAnti-Money Laundering Alert Optimization Using Machine Learning with Graphs\n\n- Ahmad Naser\n- E Jacopo\n- B David\n- A David\n- P Jo\u00e3o Tiago\n- A Pedro\n- B Pedro\n\nAhmad Naser, E., Jacopo, B., David, A., David, P., Jo\u00e3o Tiago, A., Pedro, B., & Pedro, R. (2021) Anti-Money\nLaundering Alert Optimization Using Machine Learning with Graphs, CoRR, abs/2112.07508", "embedding": [-0.014939670450985432, -0.03953351452946663, -0.031054722145199776, 0.020526673644781113, 0.0379849411547184, -0.003871905617415905, 0.03603199124336243, -0.034157853573560715, 0.02085994742810726, -0.004948372021317482, 0.02180914580821991, 0.008015938103199005, 0.000825694587547332, 0.041998423635959625, -0.05688516050577164, -0.06863545626401901, 0.07795576006174088, -0.00813191756606102, -0.07368431985378265, -0.019808536395430565, 0.006814854685217142, -0.016972413286566734, -0.007042053621262312, -0.04936928674578667, 0.02159929648041725, 0.010491953231394291, -0.02858763001859188, -0.010599625296890736, -0.019304972141981125, -0.009965799748897552, 0.08541609346866608, 0.03985891118645668, 0.03680706024169922, 0.11430826783180237, -0.03359168395400047, -0.057745713740587234, 0.022258799523115158, 0.047424402087926865, 0.08790924400091171, -0.0047927736304700375, 0.04277358576655388, -0.06839349865913391, 0.03565168008208275, 0.04136068746447563, 0.08440012484788895, 0.003844962688162923, -0.011009804904460907, 0.032691095024347305, -0.010231118649244308, 0.05022916570305824, -0.10247103124856949, -0.023447902873158455, -0.01876237615942955, 0.03250877559185028, 0.005150638986378908, 0.001482031773775816, -0.0013406869256868958, -0.014064736664295197, -0.01855563186109066, -0.02188553288578987, 0.03307029604911804, -0.011226162314414978, 0.025758124887943268, -0.015422006137669086, 0.02145615965127945, 0.05019116401672363, -0.01571740210056305, 0.05334921553730965, -0.021495729684829712, -0.014479251578450203, 0.06278297305107117, 0.024276267737150192, -0.13609875738620758, -0.01682872511446476, -0.035792846232652664, 0.06603624671697617, 0.020466020330786705, 0.06167396157979965, -0.015540357679128647, -0.0775422528386116, -0.024100832641124725, -0.031781964004039764, 0.03649105131626129, -0.015813253819942474, 0.04405151307582855, -0.02528766356408596, -0.031638000160455704, 0.04152319207787514, 0.03513602912425995, 0.0023480502422899008, 0.013250033371150494, 0.004159728996455669, 0.09231528639793396, -0.09038770198822021, 0.07483641803264618, 0.036136023700237274, 0.004075275734066963, -0.029641615226864815, 0.01788923516869545, 0.037735071033239365, -0.015027172863483429, 0.05000239983201027, -0.011215334758162498, -0.02517629973590374, 0.0484938882291317, -0.004104519262909889, 0.07633493095636368, 0.04663269221782684, 0.011067320592701435, -0.09080090373754501, -0.011868114583194256, 0.09254519641399384, 0.0613800548017025, -0.08421936631202698, 0.02343023754656315, 0.01709631271660328, -0.10448231548070908, 0.022672221064567566, -0.016626155003905296, 0.1466170847415924, -0.006391615606844425, 0.08126626908779144, -0.048679761588573456, 0.0004295359249226749, -0.04324173927307129, 0.049737658351659775, -0.16347327828407288, 4.14784156029435e-34, -0.06021266430616379, 0.006964362226426601, 0.0008655590354464948, -0.05546584352850914, -0.013467619195580482, 0.037628643214702606, -0.06748451292514801, -0.0028477523010224104, 0.0005138228298164904, 0.09062796831130981, -0.101508729159832, 0.007805244065821171, -0.10002776235342026, 0.009660310111939907, -0.005713359918445349, 0.06981810182332993, 0.024263273924589157, -0.024041766300797462, 0.025215936824679375, -0.08300221711397171, 0.07598747313022614, -0.12450501322746277, 0.0429186187684536, -0.010757111944258213, 0.029543399810791016, 0.017588021233677864, -0.046956341713666916, -0.011294176802039146, 0.08593492209911346, -0.016294607892632484, -0.009867731481790543, 0.07485371828079224, 0.09019877761602402, 0.11429397016763687, 0.025627123191952705, -0.03296997398138046, -0.08039620518684387, -0.027846839278936386, 0.057412728667259216, -0.024664076045155525, -0.08012524992227554, 0.0351882167160511, -0.01189381442964077, -0.02245110087096691, -0.04772455245256424, 0.10715153813362122, 0.007591560948640108, -0.042753733694553375, 0.03232491388916969, -0.019755391404032707, 0.050612397491931915, -0.004659047815948725, -0.024772873148322105, -0.022760853171348572, -0.060115132480859756, 0.025290602818131447, 0.05215029418468475, 0.013490192592144012, -0.05931919813156128, 0.009791228920221329, -0.02598528563976288, 0.008100138045847416, -0.028989115729928017, 0.0506172850728035, -0.08025947213172913, 0.08710412681102753, -0.01984521560370922, 0.08419317752122879, 0.043265581130981445, 0.03536981716752052, -0.0015166787197813392, 0.09245779365301132, 0.020274482667446136, 0.023281365633010864, -0.04310984164476395, -0.03457800671458244, 0.03359955549240112, -0.021802423521876335, -0.006682171951979399, 0.0056305150501430035, -0.05627250298857689, -0.06066400557756424, 0.026710333302617073, 0.037705518305301666, -0.04884471744298935, 0.031419046223163605, 0.04295603558421135, -0.02382804825901985, 0.05880247429013252, -0.07245633751153946, -0.003795739496126771, -0.054062362760305405, -0.043121978640556335, 0.05025865137577057, 0.0021748244762420654, -9.284325297508093e-34, -0.03235543519258499, 0.058665186166763306, 0.0008066606242209673, -0.034284502267837524, -0.044926177710294724, 0.010543483309447765, -0.04371686652302742, -0.03396260738372803, 0.006864106748253107, 0.06590593606233597, 0.02310875989496708, -0.11246505379676819, 0.042190760374069214, -0.045517824590206146, 0.014461386017501354, -0.021789146587252617, 0.03610881417989731, 0.01871243491768837, 0.009000060148537159, -0.014864172786474228, -0.0015163921052590013, 0.03241148591041565, -0.035348791629076004, 0.019833069294691086, 0.0370265431702137, -0.003871459048241377, -0.05606154352426529, -0.057421278208494186, -0.02064802311360836, 0.08573397248983383, -0.07285996526479721, 0.018550090491771698, 0.015096670016646385, -0.005076135974377394, -0.0036942551378160715, -0.014960771426558495, 0.06313330680131912, -0.0980934202671051, 0.01652236469089985, -0.04067257046699524, 0.005740279797464609, 0.0603245384991169, -0.11026442795991898, -0.013316917233169079, -0.06291309744119644, 0.05040081962943077, -0.029511909931898117, 0.05999365076422691, 0.04820820689201355, -0.06308396905660629, -0.02389197237789631, -0.028959276154637337, 0.05181165412068367, -0.044263310730457306, -0.0733732283115387, 0.07646647095680237, 0.07359399646520615, -0.01097539160400629, 0.006006546318531036, -0.0066598947159945965, -0.06713980436325073, -0.0018295346526429057, 0.020032957196235657, -0.023388754576444626, -0.020286183804273605, 0.007953131571412086, 0.0052364482544362545, 0.03837011381983757, 0.019346250221133232, -0.012198601849377155, -0.0015915661351755261, -0.07689332962036133, -0.01658901572227478, 0.03731667622923851, 0.055742453783750534, -0.015438131988048553, -0.04664422944188118, -0.06337892264127731, -0.043094344437122345, -0.005895931273698807, 0.04052266106009483, -0.021766044199466705, 0.004303522873669863, 0.08033259958028793, 0.060045890510082245, 0.005726479459553957, 0.016099270433187485, 0.013102713972330093, 0.09608694911003113, 0.046816375106573105, -0.034319858998060226, -0.016043366864323616, -0.0888165608048439, 0.057848405092954636, -0.07893995195627213, -3.685726213120688e-08, -0.1140412911772728, -0.024513738229870796, 0.006473078858107328, 0.03505604714155197, 0.07806913554668427, -0.00998189952224493, 0.009479168802499771, 0.0642220601439476, -0.05319555103778839, -0.004857894964516163, 0.08807597309350967, -0.03449922427535057, -0.10431414097547531, -0.08994902670383453, -0.027139484882354736, -0.08717943727970123, -0.0036059038247913122, -0.041679274290800095, 0.026407063007354736, 0.06395119428634644, 0.0032511018216609955, -0.032804325222969055, 0.0048251403495669365, 0.02332429029047489, 0.025514405220746994, -0.18643315136432648, -0.039452314376831055, 0.1280227154493332, 0.05090014263987541, 0.0655013918876648, -0.05704813078045845, -0.03965489938855171, 0.10689756274223328, -0.008306222036480904, -0.024707427248358727, 0.10404449701309204, 0.08365492522716522, -0.02331225760281086, -0.07485531270503998, 0.08422469347715378, 0.016250543296337128, 0.052361249923706055, -0.0038834474980831146, -0.013375087641179562, -0.013191115111112595, -0.04490017890930176, -0.039375729858875275, -0.025066137313842773, 0.1359741985797882, -0.0905262902379036, 0.06112669035792351, -0.07187698036432266, 0.05179709568619728, 0.05385677516460419, 0.06665533781051636, -0.012610034085810184, 0.00872126780450344, 0.04545104131102562, 0.017319438979029655, -0.018899066373705864, 0.07805414497852325, -0.06322748214006424, -0.014860531315207481, -0.038204360753297806]}, {"id": "694f114d2ef7fd944bcee9e4", "user_id": "CarlFristam", "title": "Anti-Money Laundering Alert Optimization Using Machine ...", "text": "# Computer Science > Machine Learning\n\n**arXiv:2112.07508** (cs)\n\n\\[Submitted on 14 Dec 2021 ( [v1](https://arxiv.org/abs/2112.07508v1)), last revised 17 Jun 2022 (this version, v3)\\]\n\n# Title:Anti-Money Laundering Alert Optimization Using Machine Learning with Graphs\n\nAuthors: [Ahmad Naser Eddin](https://arxiv.org/search/cs?searchtype=author&query=Eddin,+A+N), [Jacopo Bono](https://arxiv.org/search/cs?searchtype=author&query=Bono,+J), [David Apar\u00edcio](https://arxiv.org/search/cs?searchtype=author&query=Apar%C3%ADcio,+D), [David Polido](https://arxiv.org/search/cs?searchtype=author&query=Polido,+D), [Jo\u00e3o Tiago Ascens\u00e3o](https://arxiv.org/search/cs?searchtype=author&query=Ascens%C3%A3o,+J+T), [Pedro Bizarro](https://arxiv.org/search/cs?searchtype=author&query=Bizarro,+P), [Pedro Ribeiro](https://arxiv.org/search/cs?searchtype=author&query=Ribeiro,+P)\n\nView a PDF of the paper titled Anti-Money Laundering Alert Optimization Using Machine Learning with Graphs, by Ahmad Naser Eddin and 6 other authors\n\n[View PDF](https://arxiv.org/pdf/2112.07508)\n\n> Abstract:Money laundering is a global problem that concerns legitimizing proceeds from serious felonies (1.7-4 trillion euros annually) such as drug dealing, human trafficking, or corruption. The anti-money laundering systems deployed by financial institutions typically comprise rules aligned with regulatory frameworks. Human investigators review the alerts and report suspicious cases. Such systems suffer from high false-positive rates, undermining their effectiveness and resulting in high operational costs. We propose a machine learning triage model, which complements the rule-based system and learns to predict the risk of an alert accurately. Our model uses both entity-centric engineered features and attributes characterizing inter-entity relations in the form of graph-based features. We leverage time windows to construct the dynamic graph, optimizing for time and space efficiency. We validate our model on a real-world banking dataset and show how the triage model can reduce the number of false positives by 80% while detecting over 90% of true positives. In this way, our model can significantly improve anti-money laundering operations.\n\n| | |\n| --- | --- |\n| Comments: | 8 pages, 5 figures |\n| Subjects: | Machine Learning (cs.LG) |\n| MSC classes: | I.2.1, J.4 |\n| Cite as: | [arXiv:2112.07508](https://arxiv.org/abs/2112.07508) \\[cs.LG\\] |\n| | (or [arXiv:2112.07508v3](https://arxiv.org/abs/2112.07508v3) \\[cs.LG\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2112.07508](https://doi.org/10.48550/arXiv.2112.07508) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Ahmad Naser Eddin \\[ [view email](https://arxiv.org/show-email/d798b4c0/2112.07508)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2112.07508v1)**\nTue, 14 Dec 2021 16:12:30 UTC (975 KB)\n\n**[\\[v2\\]](https://arxiv.org/abs/2112.07508v2)**\nThu, 10 Mar 2022 11:10:15 UTC (500 KB)\n\n**\\[v3\\]**\nFri, 17 Jun 2022 09:00:26 UTC (975 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Anti-Money Laundering Alert Optimization Using Machine Learning with Graphs, by Ahmad Naser Eddin and 6 other authors\n\n- [View PDF](https://arxiv.org/pdf/2112.07508)\n- [TeX Source](https://arxiv.org/src/2112.07508)\n- [Other Formats](https://arxiv.org/format/2112.07508)\n\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2112.07508&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2112.07508&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2021-12](https://arxiv.org/list/cs.LG/2021-12)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2112.07508?context=cs)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2112.07508)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2112.07508)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2112.07508)\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2112.html#abs-2112-07508) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2112-07508)\n\n[David Apar\u00edcio](https://dblp.uni-trier.de/search/author?author=David%20Apar%C3%ADcio)\n\n[Pedro Ribeiro](https://dblp.uni-trier.de/search/author?author=Pedro%20Ribeiro)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2112.07508&description=Anti-Money Laundering Alert Optimization Using Machine Learning with Graphs) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2112.07508&title=Anti-Money Laundering Alert Optimization Using Machine Learning with Graphs)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2112.07508) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))", "embedding": [-0.07621046900749207, 0.04598437622189522, -0.06067528948187828, 0.015411288477480412, 0.053441908210515976, -0.0021465488243848085, 0.043110646307468414, -0.021361572667956352, -0.01427505724132061, 0.05539654567837715, 0.016777722164988518, -0.0030185480136424303, 0.003208152949810028, -0.0200194101780653, -0.06417407095432281, 0.07590427249670029, -0.05936841666698456, 0.053833164274692535, -0.019766569137573242, -0.0363018624484539, -0.021677879616618156, -0.0748692974448204, 0.004801502916961908, -0.047690585255622864, 0.06781256198883057, -0.020168486982584, 0.005189852323383093, 0.0021247623953968287, -0.006597673520445824, -0.014821732416749, 0.04027656838297844, 0.0312449149787426, 0.062178049236536026, 0.05227026715874672, -0.03562605381011963, 0.0029685180634260178, 0.02099478617310524, 0.07432417571544647, 0.05023641511797905, 0.01940283365547657, 0.02023600973188877, -0.03932720050215721, -0.008621006272733212, -0.04594508931040764, 0.05384308099746704, -0.03438754007220268, -0.06832616776227951, 0.022179340943694115, 0.007349630817770958, 0.027266809716820717, -0.14605015516281128, 0.00514777097851038, 0.019213363528251648, -0.02106957696378231, -0.045050617307424545, -0.057086095213890076, -0.0009834462543949485, -0.00674678897485137, -0.026796855032444, -0.05920962244272232, 0.016525600105524063, -0.02684510126709938, -0.054853927344083786, 0.015803741291165352, 0.017061660066246986, -0.028159525245428085, -0.002496098866686225, 0.04060738533735275, -0.07421774417161942, 0.061722688376903534, 0.0763176828622818, 0.017102252691984177, -0.10332464426755905, -0.005203392822295427, 0.023624887689948082, 0.0608503557741642, 0.04346884414553642, 0.013106797821819782, -0.004647715948522091, -0.11426790058612823, 0.007787452079355717, -0.0031593539752066135, 0.019437499344348907, -0.05485648289322853, 0.0173842404037714, 0.005649188533425331, -0.039128828793764114, -0.04396730661392212, 0.12393290549516678, -0.04048384353518486, 0.01976116932928562, 0.04376129060983658, 0.07059475779533386, -0.054697632789611816, 0.0532522015273571, 0.0005328715196810663, 0.03232189267873764, 0.03833624720573425, -0.03366277366876602, 0.0949263647198677, -0.010700538754463196, 0.019490361213684082, 0.004502161871641874, -0.06976877152919769, 0.003365609096363187, -0.01843470335006714, 0.059446532279253006, 0.09473692625761032, 0.06389909237623215, -0.028298290446400642, -0.02756595052778721, 0.051698099821805954, 0.006685448810458183, -0.008359293453395367, -0.0025301610585302114, 0.002374031348153949, -0.04242342710494995, -0.03216929733753204, -0.02261725626885891, 0.07710893452167511, -0.013402549549937248, 0.017526645213365555, -0.11363916844129562, 0.020242372527718544, -0.0433521531522274, -0.03224695846438408, -0.0831119567155838, 5.016872503407271e-33, 0.025277918204665184, 0.02665349468588829, 0.029471537098288536, -0.031891196966171265, -0.010426917113363743, 0.04117238149046898, -0.04364059865474701, -0.05638166144490242, -0.0630510002374649, 1.756710662448313e-05, -0.1431715190410614, 0.01732790656387806, 0.006684593390673399, 0.07798270881175995, -0.07512986660003662, 0.016063088551163673, 0.01706857420504093, -0.013458856381475925, 0.00030308347777463496, -0.0715038850903511, 0.12128138542175293, -0.07079264521598816, 0.015840137377381325, 0.03873062878847122, 0.02726898528635502, 0.043059758841991425, -0.01576368324458599, -0.04154127463698387, 0.04819048196077347, 0.04609942063689232, -0.08573132753372192, 0.06461606919765472, -0.009430008940398693, 0.047629471868276596, 0.02139025554060936, 0.004222356714308262, -0.10637887567281723, -0.009789836592972279, -9.747601143317297e-05, -0.032048944383859634, -0.09089997410774231, 0.06107447296380997, 0.10200954973697662, -0.010030671954154968, -0.11563438177108765, 0.035970352590084076, 0.012397831305861473, -0.015519168227910995, 0.10614784806966782, -0.00432420801371336, -0.03702395036816597, 0.0032416139729321003, -0.08365354686975479, -0.004294773563742638, -0.025572270154953003, 0.007857912220060825, -0.03619774803519249, 0.05663140118122101, -0.04172465577721596, -0.006728628650307655, 0.10165984183549881, 0.023299571126699448, -0.0028675212524831295, 0.05615491792559624, -0.06451199948787689, 0.021169710904359818, 0.0295389536768198, 0.03479090332984924, 0.0939965695142746, -0.0008510560728609562, 0.03533388301730156, 0.0708138719201088, 0.082708939909935, 0.008832150138914585, 0.000784687465056777, -0.026677962392568588, 0.06067885085940361, -0.00521945720538497, -0.012438488192856312, 0.008024492301046848, -0.09348659962415695, -0.020714696496725082, 0.06179635599255562, -0.014921394176781178, -0.091925248503685, -0.0023948736488819122, 0.1004946231842041, -0.01688038744032383, -0.03083697520196438, 0.037773650139570236, -0.0020724909845739603, 0.049247436225414276, -0.03711101412773132, 0.008749433793127537, -0.036787331104278564, -5.208712079435514e-33, -0.04599573463201523, 0.002262700581923127, 0.08251751214265823, -0.0588582381606102, 0.00841626338660717, 0.0026904409751296043, 0.002554715611040592, 5.748965122620575e-05, 0.050688911229372025, 0.020226411521434784, 0.0496365949511528, -0.10247547924518585, 0.07561047375202179, 0.005400037858635187, -0.009703809395432472, 0.009405153803527355, 0.021934526041150093, 0.017784839496016502, -0.021157503128051758, 0.028342558071017265, 0.012175041250884533, 0.08165492862462997, -0.08022671192884445, 0.0354565754532814, 0.030805271118879318, -0.014154612086713314, 0.05794323608279228, -0.002614495810121298, -0.06855776160955429, 0.04709077998995781, -0.061235133558511734, 0.06168142333626747, -0.14433829486370087, 0.0012932636309415102, -0.04574872925877571, 0.05220753327012062, 0.02411811798810959, -0.02258097194135189, -0.016775956377387047, 0.06150895357131958, 0.025965100154280663, 0.06761734932661057, -0.05306098237633705, -0.06207846477627754, -0.007345946040004492, 0.019366471096873283, -0.05538678169250488, 0.03154391795396805, 0.004706189502030611, -0.08788229525089264, 0.043627556413412094, 0.033963706344366074, -0.02098923921585083, 0.02807966247200966, -0.023930495604872704, 0.00616054842248559, 0.005535960663110018, -0.014435326680541039, -0.011607182212173939, -0.012106971815228462, -0.1489657461643219, 0.08829593658447266, -0.03540599346160889, 0.0712592825293541, 0.012346884235739708, -0.04578523337841034, -0.0001353578409180045, 0.028462212532758713, 0.017441503703594208, -0.08326032757759094, 0.03553901985287666, -0.07781685143709183, 0.0013291448121890426, 0.024822363629937172, -0.04225557669997215, 0.015928680077195168, -0.052619945257902145, 0.03209271281957626, 0.005947362631559372, -0.042937397956848145, 0.021938465535640717, -0.024544741958379745, 0.013305236585438251, 0.11202765256166458, -0.012275206856429577, 0.054923947900533676, -0.0023377537727355957, -0.037032220512628555, 0.016255337744951248, 0.06085674464702606, 0.02836640551686287, -0.05644519627094269, -0.003789006732404232, 0.04264095798134804, -0.006649899296462536, -5.2518672077894735e-08, -0.05374803766608238, -0.0026713949628174305, -0.025624385103583336, -0.010508295148611069, 0.06471044570207596, 0.04842965304851532, 0.016156263649463654, 0.056523434817790985, -0.05343659594655037, 0.058088306337594986, 0.059364233165979385, 0.04946042597293854, 0.0023513962514698505, -0.037025436758995056, -0.05926411598920822, -0.09457104653120041, 0.002104346174746752, -0.0054523576982319355, -0.024817340075969696, -0.026577964425086975, 0.054019708186388016, 0.0327131450176239, -0.015069354325532913, -0.03577097877860069, 0.08150763064622879, -0.06667687743902206, -0.079079769551754, -0.02737351506948471, 0.008539843373000622, 0.023966433480381966, -0.12105606496334076, 0.06860896199941635, -0.014840669929981232, -0.05599823594093323, 0.07628200948238373, 0.15815989673137665, 0.007847310043871403, -0.03433311730623245, -0.1061454638838768, 0.08466964960098267, 0.0354255847632885, 0.057911649346351624, -0.048301320523023605, -0.028917450457811356, 0.07536337524652481, -0.048608534038066864, -0.03836556151509285, -0.024597642943263054, 0.10721451044082642, -0.08121852576732635, 0.05950375273823738, -0.08973260223865509, 0.08849168568849564, -0.023178720846772194, 0.06233608350157738, -0.09831294417381287, -0.052211444824934006, 0.00019538561173249036, 0.05660874769091606, 0.019286077469587326, 0.11513302475214005, -0.09952026605606079, -0.023992031812667847, 0.003291126573458314]}, {"id": "694f11662ef7fd944bcee9e6", "user_id": "CarlFristam", "title": "Detecting and Preventing Money Laundering Using Deep ...", "text": "(IJACSA) International Journal of Advanced Computer Science and Applications,\nVol. 16, No. 6, 2025\n1 | P a g e\nwww.ijacsa.thesai.org\nDetecting and Preventing Money Laundering Using \nDeep Learning and Graph Analysis\nMAMUNUR R RAJA1, Md Anwar Hosen2, Md Farhad Kabir3, Sharmin Sultana4, Shah Ahammadullah Ashraf5, \nRakibul Islam6*\nMaster of Science in Information Technology (MSIT), Westcliff University, Irvine, CA, USA1\nCollege of Business, Westcliff University, Irvine, CA, USA2\nMarshall School of Business, University of Southern California, Los Angeles, USA3\nDept. of Business Administration and Management, International American University, Los Angeles, CA, USA4\nSchool of Business, International American University, Los Angeles, CA, USA5\nDept. of MBA in Business Analytics, International American University, Los Angeles, CA, United States6\nAbstract\u2014Money laundering is a major worldwide issue facing \nfinancial organizations, with its increasingly complicated and \nchanging methods. Conventional rule-based anti-money \nlaundering (AML) systems can fail to identify advanced \nfraudulent activity. This study shows a new hybrid model to detect \nsuspicious transaction patterns precisely by efficiently combining \nGraphSAGE, a graph-based Machine Learning (ML) technique, \nwith Long Short-Term Memory (LSTM) networks. The suggested \napproach uses GraphSAGE's relational capabilities for graph\u0002structured anomaly detection and the temporal strengths of \nLSTM for sequence modeling. With excessive traditional ML and \nstand-alone Deep Learning (DL) techniques, the Hybrid LSTM\u0002GraphSAGE model achieves an accuracy of 95.4% using a \nsimulated dataset reflecting real-world financial transactions. The \nfindings show how well our combined strategy lowers false \npositives and improves the identification of advanced AML \noperations. This work opens the path for creating real-time, \nintelligent, flexible money laundering detection systems \nappropriate for current financial situations.\nKeywords\u2014Anti-money laundering (AML); deep learning (DL);\nLSTM; GraphSAGE; graph analysis; transaction monitoring; \nhybrid fusion model\nI. INTRODUCTION\nIn the previous few years, money laundering and terrorism \nhave been among the main challenges to the integrity of the \nglobal financial system [1]. Money laundering issues the \nreliability of illegal activity by hiding its source; each year, the \nlaundering of around 2 to 5% of the world's GDP (1.7-4 trillion) \nleads to issues [2]. Underlying crimes include drug distribution, \nhuman trafficking, fraud, tax avoidance, and corruption. \nConsequently, money laundering is a serious worldwide issue \ninfluencing individuals, businesses, governments, and societal \nwelfare and impacting [3].\nFor financial institutions (FIs), undetectable money \nlaundering programs may cause significant reputation harm and \nconsiderable penalties. FIs use compliance professionals \nlooking at questionable activity to stay out of a vehicle for \nmoney laundering [4]. According to most rule-based algorithms \nand human monitoring, traditional AML systems struggle to \nkeep up with ever-advanced laundering procedures [5]. These \ntechniques often skip subtle, nonlinear developments in \ntransactional data or expose latent connections within multi\u0002layered financial networks\u2014a gap leaves organizations open to \nsystematic risk, reputational harm, and regulatory fines [6].\nAlthough nowadays, most methods concentrate on isolated \ntransaction analysis using shallow models like logistic \nregression or decision trees, recent developments in ML have \nshown promise in spotting aberrant financial activity [7]. These \napproaches ignore the essentially relational character of money \nlaundering, in which illegal activity is entwined in complex \nsystems of companies and transactions. The graph-based \nanalysis provides a strong prism to find these latent structures. It \nmaps links between accounts, beneficiaries, and intermediaries \n[8]. However, few researchers have successfully coupled graph \ntheory with DL to address financial crime's dynamic, high\u0002dimensional character [9].\nThis study concludes this gap by indicating a novel approach \ncombining graph analysis with DL to identify and terminate \nmoney laundering in real-time. Our method models \ntransactional networks using GNNs' hierarchical representation \nlearning ability, thereby capturing local node attributes and \nglobal topological patterns. We also provide a dynamic anomaly \ndetection system that continually updates network embeddings \nand improves risk ratings to fit changing laundering strategies.\nOur key contributions include:\n\uf02d This study provides a novel money laundering \ndetection method that combines graph-based \nanalytical structural insights with a DL model \ntemporal pattern recognition. This interaction helps \nthe system detect relational and sequential flaws in \nfinancial transactions.\n\uf02d Real-time transaction monitoring system design is a \nkey advancement. This system may identify \nsuspicious activity before it expands by continually \nrecording and analyzing transactions using past \nbehavioral patterns and changing network \narchitecture.\n\uf02d Recognizing a shortage of labeled AML data, we \ndevelop a careful and logical financial transaction \nset. This allows practical training and evaluation of \n(IJACSA) International Journal of Advanced Computer Science and Applications,\nVol. 16, No. 6, 2025\n2 | P a g e\nwww.ijacsa.thesai.org\nthe recommended models and reflects actual \nlaundering behavior.\n\uf02d This study thoroughly evaluates the hybrid model \nagainst traditional ML and stand-alone DL. Results \nshow that the hybrid model outperforms others in \ndetection accuracy, precision, recall, and false \npositive reduction.\nII.LITERATURE REVIEW\nThis study examines graph-based and hybrid DL models for \nAML, focusing on GCNs, CNNs, and new architectures like \nGAGNN and Temporal-GCN. Data availability, computational \ncost, and cross-domain transferability remain issues even with \nhigh accuracy and minimal false positives.\nBakhshinejad et al. [10] presented a graph-based DL model \nfor suspected money laundering transaction detection and a \nthorough analysis of current AML systems from a data-oriented \nstandpoint. Applied node2vec for feature extraction, created a \ndetection system converting transactional data into a graph, and \nthen classified transactions as usual or suspicious using a GCN. \nGraph embedding with GCN for classification, Node2Vec. They \nalso tuned classifier thresholds and managed unbalanced data \nusing SMOTE. Comparatively, to industry norms of 90% or \nmore, their model attained very low false negative rates, \nsometimes even nil, and significantly lowered the false alarm \nrate to around 50%.\nAlso, Irshad et al. [11] proposed a novel framework for \nidentifying money laundering activities by combining Graph \nConvolutional Networks (GCN), Convolutional Neural \nNetworks (CNN), and Feed-Forward Neural Networks (FFNN) \nin an Integrated Approach for Money Laundering Detection. \nUsing spatial patterns, sequential data, and transaction network \ntopology, the authors created a hybrid model to raise \nclassification performance. Their approach calls for CNN to \nextract local characteristics from transaction histories, GCN to \ncapture graph-based relations among entities, and FFNN for \nultimate classification. With an astounding 98.34%, the model \nexceeded conventional ML techniques. Likewise, Kute et al. [1] \nprovided an extensive CNN sentiment analysis application \noverview.\nThey evaluate current research publications using CNN \narchitectures for sentiment classification challenges in many \nfields and datasets. They gathered and analyzed more than 60 \nresearch studies, evaluating many CNN-based techniques,\nincluding hybrid models, multichannel CNNs, and \nimprovements in attention processes. They also examined \npreprocessing methods and dataset kinds used in this research.\nTheir stated accuracy falls between 75% and 90%, \ndepending on the architecture and dataset. CNN-based models \nwere better than conventional ML techniques in extracting \nspatial characteristics from text. Cheng et al. [12] suggested a \nfresh approach using group-aware deep graph learning methods \nfor AML. The authors model the financial transaction network\nas a heterogeneous graph, and they present a Group Aware \nGraph Neural Network (GAGNN) to detect suspicious group \nbehaviors often disregarded in conventional AML systems. \nTheir approach consists of building a heterogeneous transaction \ngraph, grouping based on shared characteristics (such as IP \naddresses), and using a tailored GNN architecture with group\u0002level elements for enhanced detection. Reaching an AUC of \n0.9814 and an F1 score of 0.8607, the suggested method shows \nperformance improvement over baseline models. Dumitrescu et \nal. [13] represented users or accounts and edges indicating \ntransactions, therefore investigating banking transaction data as \na graph of fraudulent activities. They devised a method to \nidentify structural and behavioral irregularities in the transaction \nnetwork using GNNs.\nUsing GNN models, especially Autoencoders and GCNs,\nthey train representations of the graph and spot suspicious \ntrends. Focusing on unsupervised methods, as tagged fraudulent \ndata is not readily available, they assessed their models using \nreal-world financial transaction data. Depending on the model \nand data setup, their method's stated accuracy in AUC (Area \nUnder the Curve) scores varied from 0.76 to 0.89. Eddin et al. \n[3] created dynamically via sliding time windows to help \npropose an ML triage model to lower false positives in AML \nsystems. Combining entity-centric characteristics with graph\u0002based features.\nUsing LightGBM on actual banking data, their approach \nreduced false positives by 80% and identified over 90% of \ngenuine positives. Furthermore, Jensen et al. [14] investigated \nusing ML and statistical techniques to fight money laundering, \nemphasizing using synthetic data to train prediction models. \nThey used synthetic data reflecting banking activities and \nconsumer characteristics to develop and evaluate their method. \nTo separate dubious from non-suspicious consumers, they used \na supervised learning approach using a gradient-boosted \ndecision tree algorithm (LightGBM).\nWith a fantastic accuracy of 99.6%, their model \ndemonstrated the possible efficiency of ML in spotting financial \nlaundering activity. Alarab et al. [15] employed a unique graph\u0002based model called Temporal-GCN, which combines GCN with \nLSTM, to identify illegal transactions in Bitcoin. They also \nincluded active learning using Monte-Carlo Dropout and \nMonte-Carlo Adversarial Attack (MC-AA) for uncertainty \nestimates and created a framework that catches both temporal \nsequences and graph topologies of transaction data.\nPreprocessing Bitcoin transaction graphs, extracting local \ncharacteristics, using LSTM to model temporal trends, and then \nfeeding the result to a TAGCN layer from the approach. The \noutperformance of the model above previous GCN-based \nmodels on the same dataset resulted in a classification accuracy \nof 97.77% and an F1-score of 80.6%. Muminovic et al. [16] \ninvestigated the difficulties of money laundering in the digital \nage, along with studies of contemporary technologies meant to \nimprove preventive systems.\nIt especially looks at how graph databases may monitor \nintricate, nonlinear financial transactions often used to hide \nillegal activity\u2014which are typically used to hide illegal activity. \nThe writers review current methods that mainly depend on \nrelational databases and rule-based detection, pointing to limits \nin scalability and adaptability.\nGraph-based models help see entities and their transactional \ninteractions more easily, enhancing the capacity to spot unusual \n(IJACSA) International Journal of Advanced Computer Science and Applications,\nVol. 16, No. 6, 2025\n3 | P a g e\nwww.ijacsa.thesai.org\ntrends. Mohan et al. [17] proposed a hybrid model combining \nEvolving Graph Convolutional Networks (EvolveGCN) with \nDeep Neural Decision Forests (DNDF) to handle AML in the \nBitcoin network.\nWith the Elliptic dataset comprising over 200,000 labeled \nand unlabeled Bitcoin transactions, they simulate the issue as a \nnode classification job. They want to improve the categorization \nof illegal transactions by combining dynamic graph learning \nwith ensemble techniques. Following Knowledge Distillation \n(KD) to compress and maximize the model, the model attained \na high F1 score of 0.9251, which then improved to 0.9525.\nMoreover, there is limited comparative analysis using \ntraditional methods in detecting and Preventing Money \nLaundering.\n1) Many models need synthetic datasets or large volumes of \nclassified transaction data, which are rare in financial\nenvironments. While transaction categorization is time\u0002consuming and error-prone, synthetic data lacks the complexity \nof real-world laundering techniques.\n2) Graph-based algorithms like GCN, GAGNN, and \nTemporal-GCN are resource-intensive in describing large,\ndynamic financial transaction networks. Training, feature \nextraction, and graph creation are computationally intensive.\n3) These models\u2019 efficacy slightly depends on group or \ngraph structure specifications and transaction data correctness \nand completeness. Models include unsupervised GNNs and \nGAGNNs that lose much in noisy, mislabeled, or poorly linked \ndata.\n4) Although many models perform well on specific\ndatasets, e.g., Bitcoin and private financial data, their \ntransferability across institutions, countries, and transaction \ntypes is poor. Applied to foreign fields, model performance is \nusually harmed.\nIII. METHODOLOGY\nA hybrid DL-based and graph-based analysis framework \nwas proposed to detect and prevent money laundering activities \neffectively. As shown in Fig. 1, raw transaction data is fed into \nthe pipeline throughout the methodology, producing final \nclassification outcomes. The design of this multi-stage \nframework is to extract temporal transactional and relational \npatterns, typically indicative of money laundering behavior.\nFig. 1. Methodology framework for detecting and preventing money laundering using the proposed hybrid LSTM-GraphSAGE model.\nA. Dataset Description\nFor this study, experiments are run using the Anti Money \nLaundering Transaction Data (SAML-D) on Kaggle by Berk \n\u00d6zta\u015f [18]. The dataset was specially developed to simulate real \nbanking transactions and behavioral patterns of money \nlaundering operations. The dataset contains 1,048,575 records of \ntransactions with 28 typologies (split between 11 normal and 17 \nsuspicious) and 12 different features: Time, Date, \nSender_account, Receiver_account, Amount, \nPayment_currency, Received_currency, Sender_bank_location, \nReceiver_bank. The dataset consists of each transaction record \nbetween a sender and a receiver on each row. \nPayment_currency, Received_currency, and Amount depict all \ntypes of currency used at the sender's and receiver's end, as well \nas the total monetary value of the transfer.\nRegarding transaction medium, the Payment_type would tell \nyou that it is an online transfer, credit card, or wire. After \nsupervised learning, the label Is_laundering is a critical binary \nfeature (1 for money laundering and 0 for legitimate). \nLaundering_type gives a multi-class annotation regarding \nlaundering techniques. The rich set of features allows for \ntemporal and relational modeling of temporal patterns of \nfinancial fraud.\nB. Dataset Preprocessing\nA series of robust preprocessing steps was implemented to \nprepare the dataset for DL and graph analysis models.\n1) Timestamp handling. The Date and Time features were \nmerged and transformed into a standard UNIX timestamp \nformat to assist temporal modeling. It does this feature \nengineering for time-based behaviors like peak transaction hours \nor clusters of frequency. By \ud835\udc37i and \ud835\udc47i let us denote the date and \ntime when \ud835\udc56 \ud835\udc61\u210e transaction occurs. As follows, the timestamp \nfeature \ud835\udc47\ud835\udc46i was derived:\n\ud835\udc47\ud835\udc46\ud835\udc56 = \ud835\udc61\ud835\udc5c_\ud835\udc61\ud835\udc56\ud835\udc5a\ud835\udc52\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5a\ud835\udc5d(\ud835\udc37\ud835\udc56 +\ud835\udc47\ud835\udc56)\n2) Account ID encoding. The Sender_account and \nReceiver_account are anonymized strings. They were labeled,\nencoded, or embedded to preserve identity without revealing \npersonal information. This later allows for building transaction \ngraphs where each unique account becomes a node:\n\ud835\udc46\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc52\ud835\udc5f\ud835\udc56 = \ud835\udc53(\ud835\udc46\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc52\ud835\udc5f_\ud835\udc4e\ud835\udc50\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61\ud835\udc56)\n(IJACSA) International Journal of Advanced Computer Science and Applications,\nVol. 16, No. 6, 2025\n4 | P a g e\nwww.ijacsa.thesai.org\n\ud835\udc45\ud835\udc52\ud835\udc50\ud835\udc52\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f\ud835\udc56 = \ud835\udc53(\ud835\udc45\ud835\udc52\ud835\udc50\ud835\udc52\ud835\udc56\ud835\udc63\ud835\udc52\ud835\udc5f_\ud835\udc4e\ud835\udc50\ud835\udc50\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61\ud835\udc56)\n3) Categorical feature encoding. For some payment \ninformation (Payment_currency, Received_currency, \nPayment_type, Sender_bank_location, \nReceiver_bank_location), those were one-hot encoded or \nembedded, based on the model. In this case, the transformation \nto capture the discrete attribute information does not introduce \nthe ordinal bias. For a categorical feature \ud835\udc4b with \ud835\udc58 unique \nvalues:\n\ud835\udc4b \u2208 {\ud835\udc651, \ud835\udc652 \u2026 \ud835\udc65\ud835\udc58\n} \u21d2 \ud835\udc42\ud835\udc5b\ud835\udc52 \u2212\u210e\ud835\udc5c\ud835\udc61(\ud835\udc4b) = [0,1,2, \u2026 ]\n4) Graph construction for network analysis.\nSender_account and Receiver_account were used as nodes and \ntransactions as edges in a directed transaction graph \ud835\udc3a = (\ud835\udc49,). \nAlso, each edge has attributes such as amount, time, payment \ntype, and binary labels for laundering. Optional aggregation was \nbased on the frequency or total amount of the edge weights:\n\ud835\udc64\ud835\udc56\ud835\udc57 = \u2211 \ud835\udc34\ud835\udc5a\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc61\ud835\udc61\n\ud835\udc61\u2208\ud835\udc47\ud835\udc56\ud835\udc57\n5) Label binarization and data splitting. The binary target \nfor classification is given by the Is_laundering column. Also, \nLaundering_type was encoded for multi-class classification or \nmore profound insight into techniques. This ensures label \nstratification and thus handles the class imbalance in the data.\nFinally, the dataset was split into training and testing subsets \nthrough an 80/20 ratio. This guaranteed that all the classes \nundergo the model evaluation phase, including classes that do \nnot undergo laundering.\nC. Models\nIn order to detect and prevent money laundering in financial \ntransaction systems, we proposed a hybrid DL framework that \nties the temporal behavior modeling and relational graph \nanalysis together, which captures the evolution of suspicious \nactivity with complex pattern development. Specifically, our \napproach is composed of three key parts: 1) an LSTM for \nlearning sequential behavioral characteristics, 2) a graph neural \nnetwork (GNN) based on GraphSAGE for modeling structural \nrelationships, and 3) a fusion model to synthesize the temporal \nand structural beneficial insights.\n1) Temporal behavior modeling using LSTM. Structured \nand repetitive behavior of money laundering schemes \ncommonly entails rapid distribution of funds through an account \nnetwork (smurfing) or calculating the best technique for the \nlayering (i.e., how to add coins to comply with the internal \nallowance of the broker). Because these are nuanced temporal \ndependencies, we leverage an LSTM network capable of \nmodeling sequential data with long-range dependencies. The \nLSTM branch in Fig. 2 extracts transaction sequences from an \naccounts perspective to capture behavioral anomalies.\nFig. 2. LSTM-based temporal feature extraction architecture.\nLet \ud835\udc4ba = {\ud835\udc65a,1, \ud835\udc65a,2,, \u2026, \ud835\udc65a, \ud835\udc47a} be the transaction sequence \nfor account \ud835\udc4e, and each transaction \ud835\udc65a,t \u2208 \ud835\udc45d is a vector of \nfeatures. The features include normalized transaction amount, \npayment type, time-based metadata (e.g., hour of day, day of \nweek), typology, currency mismatch, and geographical \ninformation (e.g., bank location).\nThe LSTM network operates on this sequence through a \nseries of gates and updates on internal memory according to the \nfollowing equations:\n(i) Forget Gate: \ud835\udc53\ud835\udc61 = \ud835\udf0e(\ud835\udc4a\ud835\udc53\ud835\udc65\ud835\udc61 + \ud835\udc48\ud835\udc53\u210e\ud835\udc61\u22121 + \ud835\udc4f\ud835\udc53)\n(ii) Input Gate: \ud835\udc56\ud835\udc61 = \ud835\udf0e(\ud835\udc4a\ud835\udc53\ud835\udc65\ud835\udc61 + \ud835\udc48\ud835\udc56\u210e\ud835\udc61\u22121 + \ud835\udc4f\ud835\udc56)\n(iii) Output Gate: \ud835\udc53\ud835\udc61 = \ud835\udf0e(\ud835\udc4a0\ud835\udc65\ud835\udc61 + \ud835\udc480\u210e\ud835\udc61\u22121 + \ud835\udc4f0)\n(iv) Candidate Memory: \ud835\udc50\u0303\ud835\udc61 = \ud835\udc61\ud835\udc4e\ud835\udc5b\u210e(\ud835\udc4a\ud835\udc50\ud835\udc65\ud835\udc61 + \ud835\udc48\ud835\udc50\u210e\ud835\udc61\u22121 + \ud835\udc4f\ud835\udc50)\n(v) Cell State Update:\ud835\udc50\ud835\udc61 = \ud835\udc53\ud835\udc50\ud835\udee9\ud835\udc50\ud835\udc61\u22121 +\ud835\udc56\ud835\udc61\ud835\udee9\ud835\udc50\u0303\ud835\udc61\n(vi) Hidden State: \u210e\ud835\udc61 = \ud835\udc5c\ud835\udc61\ud835\udee9\ud835\udc61\ud835\udc4e\ud835\udc5b\u210e(\ud835\udc50\ud835\udc61\n)\nWe denoted \ud835\udf0e to be the sigmoid activation function, tanh to \nbe the hyperbolic tangent function, and \u2299 to denote \nelementwise multiplication. The contextual behavior of account \n\ud835\udc4e at time \ud835\udc61is encapsulated in \u210e\ud835\udc61 as both current transaction \nfeatures and past behavioral history. The final hidden state \u210e\ud835\udc47 is \npassed through a fully connected dense layer with a sigmoid \nactivation to classify the suspiciousness of the account through \nbehavioral analysis: \n\ud835\udc66\u0302\ud835\udc4e = \ud835\udf0e(\ud835\udc640\u210e\ud835\udc47 + \ud835\udc4f0)\nThe binary cross-entropy loss function is used to optimize \nthe LSTM model:\n\ud835\udc3f\ud835\udc3f\ud835\udc46\ud835\udc47\ud835\udc40 = \u2212\ud835\udc66\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc66\u0302)\u2212 (1 \u2212 \ud835\udc66)log(1 \u2212 \ud835\udc66\u0302)\nThis formulation can learn from genuine and fraudulent \nbehavioral sequences and effectively identifies time-sensitive \nlaundering patterns.\n(IJACSA) International Journal of Advanced Computer Science and Applications,\nVol. 16, No. 6, 2025\n5 | P a g e\nwww.ijacsa.thesai.org\n2) Graph-based relational modeling using GraphSAGE.\nBehavioral patterns give us some clues as to when things \nhappened, but many money laundering schemes are networks \nconsisting of many, possibly thousands, of accounts, and the \nconnections among them are equally complex. Indirect transfers, \ncircular money flows, and multi-hop layering are typical ways \nthat launderers try to forfeit the trail of illegal money. The \nproblem could be captured as a directed graph where the nodes \nrepresent the accounts, and the edges between the nodes indicate\ntransactions between accounts.\nSuppose this transaction graph to be represented by \ud835\udc3a = (\ud835\udc49, \n\ud835\udc38), where:\n\uf02d The set contains N resources equal to \ud835\udc49, where each \nnode (account) in \ud835\udc49 is unique.\n\uf02d The set of directed edges, \ud835\udc38, will represent \ntransactions.\n\uf02d Edge features consist of transaction amount, \ntransaction type, time interval between transactions, \nand currency mismatch for each edge \ud835\udc52\ud835\udc62\ud835\udc63\u2208 \ud835\udc38\nbetween node \ud835\udc62 and node \ud835\udc63.\nFor each node \ud835\udc63 \u2208 \ud835\udc49, we initialize \u210e\ud835\udc63, the feature vector for \nnode \ud835\udc63, as a feature vector of the form, comprising:\n\uf02d Mean, max, and count of transaction amounts \n(aggregated statistics).\n\uf02d Frequency metrics.\n\uf02d Some categorical features can be embedded (e.g., \ntypology, payment type).\n\uf02d And optionally, the output of the LSTM model.\nFor learning meaningful node embeddings over its \nneighborhood structure, we adopted GraphSAGE, an inductive \nGNN framework that can generalize to node discovery. Layer\u0002wise, the node embedding is updated using:\n\u210e\ud835\udc41(\ud835\udc63)\n(\ud835\udc58) = \ud835\udc34\ud835\udc3a\ud835\udc3a\ud835\udc45\ud835\udc38\ud835\udc3a\ud835\udc34\ud835\udc47\ud835\udc38(\ud835\udc58)\n({\u210e\ud835\udc62\n(\ud835\udc58\u22121)\n|\ud835\udc62\ud835\udf16\ud835\udc41(\ud835\udc63)})\n\u210e\ud835\udc63\n(\ud835\udc58) = \ud835\udf0e(\ud835\udc4a(\ud835\udc58)\n. \ud835\udc36\ud835\udc42\ud835\udc41\ud835\udc36\ud835\udc34\ud835\udc47(\u210e\ud835\udc63\n(\ud835\udc58\u22121)\n, \u210e\ud835\udc41(\ud835\udc63)\n(\ud835\udc58)\n))\nThe neighbors of node \ud835\udc63 are shown here by the notation (\ud835\udc63), \nand AGGREGATE is a differentiable function like mean, max\u0002pooling, or LSTM-based spreading. After \ud835\udc3e layers, the final \nnode embedding \u210e\ud835\udc63 \ud835\udc3e is computed and gives the structural \ncontext of account \ud835\udc63. Finally, the final node embeddings are \nclassified with a sigmoid-activated dense layer:\n\ud835\udc66\u0302\ud835\udc63 = \ud835\udf0e(\ud835\udc4a\ud835\udc50\u210e\ud835\udc63\n\ud835\udc58 + \ud835\udc4f\ud835\udc50)\nIt enables us to create a suspiciousness score for each \naccount by comparing its transactional connections with other \naccounts. We extended this in practice by assigning sender and \nreceiver embeddings and edge features simultaneously.\n3) Fusion model. Combining Temporal and Relational \nKnowledge, we recognized that the temporal and structural \nfeatures give complementary information and thus designed a \nhybrid fusion model that combines the outputs from the LSTM \nand GNN branches. Such a combination helps the model detect \nsophisticated money laundering tactics that may transpire \nthrough behavioral anomalies and relational inconsistencies. \nFig. 3 depicts the overall architecture of such a system as a single \nhybrid fusion model that combines the sequential and relational \nlearning components to perform comprehensive AML detection.\nFig. 3. Architecture of the proposed hybrid fusion model for money \nlaundering detection.\nWe compute a fused feature representation for each account \n\ud835\udc63 by concatenating its final LSTM hidden state \u210e(\ud835\udc63) with the \ngraph embedding of that account \u210e\ud835\udc63\ud835\udc3e:\n\ud835\udc67\ud835\udc63 = \ud835\udc36\ud835\udc42\ud835\udc41\ud835\udc36\ud835\udc34\ud835\udc47(\u210e\ud835\udc47\n(\ud835\udc63)\n, \u210e\ud835\udc63\n\ud835\udc3e)\nThe MLP with nonlinear activation functions (e.g., ReLU) \nand dropout regularization is applied on this fused vector \ud835\udc67\ud835\udc63. \nFinally, the following is given as the final classification:\n\ud835\udc66\u0302\ud835\udc63 = \ud835\udf0e(\ud835\udc4a\ud835\udc53\ud835\udc67\ud835\udc63 + \ud835\udc4f\ud835\udc53)\nWe defined a joint loss function to train this end-to-end \narchitecture from two parts of the loss functions in the LSTM \nand GNN models:\n\ud835\udc3f\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59 = \u03bb1\ud835\udc3f\ud835\udc3f\ud835\udc46\ud835\udc47\ud835\udc40 + \u03bb2\ud835\udc3f\ud835\udc3a\ud835\udc41\ud835\udc41 + \u03bb3\ud835\udc3f\ud835\udc39\ud835\udc62\ud835\udc60\ud835\udc56\ud835\udc5c\ud835\udc5b\nHere, \ud835\udf061, \ud835\udf062, \ud835\udf063 are hyperparameters that control the \ncontribution of each loss term. All the model portions are trained \nusing the Adam optimizer with early stopping and validation\u0002based performance monitoring.\nIV. RESULT AND DISCUSSION\nA. Performance Evaluation\nIn order to evaluate the effectiveness of various models in \npredicting money laundering activities, we performed a deep \nanalysis of classification metrics, namely accuracy, precision, \nrecall, and F1-score. The LSTM baseline model, as summarized \nin Table I, resulted in an accuracy of 91.5%, precision of 89.4%, \nrecall of 90.2%, and F1-score of 89.8%. This indicates a \nrelatively strong capability in temporal pattern recognition, \nwhich is necessary for sequential transaction data. Yet, across \nall metrics, the LSTM model performed worse compared to the \nGraphSAGE model, which is a devised model to make full use \nof topological and relational patterns in transaction graphs, due \nto achieving 92.8%, 91.1%, 91.8%, and an F1-score of 91.4%. \n(IJACSA) International Journal of Advanced Computer Science and Applications,\nVol. 16, No. 6, 2025\n6 | P a g e\nwww.ijacsa.thesai.org\nImprovements indicate that capturing relationships in graph \ndimensions is important, given that such flows tend to have gone \nthrough interconnected accounts and richly interlinked \nnetworks.\nTABLE I DIFFERENT PERFORMANCE METRICS FOR VARIOUS MODELS IN \nMONEY LAUNDERING DETECTION\nModel Accuracy \n(%)\nPrecision \n(%)\nRecall \n(%)\nF1-\nscore \n(%)\nLSTM 91.5 89.4 90.2 89.8\nGraphSAGE 92.8 91.1 91.8 91.4\nProposed \nHybrid LSTM \nGraphSAGE\n95.4 93.2 93.8 93.5\nMoreover, the proposed Hybrid LSTM-GraphSAGE model \noutperformed the individual ones significantly with 95.4 % \naccuracy, 93.2 % precision, 93.8 % recall, and a robust F1-score \nof 93.5 %. This synergy of alternating structural learning with \ntemporal dependencies expressed by LSTM indicates that \nincorporating temporal dependencies from LSTM contributes to \nincreasing GraphSAGE's performance.\nThis hybrid model not only improves detection capabilities \ndue to discriminative temporal and topological patterns as well \nas balance across all key evaluation metrics, but it also \noutweighs competitors across all metrics by about 17.8% across \ngroup operation and 46.3% in total execution time. Combining \nsequence modeling and graph-based learning confirms that one \ncan achieve a deeper, more accurate understanding of money \nlaundering detection.\nB. Training and Validation Performance Analysis\nTo further validate the robustness of the proposed Hybrid \nLSTM-GraphSAGE model on the learning behavior and \ngeneralization capability, we looked at the training and \nvalidation performance at 50 epochs. Fig. 4 shows the \ndevelopment of the training and validation accuracy. Both \naccuracy curves have a steep (learn quickly) upward trajectory \nin the first few epochs.\nThe model improves steadily with training and has a training \naccuracy of around 98% and a validation accuracy of about 95%. \nIn the later epochs, this shows that these two curves are \nconverging, meaning the model has no overfitting and is very \nwell generalizing to unseen data.\nFig. 4. Training and validation accuracy of the proposed hybrid fusion model.\nFig. 5. Training and validation loss of the proposed hybrid fusion model.\nFig. 5 shows training and validation loss curves. As we can \nsee during the initial training phase, the loss values experience a \nsharp decline for both losses, which means we have successfully \nlearned key patterns in our dataset. The training loss decreases \nsteadily to below 0.1, while the validation loss converges to \naround 0.2, with no apparent signs of divergence. This stable \nconvergence behavior further reinforces the robustness of the \nproposed hybrid fusion architecture, which integrates temporal \nand structural learning components.\nLastly, the overall training and validation performance \nanalysis shows that the proposed model is well optimized and \nfree from major problems such as the issue of underfitting, \noverfitting, and so on, which makes it a good candidate for \nimplementation in a money laundering detection system in the \nreal world.\nC. Error Analysis\nThe given classification performance was also analyzed at \nthe level of error using the confusion matrix, as shown in Fig. 6, \nto fully understand the detection performance of the proposed \nHybrid LSTM-GraphSAGE model. The matrix gives some \ninsight into the number of correct and wrong predictions of the \ntransaction, either legitimate or money laundering. In a total of \npredictions, the model made 100,173 correct fraud (True \nPositives) and 99,895 correct legitimate predictions (True \nNegatives). However, 4799 of these were incorrectly classified \nas fraudulent (False Positive (FP), and 4688 as legitimate (False \nNegative (FN)).\nFig. 6. Confusion matrix for the proposed hybrid fusion model in detecting \nmoney laundering.\n(IJACSA) International Journal of Advanced Computer Science and Applications,\nVol. 16, No. 6, 2025\n7 | P a g e\nwww.ijacsa.thesai.org\nNevertheless, with a large dataset and a common class \nimbalance found in financial datasets, the proposed model \nachieved a high level of predictive accuracy with tolerable \nmargins of error. It is imperative in financial systems, where \nbeing flagged as a fraudulent user when it is not could raise \ncustomer irritation or unnecessary investigation on legitimate \nusers. However, the small number of false negatives guarantees \nthat almost all illicit activities are flagged for awareness. It \nshows that the hybrid model is very good at discriminating \nbetween normal and suspicious behaviors.\nD. ROC Curve and AUC Analysis\nThe Receiver Operating Characteristic (ROC) curve and \ncorresponding AUC give a graphical and quantitative way to \nmeasure model performance at different threshold settings. The \nROC curves of the LSTM, the GraphSAGE, and the proposed \nHybrid LSTM-GraphSAGE are plotted with a random guess \nperformance baseline (Fig. 7).\nThis LSTM model performs strongly in capturing sequential \ndependencies in the transaction data by achieving an AUC of \n0.94. LSTM slightly underperformed GraphSAGE with an AUC \nof 0.95 because GraphSAGE was able to learn structural \npatterns in the transaction network. Despite that, the proposed \nHybrid LSTM-GraphSAGE model achieves the best AUC of \n0.97 compared with individual models. By combining temporal \nand topological learning, the strength of this improvement \nsuggests that combining temporal and topological learning \nenables the model to achieve better discrimination for positive \n(money laundering) compared to negative (legitimate) classes \nfor all threshold levels.\nFig. 7. ROC curves for different models in detecting money laundering.\nThe ROC curve of the hybrid model is even steeper and more \npronounced towards the top left corner, which further validates \nthe robustness and reliability of the hybrid model. This model \ncan effectively solve the real-world financial anomaly detection \nproblem due to its high true positive rate and low false positive \nrate.\nE. Comparative Analysis\nThe performance of the proposed Hybrid \nLSTMGraphSAGE model was also compared to existing \napproaches from prior literature in terms of effectiveness, for \nwhich AUC was used as a measurement. According to the \ninformation provided in Table II, Labanca et al. followed a \nRandom Forest approach, yielding an AUC of 0.90, and Alotibi \net al. used a Na\u00efve Bayes classifier, which achieved again an \nAUC of 0.90. In the same way as Jullum et al., they used an \nXGBoost model and reported an AUC of 0.90. While these \nmodels are somewhat effective, they rely on classical ML \ntechniques, which do not maximize the expensive structures of \ntime and relationships involved in money laundering schemes.\nTABLE II COMPARATIVE ANALYSIS OF THE PROPOSED HYBRID FUSION \nMODEL WITH PREVIOUS RESEARCH BASED ON AUC VALUES\nReference Model AUC\n[19] Random Forest 0.9\n[20] Na\u00efve Bayes 0.9\n[21] XGBoost 0.9\nProposed LSTM-GraphSAGE 0.97\nCompared to such stated methods, the proposed Hybrid \nLSTM-GraphSAGE model achieved a substantially higher \nAUC of 0.97, which is better than 0.07 for each of the \naforementioned methods. In other words, we achieve a 7% \nrelative increase in AUC performance. The improvement shows \nthat such a hybrid model can better distinguish suspicious from \neveryday financial transactions through the sequential power \nlearning of LSTM while keeping a sense of the local structure \nprovided by GraphSAGE. Our proposed approach effectively \ncaptures temporal patterns and intra-account dependencies and \nprovides a more holistic and stronger money laundering \ndetection framework than the existing traditional models can \noffer.\nV.CONCLUSION\nThis study presents a strong and intelligent hybrid model \ncombining GraphSAGE, a graph-based ML method that \ncaptures complex interactions between entities, with LSTM for \nsequential data processing. With a high accuracy of 95.4%, the \nmodel effectively identifies anomalous and suspicious financial \ntransactions that may imply money laundering by combining \nthese two techniques, outperforming standard AML detection \nmethods. The proposed framework can detect direct \ntransactional disruptions and invisible patterns in complicated\nfinancial networks, supporting scalable AML behaviors. \nParticularly in fields like financial fraud, where temporal and \nrelational data are crucial, our study shows the great benefits of \nmerging DL with graph analysis. Applying the model to real\u0002world banking data would help to improve its efficacy even \nmore in the future as it would enable testing of its \ngeneralizability and operational robustness. Incorporating \nExplainable AI (XAI) techniques will also raise regulatory \nacceptability and openness, allowing financial institutions to \ntrust the system's selections. Future improvements may also \ninclude allowing cross-border transaction monitoring to address \nworldwide money laundering methods and modeling multi-layer \ntransactional graphs reflecting deeper linkages between \nconsumers, intermediaries, and external networks. Finally, \nimplementing this system in real-time surroundings with \nadaptive learning features and feedback systems would be a \nmajor step towards an intelligent AML infrastructure for the \nfuture generation.\n(IJACSA) International Journal of Advanced Computer Science and Applications,\nVol. 16, No. 6, 2025\n8 | P a g e\nwww.ijacsa.thesai.org\nDISCLOSURE AND CONFLICT OF INTEREST\nThe author declares that there are no conflicts of interest \nrelated to this research. Additionally, the author has no financial \ninterests or competing affiliations that could have influenced the \nstudy's design, execution, or findings. This manuscript is the \nauthor's original work and has not been previously published or \nsubmitted for review to any other journal or conference.\nREFERENCES\n[1] D. V. Kute, B. Pradhan, N. Shukla, and A. Alamri, \"Deep Learning and \nExplainable Artificial Intelligence Techniques Applied for Detecting \nMoney Laundering-A Critical Review,\" IEEE Access, vol. 9, pp. 82300\u2013\n82317, 2021, doi: 10.1109/ACCESS.2021.3086230.\n[2] K. Lannoo and R. Parlour, \"Anti-Money Laundering in the EU: Time to \nget serious,\" ECRI Papers, 2021, Accessed: Apr. 08, 2025. [Online]. \nAvailable: https://ideas.repec.org/p/eps/ecriwp/31980.html.\n[3] A. N. Eddin et al., \"Anti-Money Laundering Alert Optimization Using \nMachine Learning with Graphs,\" Dec. 2021, Accessed: Apr. 08, 2025. \n[Online]. Available: https://arxiv.org/abs/2112.07508v3.\n[4] B. Basaran-Brooks, \"Money laundering and financial stability: does \nadverse publicity matter?,\" Journal of Financial Regulation and \nCompliance, vol. 30, no. 2, pp. 196\u2013214, Mar. 2022, doi: 10.1108/JFRC\u000209- 2021-0075/FULL/XML.\n[5] G. Kaur, \"Trust the Machine and Embrace Artificial Intelligence (AI) to \nCombat Money Laundering Activities,\" pp. 63\u201381, 2024, doi: \n10.1007/978-981- 99-5354-7_4.\n[6] V. Shehu and A. Aliu, \"Applied Machine Learning on Anti Money \nLaundering System-The case of National Bank of North Macedonia \nMentor: Student: Applied Machine Learning on Anti Money Laundering \nSystem-The case of National Bank of North Macedonia,\" 2024.\n[7] Z. Chen, L. D. Van Khoa, E. N. Teoh, A. Nazir, E. K. Karuppiah, and K. \nS. Lam, \"Machine learning techniques for anti-money laundering (AML) \nsolutions in suspicious transaction detection: a review,\" Knowl Inf Syst, \nvol. 57, no. 2, pp. 245\u2013285, Nov. 2018, doi: 10.1007/S10115-017-1144-\nZ/METRICS.\n[8] H. Huong, X. Nguyen, T. K. Dang, and P. T. TranTruong, \"Money \nLaundering Detection Using A Transaction-Based Graph Learning \nApproach,\" Proceedings of the 2024 18th International Conference on \nUbiquitous Information Management and Communication, IMCOM \n2024, 2024, doi: 10.1109/IMCOM60618.2024.10418307.\n[9] F. Wan and P. Li, \"A Novel Money Laundering Prediction Model Based \non a Dynamic Graph Convolutional Neural Network and Long Short\u0002Term Memory,\" Symmetry 2024, Vol. 16, Page 378, vol. 16, no. 3, p. 378, \nMar. 2024, doi: 10.3390/SYM16030378.\n[10] Maciej Serda et al., \u201cA Graph-Based Deep Learning Model for Anti\u0002Money Laundering,\u201d Uniwersytet \u015bl\u0105ski, vol. 7, no. 1, pp. 343\u2013354, Aug. \n2023, doi: 10.2/JQUERY.MIN.JS.\n[11] F. Irshad, T. Alkhalifah, F. Alturise, and Y. D. Khan, \"GCF-MLD: \nIntegrated Approach for Money Laundering Detection using Machine \nLearning and Graph Network Analysis,\" IEEE Access, 2024, doi: \n10.1109/ACCESS.2024.3510115.\n[12] D. Cheng, Y. Ye, S. Xiang, Z. Ma, Y. Zhang, and C. Jiang, \"Anti-Money \nLaundering by Group-Aware Deep Graph Learning,\" IEEE Trans Knowl \nData Eng, vol. 35, no. 12, pp. 12444\u201312457, Dec. 2023, doi: \n10.1109/TKDE.2023.3272396.\n[13] B. Dumitrescu, A. Baltoiu, and S. Budulan, \"Anomaly Detection in \nGraphs of Bank Transactions for Anti Money Laundering Applications,\"\nIEEE Access, vol. 10, pp. 47699\u201347714, 2022, doi: \n10.1109/ACCESS.2022.3170467.\n[14] R. I. T. Jensen and A. Iosifidis, \"Fighting Money Laundering With \nStatistics and Machine Learning,\" IEEE Access, vol. 11, pp. 8889\u20138903, \n2023, doi: 10.1109/ACCESS.2023.3239549.\n[15] I. Alarab and S. Prakoonwit, \"Graph-Based LSTM for Anti-money \nLaundering: Experimenting Temporal Graph Convolutional Network \nwith Bitcoin Data,\" Neural Process Lett, vol. 55, no. 1, pp. 689\u2013707, Feb. \n2023, doi: 10.1007/S11063-022- 10904-8/TABLES/5.\n[16] A. Muminovic and F. Halili, \"Money Laundering Prevention in the Digital \nAge: Leveraging Graph Databases for Effective Solutions,\" International \nJournal of Natural and Technical Sciences (IJTNS), vol. 4, no. 1, pp. 1\u2013\n10, 2024, doi: 10.69648/AOAL9594.\n[17] A. Mohan, K. P.V, P. Sankar, K. Maya Manohar, and A. Peter, \n\"Improving anti-money laundering in bitcoin using evolving graph \nconvolutions and deep neural decision forest,\" Data Technologies and \nApplications, vol. 57, no. 3, pp. 313\u2013329, May 2023, doi: 10.1108/DTA\u000206-2021-0167/FULL/PDF.\n[18] B. Oztas, D. Cetinkaya, F. Adedoyin, M. Budka, H. Dogan, and G. Aksu, \n\"Enhancing Anti-Money Laundering: Development of a Synthetic \nTransaction Monitoring Dataset,\" Proceedings - 2023 IEEE International \nConference on e-Business Engineering, ICEBE 2023, pp. 47\u201354, 2023, \ndoi: 10.1109/ICEBE59045.2023.00028.\n[19] D. Labanca, L. Primerano, M. MarklandMontgomery, M. Polino, M. \nCarminati, and S. Zanero, \"Amaretto: An Active Learning Framework for \nMoney Laundering Detection,\" IEEE Access, vol. 10, pp. 41720\u201341739, \n2022, doi: 10.1109/ACCESS.2022.3167699.\n[20] J. Alotibi, B. Almutanni, T. Alsubait, H. Alhakami, and A. Baz, \"Money \nLaundering Detection using Machine Learning and Deep Learning,\"\nIJACSA) International Journal of Advanced Computer Science and \nApplications, vol. 13, no. 10, p. 2022, Accessed: Apr. 08, 2025. [Online]. \nAvailable: www.ijacsa.thesai.org.\n[21] M. Jullum, A. L\u00f8land, R. B. Huseby, G. \u00c5nonsen, and J. Lorentzen, \n\"Detecting money laundering transactions with machine learning,\"\nJournal of Money Laundering Control, vol. 23, no. 1, pp. 173\u2013 186, Jan. \n2020, doi: 10.1108/JMLC-07-2019- 0055/FULL/PDF.", "embedding": [-0.049795351922512054, 0.017757048830389977, -0.043265871703624725, -0.025204990059137344, 0.057494040578603745, -0.033073924481868744, 0.038285620510578156, -0.02103421650826931, 0.06279570609331131, -0.0020460919477045536, 0.017274610698223114, 0.01235003862529993, 0.05517426133155823, 0.01715718023478985, -0.014509999193251133, -0.03668627887964249, 0.009531350806355476, -0.02584771439433098, -0.10327757149934769, -0.04867757111787796, -0.0014586616307497025, -0.10210154950618744, -0.05355095490813255, -0.014634250663220882, -0.01781274378299713, 0.0391794815659523, -0.01687447912991047, -0.038414228707551956, -0.02204974927008152, -0.04194978252053261, 0.06478019803762436, 0.09821513295173645, -0.036251917481422424, 0.06525937467813492, -0.03243739530444145, -0.046832744032144547, -0.022334711626172066, 0.02667670138180256, 0.0669402927160263, 0.0195015836507082, 0.02989434264600277, -0.06715701520442963, -0.02345225028693676, 0.02596220187842846, 0.02969171106815338, -0.030628811568021774, -0.013053985312581062, 0.06819777190685272, -0.022066930308938026, 0.03908280283212662, -0.11285275220870972, -0.030106142163276672, 0.00936923734843731, 0.07750510424375534, -0.040092017501592636, -0.05659572035074234, 0.05811047554016113, -0.0428975448012352, -0.044125307351350784, -0.055984508246183395, 0.051180168986320496, 0.013384440913796425, 0.040271855890750885, 0.0017521294066682458, 0.005791218485683203, -0.000386888044886291, -0.06193132698535919, 0.07711918652057648, -0.006678542587906122, 0.036653872579336166, 0.08001545816659927, -0.01094093732535839, -0.12882781028747559, 0.06910436600446701, -0.012786920182406902, 0.02265237644314766, 0.017625262960791588, 0.031058430671691895, -0.02271675318479538, -0.04059729725122452, 0.022647321224212646, 0.031227540224790573, -0.025153566151857376, -0.040108468383550644, 0.017416467890143394, -0.0013897771714255214, -0.04986784979701042, -0.03585667163133621, 0.05619387701153755, 0.0006548240780830383, -0.03210122883319855, 0.021224817261099815, 0.07367667555809021, -0.09125788509845734, 0.07682225108146667, -0.010852880775928497, 0.015003017149865627, 0.026193002238869667, 0.0927433967590332, 0.03175807371735573, 0.010779823176562786, 0.07676471024751663, -0.02842867746949196, -0.06369441002607346, 0.021819300949573517, 0.000972513749729842, 0.0444553978741169, 0.05431043356657028, 0.028113339096307755, -0.028656721115112305, -0.04578583315014839, 0.06155191361904144, 0.02263936772942543, -0.06702032685279846, 0.05768594145774841, 0.00127371062990278, -0.007397147826850414, 0.04506034031510353, -0.06643401831388474, 0.08601022511720657, -0.012715213000774384, 0.09988401085138321, -0.009510485455393791, -0.031560394912958145, -0.019618699327111244, -0.021677648648619652, -0.14659088850021362, 1.1321498333456388e-33, -0.059171535074710846, 0.013263912871479988, -0.01703263260424137, -0.04117600992321968, -0.046696409583091736, 0.03064383938908577, -0.09815169870853424, -0.0015769611345604062, 0.010166714899241924, 0.1145068034529686, -0.09228736162185669, 0.09682592004537582, 0.0060805026441812515, 0.0518660768866539, 0.05217141658067703, 0.03119797073304653, 0.035649482160806656, 0.009391902014613152, 0.03332900628447533, -0.06396068632602692, 0.09940584003925323, -0.11428998410701752, 0.017196174710989, -0.0033379129599779844, 0.018439881503582, 0.06548355519771576, -0.017707666382193565, 0.07066904008388519, 0.12469059228897095, 0.018520662561058998, 0.028512684628367424, -0.03592605143785477, 0.03523869439959526, 0.07480809837579727, 0.028939994052052498, -0.032166674733161926, -0.0972733348608017, -0.02477414347231388, 0.01327798143029213, -0.08013226091861725, -0.13098983466625214, -0.031208405271172523, -0.007298789452761412, 0.01064668782055378, -0.03801910951733589, 0.12981082499027252, -0.03443152830004692, -0.0049706073477864265, -0.027782050892710686, -0.023420169949531555, 0.04604052007198334, -0.012873071245849133, 0.015372048132121563, -0.028420506045222282, -0.04789372533559799, 0.017511220648884773, 0.004785476718097925, -0.025837594643235207, -0.02287307195365429, 0.027167899534106255, 0.04275308549404144, -0.0037886297795921564, -0.13080079853534698, 0.0931701809167862, -0.07387769967317581, -0.016523169353604317, 0.055094778537750244, 0.0435953326523304, 0.04858626797795296, -0.03576347976922989, 0.04176037013530731, 0.0901782438158989, 0.03824128210544586, 0.04456690326333046, 0.021664582192897797, -0.07628024369478226, 0.08235494047403336, 0.09551871567964554, -0.016853678971529007, -0.0036603687331080437, -0.046290796250104904, -0.032328762114048004, 0.10127218067646027, 0.01066732406616211, -0.09196417033672333, 0.031943246722221375, 0.040173232555389404, -0.0372326597571373, -0.03424740582704544, 0.026967737823724747, -0.010136592201888561, 0.008391107432544231, -0.04406177997589111, 0.10188925266265869, 0.03244250267744064, -4.810880710079096e-33, -0.03283115103840828, 0.031225426122546196, 0.02946760132908821, -0.07542094588279724, -0.013087390922009945, 0.03248255327343941, 0.0009717423235997558, -0.07194724678993225, 0.019131962209939957, -0.009355518035590649, -0.07017554342746735, -0.09279511868953705, 0.015531941317021847, -0.030637487769126892, 0.013904291205108166, -0.049200642853975296, 0.07822628319263458, 0.0018269818974658847, -0.017361942678689957, 0.0012472253292798996, -0.01999996416270733, 0.03869369253516197, -0.04283541068434715, -0.015245068818330765, 0.006898263934999704, 0.002737626899033785, -0.003298216499388218, -0.029559778049588203, -0.04246995970606804, 0.10170438885688782, -0.029882915318012238, 0.04257030412554741, -0.04128481447696686, 0.00350751681253314, -0.09266186505556107, -0.0398557223379612, -0.007907567545771599, -0.05107676237821579, -0.004149363376200199, -0.03945482149720192, 0.004946481436491013, 0.06316661089658737, -0.10044478625059128, -0.021989446133375168, -0.07693042606115341, 0.012811512686312199, -0.04464343190193176, 0.03627461567521095, 0.07774047553539276, -0.03879807889461517, -0.0019446152728050947, -0.012419328093528748, 0.06919802725315094, -0.004105681087821722, -0.028913358226418495, 0.10532235354185104, 0.06943880021572113, -0.039647676050662994, -0.01205154974013567, 0.03169305622577667, -0.05542921647429466, 0.033488593995571136, -0.021181894466280937, 0.04660575091838837, 0.0023207312915474176, -0.023769667372107506, 0.028667647391557693, 0.023187460377812386, 0.019154580309987068, -0.020078303292393684, 0.03905386105179787, -0.03027377463877201, -0.06539636850357056, 0.006664028856903315, 0.03902619704604149, 0.003020151983946562, -0.06542152166366577, -0.06180029362440109, -0.04759968817234039, -0.019526418298482895, 0.09302572906017303, -0.053931646049022675, 0.03403414413332939, 0.045928895473480225, 0.02757323905825615, -0.044499244540929794, -0.043198853731155396, 0.025744814425706863, 0.03644175827503204, 0.00743747316300869, -0.029545234516263008, -0.056231409311294556, -0.07151302695274353, -0.0018325968412682414, -0.06158548593521118, -4.848289592018773e-08, -0.07394464313983917, -0.049211833626031876, 0.0669718012213707, 0.02240535244345665, 0.06239503622055054, 0.015998458489775658, -0.03714948520064354, 0.06608608365058899, -0.005023595876991749, 0.012073751538991928, 0.031046224758028984, -0.06961632519960403, -0.08735702186822891, -0.06471576541662216, -0.03856844827532768, -0.04086527228355408, 0.012208756059408188, -0.05620332062244415, -0.0070852600038051605, 0.044615738093853, -0.03897267207503319, 0.025584552437067032, -0.03476004675030708, 0.0017171790823340416, 0.032500702887773514, -0.1428920179605484, -0.04163651168346405, 0.10785390436649323, 0.04344348981976509, 0.054222576320171356, -0.047285448759794235, 0.009061608463525772, -0.016629517078399658, 0.004949586000293493, -0.07893528044223785, 0.05409354716539383, 0.049383219331502914, -0.03616692125797272, -0.09904071688652039, 0.030835455283522606, -0.021563420072197914, 0.07077320665121078, -0.009181497618556023, -0.018571853637695312, 0.0024546028580516577, -0.06778384745121002, -0.10388429462909698, -0.02225215546786785, 0.09068231284618378, -0.09453010559082031, 0.0035874706227332354, -0.054031431674957275, 0.08140505850315094, 0.042193420231342316, 0.03927404060959816, -0.01830529421567917, 0.009057140909135342, 0.042274732142686844, 0.022781966254115105, 0.04510185122489929, 0.09935133159160614, -0.1042247787117958, 0.04270698130130768, 0.013211122713983059]}, {"id": "694f11792ef7fd944bcee9e7", "user_id": "CarlFristam", "title": "Research on anti-money laundering technology based ...", "text": "| |\n| --- |\n\nACCESS THE FULL ARTICLE\n\nNo SPIE Account? [Create one](https://spie.org/account/create/accountinfo)\n\n;\n\n[ADD TO CART](https://www.spiedigitallibrary.org/shoppingcart?fuseaction=cartadditem&productid=DLX&qty=50)\n\n[ADD TO CART](https://www.spiedigitallibrary.org/shoppingcart?fuseaction=cartadditem&productid=DLX&qty=25)\n\n[ADD TO CART](https://www.spiedigitallibrary.org/shoppingcart?urlId=10.1117%2f12.3056070)", "embedding": [-0.08669528365135193, 0.009163283742964268, -0.05578911677002907, -0.011870068497955799, 0.032858677208423615, 0.01824379712343216, 0.07565233111381531, 0.001494268304668367, -0.037080634385347366, -0.030255790799856186, 0.08955535292625427, 0.07215166836977005, -0.01063678227365017, -0.04199042543768883, 0.031145354732871056, 0.010132497176527977, 0.008093573153018951, -0.01771966926753521, -0.01346212811768055, -0.007831142283976078, 0.027005106210708618, -0.07286449521780014, 0.017772765830159187, 0.0052917394787073135, -0.06843337416648865, 0.0038450437132269144, -0.03771064430475235, -0.04981818050146103, -0.050037283450365067, 0.059605617076158524, 0.06640516966581345, 0.07430113106966019, 0.04149722307920456, -0.005184858571738005, 0.06348227709531784, -0.11470360308885574, 0.0988541916012764, 0.019333939999341965, 0.10561790317296982, -0.01650574617087841, 0.042800866067409515, -0.08079294860363007, -0.04640178754925728, 0.0071962554939091206, -0.0007096066838130355, -0.0028150437865406275, -0.015626324340701103, 0.062106356024742126, -0.05470962077379227, 0.029119376093149185, -0.0027221660129725933, -0.024367505684494972, 0.09739942848682404, 0.012126355431973934, -0.10557764023542404, -0.05711568146944046, -0.009788996540009975, 0.009348743595182896, 0.062094759196043015, -0.06419403105974197, 0.08188240230083466, 0.041676025837659836, 0.03850233927369118, 0.006271154619753361, 0.021617863327264786, 0.017814164981245995, -0.029306191951036453, -0.013624797575175762, -0.011378836818039417, -0.04627775028347969, 0.043670568615198135, -0.049935683608055115, -0.06468705832958221, 0.024109933525323868, 0.01794855110347271, 0.01813352108001709, 0.019924838095903397, -0.02520831488072872, -0.05631602555513382, -0.0359666682779789, 0.015293878503143787, 0.002096205484122038, 0.04751529544591904, -0.0313720740377903, -0.05590958893299103, 0.02897096984088421, -0.038168102502822876, -0.010329707525670528, 0.06443244963884354, -0.04504822939634323, -0.024399736896157265, 0.020558089017868042, 0.03665391355752945, -0.10654816031455994, 0.06814634054899216, -0.02659766562283039, -0.02195003628730774, 0.01718762330710888, 0.019341198727488518, 0.04652012139558792, 0.005601619370281696, 0.027283845469355583, -0.01907205954194069, -0.0634029433131218, 0.04545876383781433, -0.005722769070416689, 0.042060576379299164, 0.05058920755982399, 0.010177329182624817, 0.010764723643660545, -0.014229902066290379, 0.03281081095337868, 0.09028782695531845, -0.08527039736509323, -0.010617482475936413, -0.003231549169868231, -0.07554691284894943, 0.07360081374645233, 0.009264343418180943, 0.026613501831889153, 0.06907570362091064, 0.08032536506652832, -0.0817376971244812, -0.009258350357413292, -0.049602020531892776, -0.10008213669061661, -0.06726979464292526, 8.502437332205979e-33, -0.09975820034742355, 0.009819349274039268, 0.02764781191945076, 0.034741438925266266, 0.050655968487262726, 0.007882571779191494, 0.023856181651353836, -0.05190403386950493, -0.04129969701170921, 0.1204305961728096, -0.004558447282761335, 0.021139971911907196, -0.03573337942361832, 0.03339068591594696, -0.09939402341842651, -0.003929285332560539, -0.06721866875886917, 0.01842491142451763, 0.08559153228998184, -0.026325548067688942, 0.02896793559193611, -0.07195910066366196, 0.014844469726085663, -0.003039784263819456, 0.01784193329513073, 0.06013911962509155, -0.028387876227498055, -0.005544029176235199, 0.13086466491222382, 0.023503508418798447, 0.004594567697495222, 0.022864054888486862, 0.045287784188985825, 0.07011661678552628, 0.03237657994031906, -0.048703767359256744, -0.058703694492578506, -0.04266592860221863, -0.033562105149030685, -0.010025576688349247, -0.0708516538143158, -0.02723906934261322, 0.016118666157126427, -0.02927134744822979, -0.06324992328882217, 0.09057372063398361, -0.031439390033483505, -0.02615843154489994, 0.10471584647893906, 0.019668858498334885, -0.06568538397550583, 0.02540544979274273, -0.13257236778736115, -0.022274963557720184, -0.06630416959524155, -0.06772785633802414, -0.06016261875629425, 0.004172760993242264, -0.0098715303465724, -0.012937976978719234, 0.059082768857479095, 0.07166676968336105, -0.06254420429468155, -0.017551418393850327, -0.1041145920753479, -0.030200304463505745, -0.04290267080068588, -0.02830571122467518, -0.013402363285422325, -0.013960782438516617, 0.016312841325998306, 0.13346001505851746, 0.038504283875226974, 0.0775381475687027, -0.0016241170233115554, -0.011071854270994663, 0.0381116047501564, 0.10431478917598724, -0.011642412282526493, -0.03330099210143089, -0.05983877182006836, -0.11921744048595428, 0.09056977182626724, 0.030323687940835953, -0.026907071471214294, 0.03383307531476021, -0.07738602161407471, -0.04122261330485344, -0.02311009354889393, -0.024677153676748276, 0.03355065733194351, -0.016490964218974113, -0.09571215510368347, 0.05287623405456543, 0.041795022785663605, -1.0056082338216042e-32, -0.03181525692343712, -0.035909976810216904, -0.0022776841651648283, -0.008169729262590408, -0.008166882209479809, 0.04218176379799843, 0.01038933452218771, -0.024744929745793343, 0.07430654019117355, 0.030285745859146118, -0.06543749570846558, -0.011203879490494728, -0.01659635826945305, -0.008557847701013088, 0.06633051484823227, -0.013642466627061367, 0.11502589285373688, -0.04627356678247452, -0.0902220755815506, -0.05632695183157921, 0.005684313364326954, 0.06584230065345764, -0.01245648693293333, 0.06437204033136368, -0.010262624360620975, 0.0029499446973204613, 0.04162927716970444, 0.0003707122814375907, 0.0015274836914613843, 0.10714493691921234, 0.020948579534888268, 0.023456495255231857, -0.03565797209739685, 0.05360368639230728, -0.08706127107143402, -0.07047117501497269, 0.055662401020526886, 0.055963918566703796, 0.010506197810173035, -0.11714792996644974, 0.043837469071149826, 0.006662349682301283, -0.031908269971609116, -0.010399769060313702, -0.05460551753640175, -0.04853232577443123, -0.017604004591703415, -0.02382928505539894, 0.08534932136535645, -0.04937775433063507, -0.0004546981072053313, 0.0029374423902481794, -0.006217078771442175, -0.09024536609649658, -0.011881665326654911, 0.12105463445186615, 0.054196882992982864, -0.03767537325620651, 0.05256814509630203, -0.06224604323506355, 0.0002775931206997484, 0.10171013325452805, -0.039612047374248505, 0.05304459109902382, 0.017233828082680702, -0.08154164254665375, 0.001695027225650847, 0.0164581760764122, 0.027094874531030655, -0.07139158248901367, 0.03298494964838028, -0.04623347893357277, 0.008671401999890804, -0.006605024915188551, -0.020987657830119133, 0.018616652116179466, 0.07273580878973007, -0.0030545005574822426, 0.015439479611814022, 0.01932445541024208, 0.030916836112737656, -0.09198735654354095, -0.014144864864647388, 0.08529268950223923, 0.09412828832864761, -0.01640383154153824, -0.07500849664211273, -0.07626431435346603, 0.01791435107588768, -0.008513465523719788, -0.0702136754989624, -0.050968606024980545, -0.04392431676387787, 0.034050650894641876, -0.009781123138964176, -6.542859409819357e-08, 0.04237276315689087, -0.06935092061758041, -0.013661016710102558, 0.06923659145832062, -0.0334249772131443, -0.011273556388914585, 0.007397209294140339, 0.04167552292346954, -0.0930357500910759, -0.0019258386455476284, -0.0005066115991212428, -0.01084949728101492, -0.06154812127351761, 0.010767433792352676, -0.03700394183397293, -0.098239965736866, 0.005337845999747515, -0.02819794788956642, -0.026951411738991737, -0.029345404356718063, -0.04330359026789665, -0.008878977969288826, -0.011560093611478806, -0.02639225870370865, -0.03263290598988533, -0.017893042415380478, 0.03419717401266098, 0.09845048189163208, 0.043594345450401306, 0.004436088725924492, -0.07260916382074356, 0.03999900445342064, -0.04958343878388405, 0.01954420655965805, 0.001736423815600574, 0.019252728670835495, -0.03894202783703804, 0.021886074915528297, -0.08020535111427307, 0.04275801405310631, -0.012172041460871696, 0.016653748229146004, 0.047186750918626785, 0.0016843908233568072, 0.02700698934495449, 0.006386967375874519, -0.12913134694099426, -0.0065561686642467976, 0.11689721047878265, -0.062209922820329666, 0.015939412638545036, -0.036104828119277954, 0.10528609901666641, 0.09022042900323868, -0.007393050938844681, 0.02045009844005108, 0.027324514463543892, 0.028169410303235054, 0.029466550797224045, 0.07285964488983154, 0.08787456154823303, -0.03167808800935745, 0.0627836361527443, 0.015186814591288567]}, {"id": "694f11872ef7fd944bcee9e8", "user_id": "CarlFristam", "title": "Advances in Continual Graph Learning for Anti-Money ...", "text": "# Computer Science > Machine Learning\n\n**arXiv:2503.24259** (cs)\n\n\\[Submitted on 31 Mar 2025\\]\n\n# Title:Advances in Continual Graph Learning for Anti-Money Laundering Systems: A Comprehensive Review\n\nAuthors: [Bruno Deprez](https://arxiv.org/search/cs?searchtype=author&query=Deprez,+B), [Wei Wei](https://arxiv.org/search/cs?searchtype=author&query=Wei,+W), [Wouter Verbeke](https://arxiv.org/search/cs?searchtype=author&query=Verbeke,+W), [Bart Baesens](https://arxiv.org/search/cs?searchtype=author&query=Baesens,+B), [Kevin Mets](https://arxiv.org/search/cs?searchtype=author&query=Mets,+K), [Tim Verdonck](https://arxiv.org/search/cs?searchtype=author&query=Verdonck,+T)\n\nView a PDF of the paper titled Advances in Continual Graph Learning for Anti-Money Laundering Systems: A Comprehensive Review, by Bruno Deprez and 5 other authors\n\n[View PDF](https://arxiv.org/pdf/2503.24259) [HTML (experimental)](https://arxiv.org/html/2503.24259v1)\n\n> Abstract:Financial institutions are required by regulation to report suspicious financial transactions related to money laundering. Therefore, they need to constantly monitor vast amounts of incoming and outgoing transactions. A particular challenge in detecting money laundering is that money launderers continuously adapt their tactics to evade detection. Hence, detection methods need constant fine-tuning. Traditional machine learning models suffer from catastrophic forgetting when fine-tuning the model on new data, thereby limiting their effectiveness in dynamic environments. Continual learning methods may address this issue and enhance current anti-money laundering (AML) practices, by allowing models to incorporate new information while retaining prior knowledge. Research on continual graph learning for AML, however, is still scarce. In this review, we critically evaluate state-of-the-art continual graph learning approaches for AML applications. We categorise methods into replay-based, regularization-based, and architecture-based strategies within the graph neural network (GNN) framework, and we provide in-depth experimental evaluations on both synthetic and real-world AML data sets that showcase the effect of the different hyperparameters. Our analysis demonstrates that continual learning improves model adaptability and robustness in the face of extreme class imbalances and evolving fraud patterns. Finally, we outline key challenges and propose directions for future research.\n\n| | |\n| --- | --- |\n| Subjects: | Machine Learning (cs.LG) |\n| Cite as: | [arXiv:2503.24259](https://arxiv.org/abs/2503.24259) \\[cs.LG\\] |\n| | (or [arXiv:2503.24259v1](https://arxiv.org/abs/2503.24259v1) \\[cs.LG\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2503.24259](https://doi.org/10.48550/arXiv.2503.24259) Focus to learn more arXiv-issued DOI via DataCite (pending registration) |\n\n## Submission history\n\nFrom: Bruno Deprez \\[ [view email](https://arxiv.org/show-email/04246b5d/2503.24259)\\]\n\n**\\[v1\\]**\nMon, 31 Mar 2025 16:06:47 UTC (1,918 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Advances in Continual Graph Learning for Anti-Money Laundering Systems: A Comprehensive Review, by Bruno Deprez and 5 other authors\n\n- [View PDF](https://arxiv.org/pdf/2503.24259)\n- [HTML (experimental)](https://arxiv.org/html/2503.24259v1)\n- [TeX Source](https://arxiv.org/src/2503.24259)\n- [Other Formats](https://arxiv.org/format/2503.24259)\n\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2503.24259&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2503.24259&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2025-03](https://arxiv.org/list/cs.LG/2025-03)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2503.24259?context=cs)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2503.24259)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2503.24259)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2503.24259)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2503.24259&description=Advances in Continual Graph Learning for Anti-Money Laundering Systems: A Comprehensive Review) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2503.24259&title=Advances in Continual Graph Learning for Anti-Money Laundering Systems: A Comprehensive Review)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2503.24259) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))", "embedding": [-0.07443831115961075, 0.052461374551057816, -0.03874799609184265, 0.022255439311265945, 0.05381336063146591, -0.004266773350536823, 0.001010589418001473, -0.03358174115419388, 0.015591183677315712, 0.023318886756896973, -0.019812602549791336, 0.031769633293151855, 0.04055152088403702, -0.02454645000398159, -0.06696685403585434, 0.04135125130414963, -0.038752831518650055, 0.04409182816743851, 0.032007042318582535, -0.05325785279273987, -0.027332577854394913, -0.054976463317871094, 0.02429381012916565, -0.07627511024475098, 0.05951574072241783, -0.014193395152688026, -0.04030279070138931, -0.02701432630419731, 0.028692245483398438, -0.015470377169549465, 0.04968312755227089, 0.0642680823802948, 0.0007232549251057208, 0.0516648069024086, -0.07509960979223251, -0.02129753865301609, 0.007216433994472027, 0.07036639004945755, 0.06672049313783646, 0.01984454318881035, 0.02704033814370632, -0.028569992631673813, -0.03626028075814247, -0.02994666062295437, 0.026163334026932716, -0.0011321320198476315, -0.038345661014318466, 0.026209700852632523, -0.022078214213252068, 0.03890369087457657, -0.11275791376829147, -0.03565199300646782, 0.03384776785969734, 0.042841095477342606, 0.026472685858607292, -0.07686254382133484, 0.008133062161505222, 0.02499367669224739, -0.027542758733034134, -0.0390782356262207, 0.0938112810254097, -0.07196048647165298, -0.08543980866670609, -0.03266945853829384, -0.013787694275379181, 0.03845224902033806, -0.007298341486603022, 0.08260494470596313, -0.02436894364655018, 0.06188695505261421, 0.06798245012760162, 0.014698273502290249, -0.14180301129817963, 0.02964356169104576, 0.07934693992137909, 0.07273516058921814, 0.021728800609707832, -0.010030270554125309, -0.013286985456943512, -0.08902748674154282, 0.012712693773210049, -0.02408832125365734, 0.008287256583571434, -0.05989743024110794, 0.029005182906985283, -0.04306528717279434, -0.04527942091226578, -0.07383496314287186, 0.10305555909872055, -0.03476285934448242, -0.005349424667656422, 0.013456469401717186, 0.051095329225063324, -0.1051311120390892, 0.035414982587099075, -0.0047324043698608875, 0.02617334946990013, 0.029699400067329407, -0.0019330590730533004, 0.08712188154459, -0.017076216638088226, 0.008249352686107159, -0.01158458273857832, -0.06520013511180878, 0.018846243619918823, -0.01980365626513958, -0.019593093544244766, 0.12699304521083832, 0.051689259707927704, -0.03325691819190979, -0.03338676691055298, 0.08164890855550766, -0.01383467298001051, 0.003450138261541724, 0.021988283842802048, -0.016989540308713913, -0.002886344911530614, -0.014803010039031506, 0.006729906424880028, 0.08197025954723358, -0.0034604521933943033, 0.08548127114772797, -0.07590430229902267, 0.003168224124237895, -0.041619233787059784, -0.05437379330396652, -0.06493277847766876, 4.491076451678354e-33, 0.015473547391593456, 0.05700685456395149, 0.02556518279016018, -0.035481035709381104, -0.009281828999519348, 0.062103889882564545, -0.020167836919426918, 0.013883337378501892, -0.05385222285985947, 0.026965176686644554, -0.126358300447464, 0.07036914676427841, 0.002160595031455159, 0.05319162458181381, -0.014028286561369896, -0.04572715610265732, -0.004772455897182226, -0.023782772943377495, 0.019725991412997246, -0.10038349032402039, 0.11928211152553558, -0.032446205615997314, 0.026685215532779694, 0.011966494843363762, 0.02488628774881363, 0.022563830018043518, 0.009855947457253933, -0.01527626533061266, 0.07253974676132202, 0.0334266759455204, -0.0808388963341713, 0.06611556559801102, -0.004929438699036837, 0.04879414290189743, 0.0335456058382988, -0.015335364267230034, -0.08085492998361588, 0.013316740281879902, 0.013902045786380768, -0.11792024224996567, -0.08268970251083374, 0.052527204155921936, 0.03641536459326744, -0.05469950661063194, -0.08317501097917557, -0.003873468842357397, -0.016108522191643715, -0.030509522184729576, 0.06235858425498009, -0.025819197297096252, -0.020890407264232635, -0.00589514197781682, -0.11606248468160629, 0.00445331446826458, -0.03884078934788704, 0.01766776852309704, 0.023472188040614128, 0.05090504512190819, -0.05012158304452896, -0.009808707050979137, 0.09601830691099167, 0.00022769135830458254, -0.01583440974354744, 0.06334798038005829, -0.049045391380786896, 0.05669950321316719, 0.004804458003491163, 0.009176470339298248, 0.019836772233247757, -0.017565598711371422, 0.04788336530327797, 0.10407626628875732, 0.06826191395521164, -0.06879298388957977, -0.0038584410212934017, -0.06457095593214035, 0.030731305480003357, 0.009378308430314064, -0.013883917592465878, 0.013020089827477932, -0.06280652433633804, -0.08309301733970642, 0.05456306412816048, -0.020625732839107513, -0.04963549226522446, -0.030209140852093697, 0.04235709458589554, -0.08711282163858414, 0.008139085955917835, 0.02125736139714718, 0.015445246361196041, 0.006490619387477636, -0.04418538138270378, 0.015628419816493988, -0.029138678684830666, -5.0377452423160436e-33, -0.04285440221428871, 0.019174620509147644, 0.08698856830596924, -0.0016585122793912888, 0.03609498217701912, 0.005645147059112787, -0.003998847212642431, -0.01590203121304512, 0.005957443732768297, 0.0014352082507684827, 0.03810824826359749, -0.06680604815483093, 0.01737203449010849, -0.008044466376304626, 0.012809496372938156, 0.005027022212743759, 0.006984496954828501, -0.008715536445379257, -0.03110402822494507, -0.03479284793138504, 0.026408247649669647, 0.03660206496715546, -0.09716986864805222, 0.04648805037140846, 0.05467338114976883, -0.007771817501634359, 0.04064496234059334, 0.05565853416919708, -0.0545562207698822, 0.07867918908596039, -0.06546590477228165, -0.012410433031618595, -0.07287229597568512, -0.045651569962501526, -0.031172407791018486, 0.04110664129257202, 0.025386573746800423, 0.05105406418442726, -0.032851506024599075, 0.03889208659529686, 0.03291936591267586, 0.02984074130654335, -0.09252653270959854, -0.04522909224033356, 0.004664069507271051, -0.00358989997766912, -0.09745489060878754, 0.06808813661336899, 0.028509866446256638, -0.04248400405049324, 0.07063320279121399, 0.02293790504336357, -0.045136455446481705, 0.007591442205011845, -0.0686979740858078, 0.02751840278506279, 0.022260135039687157, 0.05512527376413345, -0.0009605997474864125, -0.025144806131720543, -0.1277226358652115, 0.03373100608587265, 0.005163237452507019, 0.08406325429677963, 0.028387373313307762, -0.07112035155296326, -0.011505119502544403, 0.06667792797088623, -0.0005834909970872104, -0.06517891585826874, 0.09199614822864532, -0.005815970711410046, -0.03177623078227043, -0.0339297354221344, 0.004575987346470356, 0.027846500277519226, -0.03518756851553917, 0.031458113342523575, -0.047573965042829514, -0.013516434468328953, -0.008627311326563358, 0.03242381289601326, 0.026726847514510155, 0.1273052841424942, 0.03553372621536255, 0.0536600686609745, -0.025816909968852997, 0.02474202960729599, 0.025920728221535683, 0.059206850826740265, 0.03411727398633957, -0.0694199874997139, -0.034225836396217346, 0.006607720162719488, 0.010803109966218472, -4.979557033379933e-08, -0.13206884264945984, 0.004280611872673035, -0.07132778316736221, 0.017494304105639458, 0.10441054403781891, 0.02662842348217964, 0.04475579038262367, 0.10288133472204208, -0.09468474239110947, 0.04283539578318596, 0.09331656247377396, 0.05888049304485321, -0.03418518975377083, -0.06440778076648712, -0.05369612202048302, -0.0801231637597084, 0.005775861442089081, -0.06007660552859306, -0.034877728670835495, 0.0036850140895694494, 0.04372993856668472, 0.0026440720539540052, 0.017095986753702164, -0.0020260976161807775, 0.04083782061934471, -0.09359253942966461, -0.06627088040113449, 0.02455671690404415, 0.0532735213637352, 0.04163961112499237, -0.11006557196378708, 0.07310721278190613, 0.013712892308831215, -0.052025407552719116, 0.055770523846149445, 0.10400423407554626, 0.006016603671014309, -0.03452501818537712, -0.12685221433639526, 0.09214772284030914, 0.01251551415771246, 0.04568101093173027, -0.03477245196700096, -0.001215483294799924, 0.04787059500813484, -0.02324213646352291, -0.020410386845469475, -0.019902823492884636, 0.1070176512002945, -0.09814316034317017, 0.032462362200021744, -0.059135399758815765, 0.02804732322692871, 0.004998242482542992, 0.05882507562637329, -0.05615991726517677, -0.059007082134485245, 0.010130669921636581, 0.04990454763174057, 0.04751250147819519, 0.11604447662830353, -0.10591327399015427, -0.017213882878422737, 0.062261153012514114]}, {"id": "694f1a922ef7fd944bcee9f2", "user_id": "CarlFristam", "title": "Anti-Money Laundering by Group-Aware Deep Graph Learning", "text": "\n \n Abstract \n Money laundering (ML) is a serious challenge that supports organized and transnational crime, with far-reaching impacts on a country\u2019s economy, governance, and social welfare. Financial institutions, which manage the flow of money, Financial institutions have become essential partners in the global battle against money laundering. While traditional AML systems typically assess transactions one by one, they often fail to detects the large patterns that emerges when criminal groups operate in coordination. Today, money laundering is often orchestrated by organized networks rather than individuals acting alone. Recognizing this shift, a deep graph learning model now makes it possible to detect collaborative money laundering by zooming in on group dynamics and shared behaviors. Our approach models users and their transactions as interconnected nodes within a graph, using a community-based encoder to capture group dynamics and behavioral patterns. Additionally, we apply a local feature enhancement method to identify and group similar transactional behaviors, helping to uncover hidden laundering networks. This Experiments are using an actual data from a leading international bank card network revealed that this approach delivers notably higher accuracy in detecting suspicious activity. It delivers superior results compared to current anti-money laundering methods, consistently identifying suspicious activity more effectively in both live monitoring and scheduled data analysis. These findings underscore how using graph-based techniques to capture group-level patterns can make AML systems far more effective at spotting complex, coordinated financial crimes. \n \n \n Introduction \n 1. Money Laundering Overview \n Money laundering involves disguising illegally obtained money to make it appear legitimate. It supports organized crime and is estimated to account for about 2.7% of global GDP. Traditional anti-money laundering (AML) methods are rule-based and labor-intensive. New technologies like machine learning (ML) and deep learning are now being adopted to automate and improve detection\u2014but they often struggle to detect coordinated laundering activities by organized groups. \n \n 2. Proposed Approach: Group-Aware Graph Neural Network (GAGNN) \n To overcome limitations of traditional AML models, researchers propose a Group-Aware Graph Neural Network (GAGNN) that: \n \n \n Models accounts as nodes and transactions as edges in a graph. \n \n \n Captures both individual behavior and group dynamics. \n \n \n Uses Graph Attention Networks (GAT) and Extended Markov Random Fields (eMRF) to identify suspicious communities. \n \n \n Classifies suspicious activity at three levels: \n \n \n Individual accounts \n \n \n Transactions \n \n \n Groups of users (super-nodes) \n \n \n \n \n This multi-level structure enables better detection of organized money laundering schemes. It is scalable, trained offline, and suitable for real-time deployment. \n \n 3. Literature Review \u2013 Key Techniques and Contributions \n a. Time-Frequency Analysis (El Ammari et al., 2021) \n Uses Short-Time Fourier Transform (STFT) to detect laundering patterns over time. Captures dynamic, repetitive financial behavior with high accuracy. \n b. Deep Learning Models (Ghosh et al., 2023) \n Applies models like RNNs, LSTMs, CNNs, and GNNs for complex pattern recognition. Highlights the importance of explainable AI (XAI) tools (e.g., LIME, SHAP) to improve transparency. \n c. Rule-Based Detection (Butgereit, 2021) \n Uses rule-based logic (e.g., 12 Red Flags) to detect funnel accounts in mobile finance, effective where labeled data is scarce. \n d. Visual Analytics for Crypto AML (Wang et al., 2022) \n Introduces a visual framework using transaction flows and clustering to detect laundering in cryptocurrency exchanges\u2014helpful for non-technical investigators. \n e. Hybrid Model (Koo et al., 2024) \n Combines an autoencoder for anomaly detection with a risk-based scoring system, balancing unsupervised learning with expert-driven rules. \n f. Explainable AI via xGEMs (Dou, 2020) \n Provides interpretable counterfactuals using generative models to explain decisions made by black-box ML models, enhancing trust in AI systems. \n g. Graph-Based Detection with Sparse Data (Liu et al., 2020) \n Presents a scalable Graph Convolutional Network (GCN) that learns from limited labeled data using sampling and embedding. Effective for large, sparse financial graphs. \n \n 4. Key Innovations of GAGNN \n \n \n Graph-based transaction modeling \n \n \n Group-level analysis for detecting coordinated crime \n \n \n Community-aware attention and inference \n \n \n Multi-layer classification (users, transactions, groups) \n \n \n Scalable and real-time capable system \n \n \n \n \n Conclusion \n The growing complexity of financial crime demands more intelligent, adaptable, and interpretable solutions\u2014deep graph learning offers a promising path forward in this effort. By modeling relationships between entities and capturing group behaviors within financial networks, graph-based approaches, This approach significantly surpasses the limitations of conventional anti-money laundering methods, offering deeper insights and more adaptive solutions. This survey has highlighted a range of innovative methods, from group-aware neural networks and semi-supervised frameworks to autoencoder-based anomaly detection and explainable AI tools. Each contributes uniquely to detecting both individual and collaborative money laundering patterns in real-world settings. Despite notable progress, challenges remain. Limited access to reliable data, concerns about how models make decisions, and challenges in scaling them up are still major roadblocks to broader adoption.. However, recent advancements in hybrid learning models, interpretability techniques, and scalable graph architectures suggest a promising future for research and practical deployment. Going forward, collaboration between financial institutions, regulatory bodies, and the research community will be essential to build AML systems that are not only accurate but also trustworthy and operationally viable. Ultimately, deep graph learning is not just a technical innovation\u2014it\u2019s a foundational shift in how we understand and combat financial crime in the digital age. \n \n \n References \n [1] Liu, H., Zuo, Y., Zhu, X., Yin, H., &amp; Zhang, M. (2021). Anti-money laundering by group-aware deep graph learning. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining (pp. 1113\u20131123). ACM.\n[2] B. Unger, \\\"Money laundering regulation: From al Capone to al qaeda,\\\" in Research Handbook on Money Laundering Anonymous 2013, .\n[3] M. El Ammari, H. Rachidi, and Y. Benslimane, \\\"A time-frequency based suspicious activity detection for anti-money laundering,\\\" in Proc. 2021 4th International Conference on Advanced Systems and Emergent Technologies (IC_ASET), Hammamet, Tunisia, 2021, pp. 177\u2013182. doi: 10.1109/IC_ASET52486.2021.9691095.\n[4] A. Ghosh, M. V. R. K. R. R. Atrey, and A. B. Benerjee, \\\"Deep learning and explainable artificial intelligence techniques applied for detecting money laundering: A critical review,\\\" Computers &amp; Security, vol. 130, 2023, Art. no. 103138, doi: 10.1016/j.cose.2023.103138.\n[5] L. Butgereit, \\\"Anti Money Laundering: Rule-Based Methods to Identify Funnel Accounts,\\\" in Proc. 2021 Conf. on Information Communications Technology and Society (ICTAS), Port Elizabeth, South Africa, 2021, pp. 20\u201326. doi: 10.1109/ICTAS50802.2021.9394990.\n[6] Wang, H., Wang, X., Yang, D., &amp; Wu, Y. (2022). \u201cVisual analysis of money laundering in cryptocurrency exchange.\u201d IEEE Transactions on Visualization and Computer Graphics, 28(1), 98\u2013108. \n[7] K. Koo, M. Park, and B. Yoon, \\\"A suspicious financial transaction detection model using autoencoder and risk-based approach,\\\" IEEE Access, vol. 12, pp. 68926\u201368939, May 2024, doi: 10.1109/ACCESS.2024.3399824.\n[8] Yingtong Dou1, Zhiwei Liu1, Li Sun2, Yutong Deng2, Hao Peng3, Philip S. Yu1 \u2018\u2018Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters,\u2019\u2019. 1. IEEE, 2020.\n[9] Liu, A., Tong, Y., Li, Z., Deng, K., He, X., &amp; Tong, H. (2020). \u201cScalable semi-supervised graph learning techniques for anti-money laundering\u201d. arXiv preprint arXiv:2009.05344\n[10] T. N. Kipf and M. Welling, ``Semi-supervised classification with graph convolutional networks,\\'\\' in Proc. Int. Conf. Learn. Represent. (ICLR), 2017, pp. 114.\n[11] R. Liu, X.-L. Qian, S. Mao, and S.-Z. Zhu, ``Research on anti money laundering based on core decision tree algorithm,\\'\\' in Proc. IEEE Chin. Control Decis. Conf. (CCDC), May 2011, pp. 4322 4325.\n[12] Z. Chen, L. Dinh Van Khoa, A. Nazir, E. N. Teoh, and E. K. Karupiah ``Exploration of the effectiveness of expectation maximization algorithm for suspicious transaction detection in anti money laundering,\\'\\' in Proc. IEEE Conf. Open Syst. (ICOS), Oct. 2014, pp. 145 149.\n[13] K. Singh and P. Best, \u201cAnti-money laundering: Using data visualization to identify suspicious activity,\u201d Int. J. Accounting Inf. Syst., vol. 34, no. 3, pp. 7\u201313, 2019.\n[14] N. Heidarinia, A. Harounabadi, and M. Sadeghzadeh, \u201cAn intelligent anti-money laundering method for detecting risky users in the banking systems,\u201d Int. J. Comput. Appl., vol. 97, no. 22, pp. 35\u201339, Jul. 2014.\n[15] M.-J. Segovia-Vargas et al., \u201cMoney laundering and terrorism financing detection using neural networks and an abnormality indicator,\u201d Expert Syst. Appl., vol. 169, 2021, Art. no. 11447\n \n \n \n Copyright \n Copyright \u00a9 2025 Shwetha A B, Shreyas H G, Siddarameshwara J, Srinidhi M, Srujan T S. This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. \n \n", "embedding": [-0.03808126598596573, -0.06833851337432861, -0.04046330228447914, 0.021782876923680305, 0.05269709601998329, -0.03518526628613472, 0.014898320659995079, -0.0878237634897232, 0.04268612712621689, -0.04092302918434143, 0.01902804896235466, -0.023909950628876686, -0.020493341609835625, 0.05209393799304962, -0.03239891305565834, -0.055715300142765045, 0.040165502578020096, -0.015590216033160686, -0.06059487536549568, -0.031239690259099007, -0.024775557219982147, -0.09341210126876831, -0.0015715636545792222, -0.01816507987678051, 0.032155849039554596, 0.02998780645430088, -0.03936673700809479, -0.06332669407129288, 0.014641951769590378, -0.005884585902094841, 0.11667471379041672, 0.0690266564488411, -0.0372316837310791, 0.05718417093157768, -0.02045315131545067, -0.0302178543061018, 0.025063587352633476, 0.03441232442855835, 0.07778836041688919, -0.007773930206894875, 0.10513194650411606, -0.020869189873337746, 0.06879199296236038, 0.03292006999254227, 0.015134376473724842, -0.005110852885991335, -0.006629283539950848, 0.07228979468345642, 0.012944447807967663, 0.021843450143933296, -0.023575494065880775, -0.01579146832227707, 0.026523608714342117, 0.07418960332870483, -0.002198220696300268, -0.052649203687906265, 0.051650818437337875, -0.011232285760343075, -0.018147412687540054, -0.08134498447179794, 0.05179811641573906, 0.015412215143442154, 0.0496467724442482, -0.024427881464362144, -0.038467053323984146, 0.04601453244686127, 0.005402593873441219, 0.1092919185757637, 0.004128199070692062, -0.0014708667295053601, 0.08974969387054443, 0.003292462322860956, -0.10146541893482208, 0.01902996562421322, -0.006371758412569761, 0.013289405032992363, 0.016287053003907204, -0.013286023400723934, -0.04659978300333023, -0.027092808857560158, -0.004048977978527546, 0.035325635224580765, 0.005017525050789118, -0.04874785616993904, 0.07537955045700073, -0.0003755534125957638, -0.07072972506284714, -0.021122626960277557, -0.011922921054065228, -0.001770248869433999, -0.08747085928916931, 0.12165588140487671, 0.03552592918276787, -0.09969431161880493, 0.04013269767165184, 0.022992296144366264, 0.008862546645104885, -0.012386427260935307, 0.0325845330953598, 0.10717318207025528, -0.05485685542225838, 0.005572794005274773, 0.019901402294635773, -0.03706365078687668, 0.0978899821639061, 0.03479030728340149, 0.02735872194170952, 0.09866541624069214, 0.0063817547634243965, -0.007027825806289911, -0.017672747373580933, 0.06733474880456924, 0.03944777697324753, -0.014541271142661572, 0.06847434490919113, -0.049334168434143066, 0.01436089351773262, 0.05459979176521301, -0.029851172119379044, 0.08739752322435379, 0.01206253282725811, 0.0418081171810627, -0.026881081983447075, -0.026104692369699478, -0.025684310123324394, 0.053512535989284515, -0.12377014011144638, -6.1122767506881895e-34, -0.0027733580209314823, 0.015331415459513664, -0.02885754406452179, -0.025125624611973763, 0.014455900527536869, 0.031559720635414124, -0.12494397908449173, 0.01870214007794857, -0.0018582057673484087, 0.08896801620721817, -0.10057429224252701, 0.0073500764556229115, -0.00012320783571340144, 0.07741551101207733, -0.009156136773526669, -0.013409765437245369, 0.022869165986776352, -0.025596559047698975, 0.023344749584794044, -0.07199728488922119, 0.021733025088906288, -0.041625238955020905, 0.012017976492643356, 0.01435377448797226, -0.020979057997465134, 0.030609434470534325, -0.026124227792024612, 0.008162135258316994, 0.12866954505443573, 0.0019069331465288997, -0.011682303622364998, 0.02757840044796467, 0.056693222373723984, 0.11603348702192307, -0.029612485319375992, -0.013488014228641987, -0.06613243371248245, -0.023944873362779617, -0.010356130078434944, -0.05895514413714409, -0.044225212186574936, 0.012323343195021152, -0.043698083609342575, -0.0490143857896328, -0.02230544574558735, 0.07818487286567688, -0.02967703714966774, -0.03664505109190941, -0.03316893056035042, -0.0684220939874649, 0.06773560494184494, -0.04433806985616684, -0.018703518435359, 0.00626308424398303, -0.03586000204086304, -0.03204150125384331, 0.02851185016334057, 0.026686636731028557, 0.006887374445796013, 0.00813613273203373, 0.05318555235862732, 0.009821061044931412, -0.06205177307128906, 0.07258017361164093, -0.03357725217938423, -0.03758512809872627, 0.03691535443067551, 0.09622024744749069, -0.0017038177466019988, -0.04339217022061348, -0.005011508706957102, 0.156961128115654, 0.019128860905766487, 0.012369262054562569, -0.0031467354856431484, 0.017483122646808624, 0.03583374619483948, -0.009187987074255943, -0.053981926292181015, 0.06362615525722504, -0.027195746079087257, -0.09057193994522095, 0.07599224895238876, 0.0208955816924572, -0.08105333149433136, 0.05790496990084648, 0.01878941059112549, -0.03606173023581505, 0.0231649000197649, 0.012501709163188934, -0.03887469321489334, -0.03343842551112175, 0.025713935494422913, 0.07441598176956177, 0.03286116570234299, 4.610339640433824e-35, -0.0040456680580973625, 0.06547696888446808, 0.05114201456308365, -0.05623431131243706, -0.0027998408768326044, -0.02571067586541176, 0.01015913113951683, -0.0456775464117527, -0.006302251014858484, 0.045510925352573395, -0.040504299104213715, -0.11217118799686432, 0.08006468415260315, 0.007301528472453356, 0.06364244967699051, -0.0463574156165123, 0.08475495874881744, 0.003829467808827758, -0.0258090328425169, -0.004200652241706848, -0.001472540432587266, 0.0229642391204834, -0.029483353719115257, 0.03017415851354599, 0.05375751480460167, -0.022996339946985245, 0.02148633450269699, -0.03450067713856697, -0.04286232218146324, 0.07628145068883896, -0.04486856237053871, 0.0136506836861372, -0.0004769610532093793, -0.05229208990931511, -0.1036776527762413, 0.05466962233185768, -0.022253818809986115, -0.07240215688943863, 0.024894490838050842, -0.05892498046159744, -0.021138127893209457, 0.050704970955848694, -0.13076302409172058, 0.02263759635388851, -0.12351816892623901, 0.0693124383687973, -0.015140903182327747, 0.06797034293413162, -0.01364744734019041, -0.04327920451760292, -0.0289238803088665, 0.019263384863734245, 0.029297396540641785, -0.008910481818020344, -0.04533352330327034, 0.07111825048923492, 0.04635108262300491, 0.011911129578948021, 0.054230593144893646, -0.012600244022905827, -0.10536742955446243, -0.007164120674133301, -0.0388617068529129, 0.02610398456454277, -0.03338124603033066, -0.021279700100421906, 0.007594693452119827, 0.01557878963649273, 0.03658388555049896, -0.000397018768126145, 0.052685391157865524, -0.07335855811834335, -0.08611015230417252, 0.029195550829172134, 0.012533541768789291, -0.007258137222379446, -0.007398882415145636, -0.08917098492383957, -0.02630923129618168, -0.02189098484814167, 0.07641944289207458, -0.0930132269859314, 0.02480851486325264, 0.03693501278758049, 0.05553280562162399, 0.0016528862761333585, -0.023698456585407257, 0.07332465797662735, 0.03681395202875137, 0.07283537089824677, -0.01680641621351242, -0.02105366252362728, -0.08084853738546371, -0.039162978529930115, -0.03847182169556618, -3.1808362166430015e-08, -0.11463207006454468, 0.023324333131313324, 0.022132843732833862, 0.008879554457962513, 0.07133721560239792, 0.03714108467102051, 0.04244256764650345, 0.08693148195743561, 0.0016428279923275113, 0.039094969630241394, 0.07333796471357346, -0.05023695155978203, -0.09745077043771744, -0.09614541381597519, -0.02522348240017891, -0.04284321889281273, 0.027840731665492058, -0.025973355397582054, 0.017821667715907097, 0.06460170447826385, 0.013040325604379177, -0.00787294190376997, 0.007517211604863405, -0.0019214595668017864, 0.002161690266802907, -0.19153992831707, -0.10442445427179337, 0.07655322551727295, 0.047975603491067886, 0.0113443648442626, -0.0686182752251625, 0.011764390394091606, -0.011374931782484055, 0.020063087344169617, -0.04183013737201691, 0.10859982669353485, 0.048007551580667496, 0.0012954537523910403, -0.04586498811841011, 0.039086513221263885, 0.01670926809310913, 0.10108210891485214, -0.03011816367506981, -0.04636797681450844, -0.03750055655837059, -0.03458297625184059, -0.026037516072392464, -0.024741262197494507, 0.10548780113458633, -0.08794955164194107, 0.009978839196264744, -0.08287890255451202, 0.06378353387117386, 0.0580885075032711, 0.028151793405413628, -0.011123020201921463, -0.04336104914546013, 0.03823597729206085, 0.06723101437091827, 0.009901553392410278, 0.03892922028899193, -0.06372963637113571, -0.028661122545599937, -0.070268914103508]}, {"id": "694f1f7d680f3c15bf455e41", "user_id": "CarlFristam", "title": "AI-Powered Fraud Detection in Financial Services: GNN, ...", "text": "\n \n 34 Pages \n Posted: 10 Mar 2025 \n \n Date Written: March 07, 2025 \n \n Abstract \n The rapid evolution of financial fraud, coupled with increasing regulatory scrutiny, challenges conventional fraud detection approaches. Traditional machine learning models struggle to capture complex fraud networks and evolving transactional patterns. This study proposes a Graph Neural Network (GNN)-based fraud detection framework, integrating network science, deep learning, and Explainable AI (XAI) to enhance fraud prevention in financial systems while ensuring compliance with anti-money laundering (AML) and knowyour-customer (KYC) regulations. By structuring financial transactions as graphs, GNNs identify hidden dependencies, collusive fraud, and synthetic identity fraud more effectively than traditional models. We benchmark GNNs against Random Forest and XGBoost, demonstrating superior recall and detection accuracy. Furthermore, we evaluate computational efficiency and real-time feasibility, addressing the scalability challenges of AI-driven fraud detection in highfrequency financial environments. Our findings suggest that integrating GNNs into financial information systems and fintech platforms significantly enhances fraud detection accuracy, risk assessment, and regulatory transparency. This research offers actionable insights for financial institutions, regulators, and AI practitioners, positioning graph-based AI methodologies as a critical innovation for ethical, scalable, and compliant financial crime prevention. \n \n Keywords: Financial Fraud Detection, Graph Neural Networks, Anomaly Detection, AI Ethics, Compliance, Risk Management \n \n Suggested Citation: \n Suggested Citation \n \n", "embedding": [-0.09939859807491302, -0.04894857481122017, -0.0366608202457428, 0.027948344126343727, 0.028110751882195473, -0.018954403698444366, 0.024004530161619186, -0.06958752870559692, 0.030404727905988693, -0.04066702723503113, -0.02100950852036476, -0.03615297004580498, 0.020108593627810478, 0.006271044258028269, -0.06504668295383453, -0.07780277729034424, 0.060959190130233765, 0.04382409155368805, -0.04769895225763321, -0.026111558079719543, 0.029467491433024406, 0.019128883257508278, -0.017042843624949455, -0.02322116307914257, 0.04482263699173927, -0.012518410570919514, 0.017630623653531075, -0.0013790797675028443, -0.04685700312256813, -0.018848484382033348, 0.09771190583705902, -0.0030314140021800995, -0.00316373142413795, 0.03345306217670441, -0.04780927300453186, -0.02037595398724079, -0.04872904717922211, 0.018464630469679832, 0.0722389817237854, -0.02900526486337185, 0.07025527209043503, -0.07226041704416275, -0.006656093057245016, 0.034931182861328125, 0.08156006038188934, -0.0012838761322200298, -0.021629026159644127, 0.015944041311740875, 0.04186629876494408, 0.055039722472429276, -0.09135077148675919, -0.03385729715228081, 0.013326099142432213, 0.041631054133176804, 0.02791702374815941, 0.030004000291228294, 0.04535538703203201, -0.020682048052549362, -0.05103278160095215, -0.015259234234690666, 0.08151663094758987, -0.05249448120594025, 0.048674702644348145, -0.02275218442082405, -0.015197516418993473, 0.05108204111456871, -0.03580941632390022, 0.06300162523984909, 0.002832834143191576, -0.012697093188762665, 0.1031883955001831, 0.010213431902229786, -0.11019208282232285, -0.010504838079214096, -0.0635472759604454, 0.08004101365804672, 0.02349724993109703, 0.05127685144543648, 0.009039956144988537, -0.026620915159583092, -0.03290542960166931, 0.0016132611781358719, 0.05105544999241829, 0.020275523886084557, 0.05027538910508156, -0.02474178746342659, -0.059260088950395584, 0.008533197455108166, -0.06838567554950714, -0.005261542275547981, 0.033801887184381485, 0.005088114179670811, 0.08943365514278412, -0.05742993950843811, 0.03661304712295532, -0.022372841835021973, 0.01129502709954977, -0.07294689863920212, 0.02780638448894024, 0.019862988963723183, -0.06045472249388695, 0.04147133231163025, 0.00014094184734858572, -0.05307716876268387, 0.05329769849777222, -0.020897049456834793, 0.06521675735712051, 0.04892057925462723, 0.057698316872119904, -0.06738747656345367, 0.006557153537869453, 0.10153592377901077, 0.024169713258743286, -0.0211623664945364, 0.03132995590567589, 0.05313737690448761, -0.05118560791015625, 0.007682776544243097, 0.0005551695358008146, 0.14747019112110138, -0.05380261316895485, 0.06507475674152374, -0.052601758390665054, 0.012232676148414612, -0.043338071554899216, 0.025070302188396454, -0.12537725269794464, 7.281597919458737e-34, -0.00842637475579977, 0.04382850602269173, 0.02162104658782482, -0.06090717017650604, 0.04139632731676102, 0.00175179704092443, -0.07454822957515717, 0.029945341870188713, -0.008372614160180092, 0.09490030258893967, -0.1284116804599762, 0.05141887441277504, -0.08661345392465591, 0.043834250420331955, -0.01542882714420557, 0.05583617463707924, -0.0231008380651474, -0.01995668187737465, 0.01929590106010437, -0.08532342314720154, 0.09933581948280334, -0.08851467818021774, 0.04864659905433655, -0.029247472062706947, 0.037816233932971954, 0.011129098944365978, 0.0050224619917571545, 0.026002297177910805, 0.12467055767774582, 0.00997458677738905, -0.05320838838815689, 0.007457538042217493, 0.09069983661174774, 0.05191446468234062, 0.027979368343949318, -0.039021506905555725, -0.0740688368678093, -0.05939111113548279, -0.013989904895424843, -0.026507865637540817, -0.0988709107041359, 0.005671858787536621, 0.01994580589234829, -0.02760004624724388, -0.056853823363780975, 0.08391397446393967, 0.03237570449709892, -0.06843119114637375, 0.020492643117904663, -0.0401163287460804, 0.029421888291835785, -0.02851387858390808, 0.01877237670123577, 0.06649988889694214, -0.021272137761116028, 0.005923922639340162, 0.06040944531559944, 0.027312804013490677, -0.030472716316580772, 0.00273764762096107, 0.015542094595730305, -0.007801092695444822, -0.04398585855960846, 0.05684618651866913, -0.10705979913473129, 0.04665222764015198, 0.0218819472938776, 0.08843895047903061, -0.04219815880060196, 0.011429588310420513, 0.0015881266444921494, 0.08003558963537216, -0.019899846985936165, -0.016684705391526222, -0.006093906704336405, -0.029299097135663033, 0.02732117474079132, -0.016230160370469093, -0.05948358401656151, 0.02991638146340847, -0.033205483108758926, -0.016258390620350838, 0.0352468304336071, 0.05278277024626732, -0.06419765949249268, 0.05221747234463692, 0.07378572225570679, 0.01803961955010891, 0.059727203100919724, -0.004632353782653809, -0.05070904642343521, -0.049110047519207, 0.05819941684603691, 0.03616448864340782, 0.0067734261974692345, -1.1100145400356859e-33, -0.06567556411027908, 0.03748765587806702, 0.022728627547621727, -0.00630209082737565, -0.007224011234939098, -0.009396396577358246, -0.08015701174736023, -0.03886834532022476, -0.0012429486960172653, 0.022187387570738792, -0.02837486006319523, -0.06738422811031342, 0.07875481247901917, -0.05486045405268669, 0.01605193316936493, -0.03520103916525841, -0.002827265067026019, 0.03695778548717499, -0.026098128408193588, -0.03253091871738434, 0.06332086771726608, 0.03940478339791298, -0.03962100297212601, -0.03129839524626732, -0.010683932341635227, -0.010358939878642559, -0.02140820026397705, 0.036887411028146744, -0.00436549773439765, 0.053754955530166626, -0.07819004356861115, 0.054863475263118744, -0.03318895027041435, 0.011491650715470314, -2.2332673324854113e-05, -0.025683028623461723, 0.03981667384505272, -0.07231386750936508, -0.012580381706357002, -0.02640916220843792, 0.03907192125916481, 0.019617201760411263, -0.11361347138881683, -0.00337130855768919, -0.02598854899406433, 0.0036112561356276274, -0.01840391382575035, 0.03345896303653717, 0.06952835619449615, 0.00829884223639965, -0.03963591530919075, -0.01627722568809986, 0.012714923359453678, 0.041482750326395035, -0.06626430153846741, 0.02305973321199417, 0.05594097822904587, 0.054349254816770554, 0.021809257566928864, 0.06158679351210594, -0.1259813904762268, -0.017822809517383575, 0.009890505112707615, -0.0016360752051696181, 0.000143594661494717, -8.782567601883784e-05, 0.03355404734611511, 0.08064620941877365, 0.02627488225698471, -0.013649697415530682, 0.02920398861169815, -0.07997320592403412, -0.046319629997015, 0.06578393280506134, -0.006293067242950201, -0.004976197611540556, -0.05619608238339424, -0.07279473543167114, -0.05009652301669121, -0.008614416234195232, 0.12268763780593872, -0.012407821603119373, 0.053332749754190445, 0.07633940130472183, 0.06565038859844208, 0.0035297940485179424, 0.032904304563999176, 0.02647402323782444, 0.06759782135486603, 0.042914289981126785, -0.01904482953250408, -0.0035321649629622698, -0.08659305423498154, 0.014190729707479477, -0.08187966793775558, -3.308540286184325e-08, -0.10562959313392639, 0.040011413395404816, 0.03539206087589264, 0.02037949115037918, 0.05532778799533844, -0.02092135325074196, 0.020085914060473442, 0.06922049820423126, -0.048878178000450134, -0.019894173368811607, 0.07830044627189636, -0.05521126091480255, -0.05947414040565491, -0.13994161784648895, -0.02223031036555767, -0.06533792614936829, -0.0021135741844773293, -0.020121853798627853, 0.06691063195466995, 0.08098246157169342, 0.028990240767598152, -0.016919070854783058, 0.03166133910417557, -0.002206082222983241, -0.015634816139936447, -0.1858554631471634, -0.016478367149829865, 0.12574462592601776, 0.033996161073446274, 0.049524225294589996, -0.08441746979951859, -0.04141147434711456, 0.08076341450214386, 0.012861565686762333, -0.03945838287472725, 0.12807898223400116, 0.03900478780269623, -0.049746401607990265, -0.06108242645859718, 0.020571324974298477, -0.002281486289575696, 0.03341972827911377, 0.0209449902176857, -0.03125804662704468, -0.06315042078495026, -0.040029190480709076, -0.045139048248529434, -0.045490775257349014, 0.15576106309890747, -0.03239840269088745, 0.008735442534089088, -0.07752981036901474, 0.09427015483379364, 0.06562405824661255, 0.041953083127737045, 0.006309490650892258, -0.03834259882569313, -0.02013983204960823, 0.030317038297653198, 0.04425665736198425, 0.06906170397996902, -0.051692526787519455, -0.010493123903870583, -0.02673349343240261]}, {"id": "695027e6d72d1f222af232be", "user_id": "CarlFristam", "title": "Explainable Artificial Intelligence for Anti-Money Laundering", "text": "Explainable Artificial Intelligence for Anti-Money Laundering | SAS\n[SAS | The Power to Know](https://www.sas.com)\n![Explainable Artificial Intelligence for Anti-Money Laundering](https://www.sas.com/en/whitepapers/explainable-artificial-intelligence-for-anti-money-laundering/_jcr_content/par/textimage/image.img.jpg/1753125027446.jpg \"Explainable Artificial Intelligence for Anti-Money Laundering\")\n**White Paper**\n# Explainable Artificial Intelligence for Anti-Money Laundering\npresented by SAS\nMachine learning holds considerable promise for improving anti-money laundering efforts, but adoption has been slow due in part to regulatory demands for transparency. This white paper explores how explainable AI (XAI) techniques address the \u201cblack box\u201d nature of ML models, enabling financial institutions to meet governance standards while benefiting from AI\u2019s strengths. With increasing regulatory support for responsible AI, this paper provides practical guidance for building transparent, compliant and effective AML systems powered by machine learning.", "embedding": [-0.06243125721812248, -0.01815013587474823, -0.0262442696839571, 0.023819753900170326, 0.04213755577802658, -0.01709706149995327, 0.026820296421647072, -0.020283199846744537, 0.03125325217843056, 0.0013121392112225294, -0.029491720721125603, -0.02621529996395111, 0.033722784370183945, -0.004812269471585751, -0.046287838369607925, 0.03049120120704174, 0.04192226380109787, -0.004793678876012564, -0.11491551995277405, -0.03059076890349388, 0.06813786178827286, -0.025338271632790565, -0.05019914358854294, -0.029466597363352776, -0.038301434367895126, 0.032915204763412476, 0.011936523020267487, -0.01675722561776638, 0.0016054646112024784, 0.00762155931442976, 0.04686744511127472, -0.013818786479532719, 0.0005811919108964503, 0.047036685049533844, -0.01844499073922634, -0.003582183737307787, 0.0034036762081086636, 0.03262325003743172, 0.024749871343374252, -0.04181266203522682, 0.0004254137456882745, -0.09321285039186478, 0.023184889927506447, -0.03982838988304138, 0.08438848704099655, 0.002551538171246648, 0.03180501237511635, -0.002409722190350294, -0.01962609589099884, -0.02438834309577942, -0.11517807841300964, -0.029458478093147278, 0.006187458988279104, 0.059903278946876526, -0.06767435371875763, -0.012149715796113014, 0.013160538859665394, -0.016589917242527008, -0.052215609699487686, -0.060806553810834885, -0.003956298343837261, 0.00903594121336937, 0.07594246417284012, -0.005579855293035507, 0.01963941566646099, 0.09398268908262253, -0.05862794071435928, 0.07761655747890472, -0.018489355221390724, -0.05858868733048439, 0.043206751346588135, -0.01579209789633751, -0.045915715396404266, -0.015258592553436756, -0.0253377016633749, 0.02663293294608593, 0.013794074766337872, 0.027860000729560852, 0.05942149832844734, -0.025738846510648727, -0.03162817656993866, -0.001475751749239862, -0.018138227984309196, 0.00568390404805541, 0.030409950762987137, -0.049129173159599304, -0.011679054237902164, 0.010993453674018383, 0.04660146310925484, 0.04136177897453308, 0.023703178390860558, 0.026849308982491493, 0.09338032454252243, -0.10075290501117706, 0.10985211282968521, 0.010272836312651634, 0.03562641516327858, -0.07657812535762787, -0.007461369037628174, 0.07139690965414047, -0.04024457186460495, 0.06526210904121399, 0.0218576081097126, -0.052070558071136475, -0.03368059918284416, -0.04706287384033203, 0.07747740298509598, 0.06219205632805824, 0.028441833332180977, -0.1092747151851654, -0.016766296699643135, 0.006898419465869665, 0.012973158620297909, -0.05440288782119751, 0.044233981519937515, -0.0003799961123149842, -0.051421936601400375, 0.05434897169470787, 0.032075200229883194, 0.043140705674886703, -0.007638883776962757, 0.050977155566215515, -0.058006834238767624, 0.047741010785102844, 0.08869825303554535, 0.05299600213766098, -0.13338109850883484, 2.327933767676096e-33, -0.12346526235342026, 0.05499955639243126, -0.024617746472358704, -0.010739034973084927, 0.0013688188046216965, -0.01670733094215393, -0.0002987099578604102, -0.011527471244335175, -0.034655872732400894, 0.13048002123832703, -0.037192512303590775, 0.05459832772612572, -0.04372188448905945, 0.023509999737143517, 0.0052161975763738155, -0.005385307129472494, -0.000584096647799015, -0.005395583342760801, 0.015957094728946686, -0.06347843259572983, 0.10139120370149612, -0.03644271939992905, 0.04435868561267853, -0.06417521834373474, 0.043980225920677185, -8.882523252395913e-05, -0.032644305378198624, 0.004501646384596825, 0.11046033352613449, 0.02139413170516491, 0.03263410925865173, 0.030370816588401794, 0.05405252426862717, 0.06371325254440308, 0.0012246111873537302, -0.0051293508149683475, -0.12051709741353989, -0.01013247761875391, 0.03928752616047859, -0.016440721228718758, -0.08450490236282349, 0.00962149165570736, 0.03623662516474724, -0.021763700991868973, -0.030698930844664574, 0.075143963098526, 0.010229040868580341, -0.03681197389960289, -0.028811631724238396, -0.04472954198718071, 0.07665423303842545, 0.04328843951225281, -0.04856297746300697, -0.0849684327840805, 0.010547916404902935, -0.02583329752087593, -0.017385896295309067, 0.058651186525821686, -0.041759636253118515, 0.01619175262749195, 0.015996163710951805, -0.017464041709899902, -0.052637092769145966, 0.12662136554718018, -0.06022737920284271, 0.04665742069482803, 0.03237758204340935, 0.11130961030721664, 0.05935482680797577, -0.02671964094042778, -0.001102052628993988, 0.044670213013887405, 0.04507927969098091, 0.01822502166032791, -0.024396488443017006, -0.04737664386630058, 0.07083761692047119, -0.012983390130102634, 0.0078972727060318, -0.03314841166138649, -0.04237503930926323, 0.025251949205994606, 0.036282215267419815, 0.04695779085159302, -0.02834920398890972, 0.019743600860238075, 0.01993926800787449, -0.017295505851507187, 0.005841387901455164, -0.0618276372551918, -0.0572320930659771, -0.0760326236486435, 0.014203573577105999, 0.08777696639299393, -0.04409971460700035, -3.797429357543615e-33, -0.049841396510601044, -0.03795774281024933, 0.006736654322594404, -0.0009857980767264962, -0.033525533974170685, 0.029286302626132965, -0.008950529620051384, -0.08076310157775879, 0.08451507240533829, 0.041106928139925, -0.017414631322026253, -0.06524073332548141, 0.06935858726501465, 0.022716928273439407, -0.01086154580116272, 0.0011086505837738514, 0.004037779290229082, 0.00010158367513213307, -0.003416001331061125, 0.016466936096549034, 0.0004888571565970778, 0.12243394553661346, 0.010477977804839611, 0.03292737528681755, 0.0014162380248308182, -0.003178221406415105, -0.06680301576852798, 0.005700494162738323, 0.014571688137948513, 0.08590079098939896, -0.05082333832979202, 0.002701162826269865, 0.0012894049286842346, -0.0011966106249019504, -0.09596166014671326, -0.021389270201325417, 0.027547607198357582, -0.07526575773954391, -0.04476311057806015, 0.006068538874387741, 0.01945372298359871, 0.013499573804438114, -0.10950856655836105, -0.03851484879851341, -0.08428400009870529, 0.00865242350846529, -0.02105524390935898, 0.046610284596681595, 0.09574538469314575, -0.0844312533736229, -0.039771147072315216, -0.04819406941533089, 0.013617368414998055, -0.040246736258268356, -0.08705595135688782, 0.09937435388565063, 0.02838750369846821, -0.010920951142907143, 0.012486818246543407, 0.023309264332056046, -0.07460782676935196, -0.010128067806363106, 0.044804323464632034, 0.05358564108610153, -0.0032656004186719656, -0.02045091800391674, -0.0013438245514407754, 0.03954264894127846, -0.0069363475777208805, -0.10745611786842346, 0.05012839660048485, -0.12007355690002441, -0.05208977684378624, 0.052171334624290466, 0.03464162349700928, -0.022258935496211052, -0.04261980950832367, -0.0778031274676323, -0.049549318850040436, -0.02541756071150303, 0.03776201978325844, -0.060339123010635376, 0.0204018484801054, 0.018046695739030838, 0.05625498667359352, -0.019218405708670616, 0.042958661913871765, -0.028704172000288963, 0.06177699938416481, -0.0032665913458913565, -0.08317016065120697, 0.005152571480721235, -0.07439444214105606, 0.057354096323251724, -0.11196229606866837, -4.7095497279769916e-08, -0.028877628967165947, -0.023814033716917038, 0.053630582988262177, 0.02359612099826336, 0.082456573843956, -0.004391390364617109, -0.07239735871553421, -0.02103893645107746, -0.036449652165174484, -0.031245317310094833, 0.08154556155204773, -0.09187597781419754, -0.06595906615257263, -0.06332229822874069, -0.0784778818488121, 0.022519534453749657, -0.037045691162347794, -0.0075802914798259735, 0.019019121304154396, 0.00406659534201026, 0.027409762144088745, -0.030706625431776047, 0.017592288553714752, -0.013731870800256729, 0.07771074026823044, -0.13859200477600098, -0.08573131263256073, 0.08715277910232544, 0.0547906868159771, 0.11509553343057632, -0.05153743550181389, 0.03139761462807655, 0.09375976771116257, 0.01097080297768116, 0.007091942708939314, 0.10570014268159866, 0.07068919390439987, -0.03232981264591217, -0.0619240440428257, 0.007913677953183651, 0.02896939218044281, 0.06842823326587677, -0.03754957765340805, -0.03831604868173599, 0.0603460855782032, -0.06164288520812988, -0.05856011062860489, -0.07912146300077438, 0.06853137165307999, -0.039274826645851135, 0.04718837887048721, -0.07068311423063278, 0.09063796699047089, 0.09248577058315277, 0.10423856228590012, -0.02910257689654827, 0.02023811638355255, 0.040323056280612946, -0.014309385791420937, 0.08398161828517914, 0.07549896091222763, 0.024050598964095116, 0.05527886375784874, -0.05842304974794388]}, {"id": "69504a54c7a1aadea91e9cce", "user_id": "Test", "title": "AST SpaceMobile Falls Despite Successful Satellite Launch", "text": "AST SpaceMobile Falls Despite Successful Satellite Launch\n* [BREAKING NEWS: Stock Futures Stifled Ahead of Shortened Trading](https://www.schaeffersresearch.com/content/ezines/2025/12/24/stock-futures-stifled-ahead-of-shortened-trading)\n**\n[&gt;&gt; Stay sharp with Market Recap: Everything that shaped the markets today, delivered straight to your inbox.&lt;&lt;]()\n[[![5MRD](https://www.schaeffersresearch.com/images/default-source/default-album/5mrd.png?sfvrsn=1a87bf06_0 \"5MRD\")](https://ads.schaeffersresearch.com/5minutemarketrundown/)](https://ads.schaeffersresearch.com/ov-1/)\n# AST SpaceMobile Falls Despite Successful Satellite Launch\n## ASTS options volume is today running at six time the intraday average\n[![avatar](https://schaeffers-cdn.s3.amazonaws.com/images/default-source/schaeffers-cdn-images/headshots/fernanda-horner.tmb-0.jpg?sfvrsn=aaa9dd06_1)](https://www.schaeffersresearch.com/author?author=Fernanda+Horner)\n[Fernanda Horner](https://www.schaeffersresearch.com/author?author=Fernanda+Horner)\nDigital Content Manager\nDec 24, 2025\nat 10:37 AM\n* [ASTS](https://www.schaeffersresearch.com/Search?tag=asts)\n[![facebook](https://www.schaeffersresearch.com/assets/v3/images/icons/facebook-square.png)](https://www.facebook.com/sharer/sharer.php?kid_directed_site=0&sdk=joey&u=https://www.schaeffersresearch.com/content/news/2025/12/24/ast-spacemobile-falls-despite-successful-satellite-launch&display=popup&ref=plugin&src=share_button)[![X logo](https://www.schaeffersresearch.com/assets/v3/images/icons/x-square.png)](https://twitter.com/intent/tweet?url=https://www.schaeffersresearch.com/content/news/2025/12/24/ast-spacemobile-falls-despite-successful-satellite-launch)[![linkedin](https://www.schaeffersresearch.com/assets/v3/images/icons/linkedin-square.png)](http://www.linkedin.com/shareArticle?mini=true&url=https://www.schaeffersresearch.com/content/news/2025/12/24/ast-spacemobile-falls-despite-successful-satellite-launch)\n![Space stocks, Spaceship stocks, Rocket stocks, Satellite stocks](https://schaeffers-cdn.s3.amazonaws.com/images/default-source/schaeffers-cdn-images/default-images/sectors/bigstock-sunset-of-earth-planet-silhoue-404598074.jpg?sfvrsn=c6a8d806_4)\nThe Starlink rival is closer to offering space-based mobile connectivity\n**AST SpaceMobile Inc****(NASDAQ:ASTS)**stock is down 5.3% at $81.18 at last glance, the Starlink rival brushing off the successful launch of BlueBird 6. The satellite, AST's largest ever launched, puts the Starlink rival much closer to offeringspace-based mobile connectivity.\nDespite today's tumble, ASTS sports a 299% year-to-date lead.[**The stock**](https://www.schaeffersresearch.com/content/analysis/2025/11/06/ast-spacemobile-stock-falls-from-highs-before-earnings)traded as high as $92.95 out of the gate, but is now back below $90. There's contrarian potential to help the shares make another run at their Oct. 16 record high of $102.79.\nFor starters, analysts lean pessimistic, with seven of the 11 in question sporting a tepid \"hold\" rating, while the 12-month consensus target price of $73.23 is a 10.5% discount to current levels. Shorts are also in control, with the 36.62 million shares sold short accounting for 16.3% of the equity's available float.\nDrilling down to today's options activity, 75,000 calls and 40,000 puts have exchanged hands so far, which is six times the volume typically seen at this point. The most active contract the weekly 12/26 95-strike call.\n[Follow @Schaeffers](https://twitter.com/Schaeffers)\n**[$40 Gets You 4 High-Conviction Trades. Let's Go.](https://store.schaeffersresearch.com/offers/2509/totw-40-1-month-trial)**\nWe just booked back-to-back double-digit gains on Celsius and Palantir in**Trade of the Week**, and we&rsquo;re eyeing even bigger wins!\nEvery week starts with a fully defined options trade straight from the desk Schaeffer&rsquo;s Senior V.P. of Research, Todd Salamone, backed by**30+ years**of proven market experience and disciplined risk management.\nRight now, you can get 4 total trades over the next 4 weeks for $40 &ndash; just $10 per trade.\n[\ud83d\udc49**Sign Up Now to Receive Your First Trade!**](https://store.schaeffersresearch.com/offers/2509/totw-40-1-month-trial)\n[![tesla](https://www.schaeffersresearch.com/images/default-source/default-album/tesla3b78d07823936f13b9ccff000047db6d.png?sfvrsn=e7ebbf06_0&amp;MaxWidth=450&amp;MaxHeight=600&amp;ScaleUp=false&amp;Quality=High&amp;Method=ResizeFitToAreaArguments&amp;Signature=B05D1F8EC57CD47F75A5F582B8B8F01D330B349F \"tesla\")](https://store.schaeffersresearch.com/offers/2510/vot-995-lifetime)\nLIVE Trading Closeout Tracker\n[\nOptions Under $5\nRKLBCall+342%!\nProfit taken 12/19\n](https://store.schaeffersresearch.com/products-services/real-time-alert-services/options-under-$5)[\nExpiration Week Countdown PLUS\nRCLCall+145%!\nProfit taken 12/19\n](https://store.schaeffersresearch.com/products-services/weekly-monthly-newsletters/expiration-week-plus)[\nPowerTrend\nJPMCall+100%!\nProfit taken 12/19\n](https://store.schaeffersresearch.com/products-services/real-time-alert-services/powertrend)[\nVolatility Trader\nDKNGStraddle+109%!\nProfit taken 12/12\n](https://store.schaeffersresearch.com/products-services/real-time-alert-services/volatility-trader?_ga=2.119363210.227857116.1580834805-1479985833.1578497727)[\nIn The Money Countdown\nGAPCall+150%!\nProfit taken 12/11\n](#)[\nSchaeffer\u2019s Weekly Volatility Trader\nTEVAStraddle+102%!\nProfit taken 12/10\n](https://store.schaeffersresearch.com/products-services/real-time-alert-services/weekly-volatility-trader)[\nOptions Under $5\nMDTCall+218%!\nProfit taken 12/8\n](https://store.schaeffersresearch.com/products-services/real-time-alert-services/options-under-$5)[\nWeekend Trader Alert\nRKLBCall+111%!\nProfit taken 12/8\n](https://store.schaeffersresearch.com/products-services/weekly-monthly-newsletters/weekend-trader-alert)[\nWeekly Options Countdown Plus\nWMTCall+300%!\nProfit taken 12/5\n](#)[\nOption Advisor\nGMCall+102%!\nProfit taken 12/5\n](https://store.schaeffersresearch.com/products-services/weekly-monthly-newsletters/option-advisor)\n[![Follow us on X, Follow us on Twitter](https://schaeffers-cdn.s3.amazonaws.com/images/default-source/schaeffers-cdn-images/marketing/follow-us-on-x-follow-us-on-twitter.png?sfvrsn=32dea306_0 \"Follow us on X, Follow us on Twitter\")](https://x.com/schaeffers)\nAbout Schaeffer's\n[Who We Are](https://www.schaeffersresearch.com/about-us)\n[More about Bernie](https://www.schaeffersresearch.com/about-bernie-schaeffer)\n[Business Hours](https://www.schaeffersresearch.com/contact-us)\n[Schaeffer's Sitemap](https://www.schaeffersresearch.com/sitemap)\nHow Can We Help?\n[Access Your Account](https://myaccount.schaeffersresearch.com)\n[Contact Us](https://www.schaeffersresearch.com/contact-us)\n[Privacy Policy](https://www.schaeffersresearch.com/privacy-policy)\n[Legal Notices](https://www.schaeffersresearch.com/legal-notice)\nPremium Products\n[Trading Services](https://store.schaeffersresearch.com/)\n[Educational Programs](https://store.schaeffersresearch.com/product-details/education-and-courses)\n[Deal of the Week](https://www.schaeffersresearch.com/current-promotion)\n[Free Market Newsletters](https://store.schaeffersresearch.com/product-details/free-publications)\nLet's get social:\n[![X logo](https://cdn.schaeffersresearch.com/images/default-source/schaeffers-cdn-images/optimized-website-images/social-media-buttons-and-icons/x-2-240.png)](https://twitter.com/schaeffers)[![Facebook logo](https://cdn.schaeffersresearch.com/images/default-source/schaeffers-cdn-images/optimized-website-images/social-media-buttons-and-icons/facebook-2-240.png)](https://www.facebook.com/schaeffersinvestmentresearch/)[![Instagram logo](https://cdn.schaeffersresearch.com/images/default-source/schaeffers-cdn-images/optimized-website-images/social-media-buttons-and-icons/instagram-2-240.png)](https://www.instagram.com/schaeffers_research/)[![YouTube logo](https://cdn.schaeffersresearch.com/images/default-source/schaeffers-cdn-images/optimized-website-images/social-media-buttons-and-icons/youtube-7-240.png)](https://www.youtube.com/user/Schaeffers/)[![Linkedin logo](https://cdn.schaeffersresearch.com/images/default-source/schaeffers-cdn-images/optimized-website-images/social-media-buttons-and-icons/linkedin-2-240.png)](https://www.linkedin.com/company/schaeffer's-investment-research)\nPayments Accepted:\n[![Master Card logo](https://cdn.schaeffersresearch.com/images/default-source/schaeffers-cdn-images/optimized-website-images/payment-methods/mc-transparent.png)](#)[![Visa logo](https://cdn.schaeffersresearch.com/images/default-source/schaeffers-cdn-images/optimized-website-images/payment-methods/visa-transparent.png)](#)[![Discover logo](https://cdn.schaeffersresearch.com/images/default-source/schaeffers-cdn-images/optimized-website-images/payment-methods/discover-transparent.png)](#)[![AmEx logo](https://cdn.schaeffersresearch.com/images/default-source/schaeffers-cdn-images/optimized-website-images/payment-methods/amex-transparent.png)](#)[![PayPal logo](https://cdn.schaeffersresearch.com/images/default-source/schaeffers-cdn-images/optimized-website-images/payment-methods/paypal-transparent.png)](#)\n&copy;2021Schaeffer's Investment Research, Inc.\n5151 Pfeiffer Road, Suite 450, Cincinnati, OH 45242\nAll Rights Reserved. Unauthorized reproduction of any SIR publication is strictly prohibited.", "embedding": [-0.03834057226777077, -0.005935327615588903, 0.09042829275131226, 0.04600709676742554, -0.009431115351617336, -0.011346038430929184, -0.06434545665979385, 0.05388231948018074, 0.018881957978010178, 0.011662175878882408, -0.017822127789258957, 0.09055906534194946, -0.05271812155842781, 0.0371989868581295, -0.01824239082634449, -0.05326645076274872, 0.00845809280872345, -0.10949287563562393, -0.0986197367310524, 0.06792161613702774, -0.022515323013067245, 0.0318320170044899, -0.023507991805672646, 0.02324174903333187, 0.0672696977853775, -0.0627761110663414, -0.061391353607177734, -0.03943713754415512, -0.040069252252578735, -0.07032185792922974, -0.023333748802542686, 0.07797454297542572, 0.010664127767086029, 0.07606828212738037, 0.008525753393769264, -0.040152113884687424, -0.03752589225769043, -0.05863663926720619, 0.07551388442516327, -0.01163538172841072, 0.010345014743506908, -0.03213489428162575, -0.03712470084428787, 0.09613034129142761, -0.03556139022111893, -0.0016743098385632038, -0.03822333365678787, -0.1041923314332962, 0.02488710545003414, 0.019669748842716217, -0.1010499969124794, 0.04204682633280754, 0.021795209497213364, -0.028703127056360245, -0.06865180283784866, -0.0031235567294061184, -0.08629385381937027, -0.0012519602896645665, 0.11037007719278336, -0.007327939383685589, 0.05575636774301529, -0.03602319583296776, -0.028356127440929413, 0.008790229447185993, -0.0014069860335439444, 0.01940002664923668, -0.026530567556619644, 0.04247583448886871, -0.027574922889471054, 0.06414647400379181, 0.025651931762695312, 0.05122445523738861, -0.10808179527521133, 0.005533927120268345, 0.014413408935070038, 0.051805827766656876, 0.030016547068953514, -0.03222190961241722, 0.03351442515850067, -0.006793443579226732, 0.039529915899038315, -0.017205683514475822, -0.0898597463965416, 0.009740469977259636, -0.04850076138973236, -0.03481224179267883, 0.014608417637646198, 0.10134923458099365, 0.025922643020749092, -0.016543148085474968, 0.04181670397520065, 0.03672759607434273, 0.011899246834218502, 0.06903838366270065, -0.016120322048664093, -0.011322899721562862, -0.003594718175008893, -0.08444669097661972, -0.026898112148046494, 0.00011454199557192624, 0.08425427973270416, 0.02539810538291931, -0.012045432813465595, 0.05977097153663635, -0.001530243782326579, -0.15919455885887146, 0.02603500708937645, 0.011839920654892921, -0.0097539983689785, -0.01234413217753172, -0.05825985223054886, 0.018270274624228477, 0.0026379209011793137, -0.025384707376360893, -0.08242729306221008, 0.10405439138412476, -0.09263826906681061, 0.020593997091054916, 0.04164833202958107, 0.01902979239821434, 0.02007487043738365, 0.028195006772875786, -0.02967611514031887, -0.02392643131315708, 0.0031327710021287203, 0.0709134191274643, -0.0021382602863013744, 6.380817700449572e-33, -0.04662878066301346, -0.013783248141407967, 0.0023540998809039593, -0.008982040919363499, -0.014032794162631035, -0.04213631525635719, -0.03729197755455971, 0.016553571447730064, -0.027147304266691208, -0.012408734299242496, -0.049224916845560074, 0.018727699294686317, -0.07131829112768173, -0.019633669406175613, 0.020976953208446503, -0.10472947359085083, 0.023090507835149765, 0.03522194176912308, -0.024394482374191284, -0.00338012189604342, 0.017362529411911964, -0.008325268514454365, -0.048816755414009094, -0.01462144311517477, 0.06078965216875076, 0.014207160100340843, 0.029343323782086372, -0.006938650738447905, -0.005501249339431524, 0.04462435841560364, -0.06094907224178314, 0.02783176302909851, -0.02246476523578167, 0.007514629513025284, -0.005031416192650795, -0.032450783997774124, -0.050263822078704834, -0.017003100365400314, -0.03198475390672684, -0.052889518439769745, -0.03809438273310661, 0.0033872579224407673, -0.12025105953216553, -0.001902685035020113, -0.010871943086385727, -0.000992867280729115, 0.010276529006659985, 0.008866304531693459, 0.0721619501709938, 0.051655255258083344, -0.08810886740684509, 0.11964137852191925, -0.02740396186709404, -0.05119249224662781, 0.03152203559875488, 0.035281404852867126, 0.01298801600933075, -0.021151570603251457, -0.00899228360503912, 0.10527577251195908, 0.05352744087576866, -0.027817493304610252, 0.021594418212771416, -0.047466326504945755, -0.10435464978218079, 0.04160366207361221, 0.006896946579217911, -0.003071162151172757, -0.05640871450304985, 0.067744180560112, 0.02470681071281433, -0.03922338783740997, 0.08924616128206253, -0.043835144490003586, 0.009728056378662586, -0.0004119271761737764, 0.028481721878051758, 0.01921815238893032, 0.00300574884749949, -0.06216273084282875, 0.03902708366513252, -0.02007564716041088, 0.04875222221016884, -0.09853415936231613, 0.08068108558654785, 0.003930964507162571, 0.018720842897892, -0.08677476644515991, -0.016178345307707787, 0.0682084858417511, -0.05500884726643562, -0.06300362199544907, -0.08495976775884628, 0.0315755158662796, 0.0009417503606528044, -7.57772074213621e-33, 0.039823196828365326, -0.0022824625484645367, -0.029159337282180786, 0.008416885510087013, -0.028142385184764862, 0.02751261554658413, 0.040681470185518265, 0.15399165451526642, 0.017593780532479286, 0.03450603783130646, -0.026942577213048935, 0.06462471932172775, -0.02802868001163006, -0.031264808028936386, -0.03731309995055199, -0.03447318449616432, 0.10405182838439941, -0.05400613695383072, 0.08934451639652252, 0.06300172954797745, 0.018920745700597763, 0.011778031475841999, -0.07283779978752136, 0.13291259109973907, 0.01713336631655693, 0.0879986435174942, 0.034570157527923584, 0.06017123535275459, -0.06378208100795746, -0.026365432888269424, 0.017871294170618057, -0.029678665101528168, -0.03515946865081787, 0.03607451543211937, 0.039836663752794266, 0.0445428341627121, 0.0437987744808197, 0.00663224421441555, -0.09313507378101349, 0.009463632479310036, 0.01298291701823473, 0.020384106785058975, 0.0618506595492363, 0.0021555577404797077, 0.012262316420674324, -0.04538765549659729, 0.036301083862781525, 0.012091814540326595, 0.05570746213197708, 0.010097423568367958, 0.023831453174352646, -0.04209476336836815, -5.186982161831111e-05, 0.06142578274011612, -0.009126381948590279, 0.02635877951979637, 0.014562642201781273, -0.054069533944129944, -0.057679858058691025, -0.012460584752261639, 0.07066292315721512, -0.009521076455712318, 0.008807501755654812, -0.08665649592876434, -0.01914101466536522, -0.11905378848314285, 0.0372578464448452, -0.03615308552980423, 0.0022805966436862946, 0.020009445026516914, -0.011719023808836937, -0.0415850393474102, -0.04114709794521332, -0.08486331254243851, 0.014047246426343918, 0.03363405913114548, -0.03591679036617279, 0.014163564890623093, 0.015403282828629017, 0.031108833849430084, -0.05039937421679497, 0.09589145332574844, -0.02234346978366375, -0.007814100943505764, -0.007189740892499685, 0.02817823551595211, 0.008681587874889374, 0.026967240497469902, -0.043411657214164734, 0.08833660930395126, -0.07695779204368591, -0.009662984870374203, 0.013609676621854305, 0.16115981340408325, -0.030139625072479248, -6.726151013936033e-08, 0.0664551705121994, -0.011529271490871906, -0.023122230544686317, -0.008540533483028412, 0.03394550830125809, -0.10563693195581436, 0.027835607528686523, 0.01955225318670273, 0.022092629224061966, 0.052344582974910736, 0.06583477556705475, -0.07895423471927643, -0.0850093737244606, 0.046936579048633575, -0.0629371777176857, -0.06408275663852692, -0.09454215317964554, 0.10613469779491425, -0.022075241431593895, -0.04341588169336319, 0.02948799915611744, 0.03834243491292, 0.0547911673784256, -0.0179184190928936, 0.08295069634914398, 0.10428643971681595, -0.015941400080919266, 0.04824873432517052, 0.07285438477993011, 0.043481405824422836, -0.053023193031549454, -0.019953323528170586, 0.0009739900124259293, -0.08117913454771042, -0.1252734363079071, -0.015622259117662907, 0.05250714719295502, 0.002729185624048114, 0.0687161460518837, 0.05774969607591629, 0.005642565432935953, -0.06627989560365677, -0.009513868018984795, 0.004566447343677282, 0.006871999241411686, -0.0012766512809321284, -0.06058718264102936, 0.05072547867894173, 0.05300867557525635, -0.030625903978943825, -0.006536614149808884, -0.06387296319007874, -0.08240904659032822, 0.0496714785695076, 0.0789935290813446, -0.008711173199117184, -0.0653853714466095, 0.02161608450114727, -0.019459383562207222, 0.03298906609416008, 0.016385376453399658, -0.0984010323882103, -0.0928482711315155, 0.1082775741815567]}, {"id": "69516515928c45e466b93213", "user_id": "CarlFristam", "title": "Powerful Graph Neural Networks for Money Laundering ...", "text": "Utrecht University\nComputing Science\nMaster\u2019s Thesis\nPowerful Graph Neural Networks for\nMoney Laundering Pattern Detection\nAuthor:\nStan Verlaan\nICA-6813526\nSupervisors:\nDr. E.J. van Leeuwen\nDr. I.R. Karnstedt-Hulpus\nSecond examiner:\nProf. dr. H.L. Bodlaender\nA thesis submitted in fulfillment of the requirements\nfor the degree of Master of Science\nin the\nFaculty of Science\nDepartment of Information and Computing Science\nJuly 12, 2024\ni\nAcknowledgements\nI would like to express my deepest gratitude to my supervisors, dr. Erik Jan van Leeuwen\nand dr. Ioana Karnstedt-Hulpus, for their invaluable guidance throughout the course of my\nmaster\u2019s thesis. Their expertise, insights, and constructive feedback have been instrumental in\nshaping this work. Additionally, I would like to thank prof. dr. Hans Bodlaender for reading\nand judging my thesis. I am also thankful to Vahid, Ram\u00f3n and Karen for our bi-weekly\ngroup sessions and lunches, where I could share my progress, receive helpful suggestions, and\ndraw inspiration from their work on similar projects. I extend my gratitude to my fellow\nstudents and good friends for the fun we have had over the past five years and to my parents\nand brother for always supporting me. Lastly, I want to express my sincerest appreciation\nto Lianne for her help, belief and encouragement throughout this project. You have the\nbest patience and always provide me with much-needed distraction during the evenings and\nweekends. Thank you.\nii\nAbstract\nPowerful Graph Neural Networks for\nMoney Laundering Pattern Detection\nby Stan Verlaan\nThis research enhances graph neural networks (GNN) for identifying suspicious accounts\ninvolved in money laundering. Extending the work of Egressy et al. (2024), we modify and\npropose a set of techniques that enable GNNs to detect suspicious subgraph patterns in the\nweighted temporal networks underlying financial data. These techniques include a novel\nmessage passing scheme, which allows for the indication of edge directionality within a single\naggregator function, element-wise edge weight multiplication, and an LSTM aggregator that\ncan learn from the sequential order of edges imposed by timestamps. Our LAS-GNN model\nis based on an inductive learning framework and can generalize across different networks.\nExperimental results on synthetic networks show that LAS-GNN is robust and can identify\nbasic money laundering patterns, such as smurfing motifs and simple cycles up to length\n6, to near perfection, outperforming a graph isomorphism network benchmark with edge\nfeatures. While the primary focus is on the financial crime domain, the findings have broader\napplications in dynamic network settings.\niii\nContents\nAcknowledgements i\nAbstract ii\n1 Introduction 1\n1.1 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.2 Our Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n2 The State of Money Laundering Detection 4\n2.1 Transaction-Based Machine Learning for AML . . . . . . . . . . . . . . . . . . . . 4\n2.1.1 Supervised Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.2 Unsupervised Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.2 Graph-based Approaches for AML . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2.1 Domain-led . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.2.2 Graph-based Features . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.2.3 Random Walk Embeddings . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2.2.4 Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n3 Graph Neural Networks 13\n3.1 Transductive vs. Inductive . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n3.2 Graph Convolutional Network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.3 Inductive Representation Learning . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3.1 GraphSAGE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.3.2 Graph Isomorphism Network . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.4 GNN Techniques for Graph Pattern Finding . . . . . . . . . . . . . . . . . . . . . 18\n3.4.1 Modelling Node Identity . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.4.2 Modelling Edge Directionality . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.4.3 Modelling Weights . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n3.4.4 Modelling Time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n4 Method 21\n4.1 Money Laundering Patterns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n4.2 Modelling Edge Directionality: Signed Message Passing . . . . . . . . . . . . . . 22\n4.3 Modelling Weights: Edge Weight Multiplication . . . . . . . . . . . . . . . . . . . 23\n4.4 Modelling Time: LSTM Aggregation . . . . . . . . . . . . . . . . . . . . . . . . . 23\n4.4.1 Long Short-Term Memory . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.4.2 LSTM Aggregator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.5 The LAS-GNN Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.6 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n4.6.1 Ego IDs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n4.6.2 Signed Message Passing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\niv\n5 Experimental Setup 29\n5.1 Synthetic Network Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.1 Directed Watts-Strogatz Model . . . . . . . . . . . . . . . . . . . . . . . . 29\n5.1.2 Network Parameter Settings . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.1.3 Edge Weights and Timestamps . . . . . . . . . . . . . . . . . . . . . . . . 32\n5.1.4 Ground Truth . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n5.2 Model Training . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n5.3 Compared Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n5.4 Evaluation Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.4.1 Confusion Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.4.2 Accuracy, Precision, Recall, F1-score . . . . . . . . . . . . . . . . . . . . . 35\n5.4.3 Precision-Recall Curve, Average Precision . . . . . . . . . . . . . . . . . . 36\n5.5 Technical Specifications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n6 Results 38\n6.1 Preliminary Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n6.1.1 Edge Directionality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n6.1.2 Number of GNN Layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6.1.3 Number of LSTM layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n6.2 Unweighted Non-temporal Detection . . . . . . . . . . . . . . . . . . . . . . . . . 42\n6.3 Weighted Non-temporal Detection . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n6.3.1 Edge Weight Similarity Task . . . . . . . . . . . . . . . . . . . . . . . . . 44\n6.4 Unweighted Temporal Detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n6.5 Weighted Temporal Detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n6.6 Longer Cycle Detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n7 Discussion 51\n7.1 Discussion of Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n7.2 Experimental Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n7.3 Model Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n8 Conclusion 53\nBibliography 54\nA Weighted Non-temporal Detection 60\nA.1 Gather-scatter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\nA.2 C3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\nB Weighted Temporal Detection 62\nB.1 Gather-scatter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\nB.2 Scatter-gather . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\nB.3 C3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\n1\nChapter 1\nIntroduction\n1.1 Background\nMoney laundering (ML) is the process of concealing the origin of illegitimately obtained money. It\ninvolves the conversion of illicit funds into seemingly legitimate assets. This \u201cdirty\u201d money can be\nobtained from all sorts of illegal activities, such as embezzlement, drug and human trafficking, and\nthe funding of terrorist organizations, and is disguised so that it can be used without the detection\nof said activities. According to the United Nations Office on Drugs and Crime (UNODC), between\n2% to 5% of the global Gross Domestic Product (GDP) can be attributed to money laundering,\nwhich amounts to 800 billion to 2 trillion US dollars. This makes the money laundering business\none of the largest industries in the world. With the growth of global economy, e-businesses and\nonline transactions, it is predicted that the number of money laundering crimes will continue to\nincrease (Zhang et al., 2003). The implications this has for both the economy and society as a\nwhole are significant and wide-ranging. Aimless movement of large funds can have destabilizing\neffects on financial systems, and money laundering often goes hand-in-hand with tax and duty\nevasion (Capgemini). Furthermore, these funds facilitate criminal and terrorist organizations,\nwith obvious consequences for national safety.\nGiven these negative effects, detecting money laundering processes is of paramount importance.\nAnti-Money Laundering (AML) refers to the set of laws, regulations, and procedures designed\nand aimed at detecting, preventing, and prosecuting individuals and entities involved in money\nlaundering. Banks monitor transactions and report suspicious activity based on a set of rules that\nare predefined by domain experts. Such rules and the statistical thresholds related to different\nscenarios are motivated by industry red flags (transactions to suspicious countries) and basic\nstatistical indicators (amounts over a certain threshold), as well as expert judgement (Rompaye).\nEven though this seems like a sensible and straightforward way of translating money laundering\nconcerns into a working system, such rule-based approaches suffer from some drawbacks (Gao\net al., 2009). Sophisticated criminals who are familiar with the rules can easily deceive the system\nand evade detection. In turn, these rule-based systems need to be updated constantly to keep up\nwith the ever-evolving money laundering strategies. Furthermore, static rules may not always\nbe able to capture the complex patterns of money laundering trails. While the scope of a single\nassessment can be broadened to include numerous transactions, this may result in much more\nintricate rules that are prone to implementation errors and whose effectiveness are hard to discern.\nA valuable method used by transaction offices and advocated to banks by De Nederlandse\nBank (DNB) for detecting money laundering processes is the five-step process scheme of topologies\n(De Nederlandse Bank). This method analyzes historical data of transactions and clients based\non established money laundering topologies to identify accounts whose activities are similar to\nthe accounts in such topologies. The newly detected accounts may reveal to be part of novel\nmoney laundering topologies, which in turn can be employed to analyze new historical data.\nHowever, when rule-based approaches are used for matching targets and analyzing the results,\nthe same drawbacks still apply. Moreover, they are often associated with the generation of a\nChapter 1. Introduction 2\nlarge number of false-positives (Gao et al., 2009) and the manual follow-up of the alerts can be a\ntime-consuming and labour-intensive process.\nTo aid in this process, more and more institutions consider the use of machine learning. With\nmachine learning, advanced algorithms can be utilized to identify suspicious money laundering\ncases directly from the data. While this can be much more efficient, it also turns out to be more\nprecise and effective in practice: KPMG Belgium\u2019s experience at a leading bank showed that\ntheir identification of suspicious activity can be improved by up to 40% by replacing rule-based\nand scenario-based tools with machine learning models (Rompaye). Apart from the increase in\nperformance, changing to AI-based solutions can help overcome some limitations of traditional\nsystems, since they are suitable for adapting to new money laundering schemes and can meet the\ndemand of the high volume of transactions performed on a daily basis.\nIn literature, a range of different machine learning models are proposed and their potential\nfor the domain of financial crime is investigated. These comprise anomaly detection algorithms\nand traditional supervised learning approaches that can handle the severe data imbalance related\nto such tasks. Recently, more sophisticated deep learning techniques that utilize the underlying\nnetwork structure of transaction data have emerged. Graph Neural Networks (GNNs) that operate\non graph-structured data can be deployed for classifying accounts suspected of money laundering.\nNevertheless, research into the capabilities of such models for AML is still in its early stages\nand often focus on extensive features while ignoring the structural pattern detection capabilities\nnecessary in the following task: Given one or more graph(s) and multiple examples of one or\nmore suspicious subgraph pattern(s), detect unseen nodes that occur in such pattern(s). While\na GNN can be extended to enable pattern finding of suspicious motifs, weighted and temporal\nproperties are often not explicitly incorporated. As a result, the dynamics of the network are not\ncaptured by the model.\n1.2 Our Contributions\nIn this research, we build upon the work of Egressy et al. (2024) by enhancing and proposing\ntechniques for graph neural networks to leverage the underlying network structure of transaction\ndata for detecting suspicious accounts indicative of money laundering. Instead of directly\nextracting suspicious subgraph patterns from the network, the model performs supervised node\nclassification to identify accounts that show structural resemblance to nodes in a target pattern.\nIn addition to utilizing ego IDs, binary node features designed to detect cycles, we propose\na novel message passing scheme termed signed message passing, an alternative to existing\nheterogeneous schemes. While heterogeneous message passing aggregates messages from incoming\nand outgoing neighbours separately, signed message passing allows for the aggregation of both\ntypes of edges simultaneously while still preserving an indication of the directionality of edges.\nFurthermore, we extend the money laundering patterns (ML patterns) to the context of\nweighted temporal networks by introducing the concepts of weighted patterns and temporal\npatterns. By incorporating edge weight multiplication with signed message passing, our model\ncan detect patterns whose edge weights exceed a certain threshold. To identify temporally ordered\npatterns, we propose an LSTM aggregator that learns from the sequential order of edges imposed\nby timestamps. This LSTM aggregator is seamlessly integrated into the GNN layers, providing\na straightforward and intuitive method of capturing the dynamic characteristics of financial\nnetworks.\nThe developed model, named LAS-GNN, is based on an embedding generation framework\nthat can be used in an inductive setting, allowing for generalization across distinct networks.\nWe test our algorithm on synthetic networks generated by ourselves and compare its detection\nperformance against different baselines, including a graph isomorphism network benchmark that\nincorporates weights and timestamps as edge features. Although our findings can be generalized\nChapter 1. Introduction 3\nand applied to other pattern detection tasks in dynamic network settings, such as molecule\ndetection and traffic forecasting, our focus remains on the financial crime domain of money\nlaundering.\nThis thesis is structured as follows. We begin with an overview of the related literature\nregarding approaches for money laundering detection in Chapter 2. Scientific findings on standard\nmachine learning algorithms and advanced techniques for incorporating network structure are\ndiscussed within the domain of AML. A more in-depth description of graph neural networks\ncan be found in Chapter 3, where we also describe current techniques that extend GNNs for\npattern finding. In Chapter 4, we introduce our proposed techniques and modifications to existing\nmethods, offering a full description of our model. This is followed by Chapter 5, which details\nour experimental setup, including the generation of synthetic networks, training specifications,\ncompared models, and relevant evaluation metrics. The results of our model on the designed\ntasks are presented in Chapter 6, where we also compare its performance to a graph isomorphism\nnetwork and other baselines. The discussion and conclusion of our research can be found in\nChapter 7 and Chapter 8, respectively.\n4\nChapter 2\nThe State of Money Laundering\nDetection\nIn this chapter, we discuss recent scientific developments in Money Laundering Detection (MLD).\nThere is a wide variety of models, which range from domain-led to entirely data-driven. The\npapers discussed here consist of standard, frequently used approaches as well as state-of-the-art\nmodels that together make up an overview of both effective and widely-used approaches for MLD.\nWe refer to more extensive surveys for more information (Labib et al.; Chen et al., 2018).\nA problem related to money laundering detection is fraud detection, which shares many\nsimilarities but differs in modus operandi and patterns identified. While our main focus lies on\nmoney laundering detection specifically, we come across some results for fraud detection in the\ndiscussed literature. Two surveys on fraud detection specifically can be found here: (Adewumi\nand Akinyelu, 2017; Ali et al., 2022).\nOur overview of detection approaches for money laundering begins in Section 2.1 with more\ntraditional supervised machine learning and anomaly detection algorithms that directly operate\non transaction data. Subsequently, we discuss graph-based approaches that explicitly utilize the\ngraph structure of a financial network in Section 2.2.\n2.1 Transaction-Based Machine Learning for AML\nIn Chapter 1, we discussed the downsides of the conventional rule- and scenario-based systems that\nare still primarily used at financial institutions today. Over the past decade, extensive research\nhas been conducted on automated AI-based solutions aimed at money laundering detection,\nwith more and more institutions embracing such methods alongside their traditional systems.\nThese machine learning methods work on data and can be broadly categorized into two types:\nsupervised and unsupervised. Although the former uses labelled data providing information\nabout alerted cases, the latter discovers hidden patterns solely from unlabeled data. Both\nmethods can be applied to transaction data, customer account data, or a combination of both.\nWhile the actual information available may vary across data sets or institutions, examples of\nfeatures in transaction data consists of a transaction volume, date and time, currency, payment\ntype, etc. Account data may comprise the type of account (person, corporate), affiliated bank,\ndemographic information, and more. Note that the account features can be integrated into\ntransaction features by creating corresponding feature columns for the source and target account\nof a transaction separately. Conversely, transaction features related to the same account can\nbe combined (averaged, summed, etc.) to form account features, although such operations may\naffect the expressiveness of the original transaction feature values. Therefore, most studies focus\non approaches analyzing transaction data.\nA problem with transaction data is that the proportion of transactions related to financial\ncrime is exceedingly small. While great for society, this can provide a challenge for learning\nalgorithms. This phenomenon, where instances of a certain class are significantly underrepresented\nin the dataset, is referred to as class imbalance. Especially in domains such as financial crime,\nChapter 2. The State of Money Laundering Detection 5\nwhere detecting the minority class is most crucial, it is important to take this into account\nwhen constructing and evaluating a machine learning model. When assessing a machine learning\nmodel using ground truth, certain performance measures, such as accuracy, can be misleading. A\nclassifier that only predicts the majority class is bound to yield high accuracy, although such a\nmodel is essentially useless for MLD. Therefore, we mostly concern ourselves with the precision\nand recall scores. In our discussion of related literature, we focus on aspects such as the number\nof false positives, false negatives, etc. These metrics are explained in Section 5.4.\n2.1.1 Supervised Learning\nIn the case that labelled data of actual reported money laundering cases is available, it seems\nbeneficial to leverage this information for creating a baseline understanding for the machine\nlearning model.\nIn an empirical study conducted by Zhang and Trubey (2019), five prominent supervised\nmachine learning algorithms are compared on the binary classification task of whether a transaction\nqualifies as a money laundering event or not. The authors used real-world transaction data\nprovided by a non-disclosed U.S. financial institution. All transactions were initially alerted\nas suspicious, but less than one per cent was ultimately flagged as SAR. The objective was to\ndistinguish the escalated alerts that were reported to the Financial Crimes Enforcement Network\n(FinCEN) from the inconsequential alerts. To handle the class imbalance, the authors also applied\ntwo sampling schemes to increase the relative presence of these events. These sampling schemes\ninvolved over-sampling the minority class (escalated alerts) and under-sampling the majority\nclass (insignificant alerts). The implemented algorithms include Bayes logistic regression (BLR),\ndecision tree (DT), random forest (RF), support vector machine (SVM), and artificial neural\nnetwork (ANN). These models were built using ten non-disclosed explanatory variables from a\nset of roughly a hundred variables based on rich information from the transactions and customer\ncharacteristics, including risk rate, age and location.\nResults revealed that without sampling, the ANN performed best with an Area Under the\nROC Curve (AUC) of 0.74, while the SVM was the worst with an AUC of 0.60. However, while\nthe ANN model showed resilience against the sampling schemes, the SVM became the second-best\nclassifier in the case of under-sampling and even surpassed ANN as the best-performing model in\nthe case of severe over-sampling. The finding that SVM performs well on more balanced data sets\nbut not on the original, skewed data is reiterated by Alarab et al. (2020). The decision tree model\ngained from both sampling schemes but was consistently ranked as the worst performing classifier\nfor each event rate, apart from the scenario without any sampling. Despite its lower predictive\nperformance, decision trees can be valuable for identifying new rules that can conveniently be\nintegrated into traditional rule-based systems, something done by Wang and Yang (2007) based\non customer profiles of a Chinese bank. The random forest showed strong performance both with\nand without sampling.\nAlarab et al. (2020) combined different supervised classification models, including RF, Extra\nTrees and Bagging classifier, into an ensemble model that outperformed each individual model\nin detecting illicit transactions in the Elliptic dataset, a dataset comprising real-world bitcoin\ntransactions. This is accomplished by simply averaging the classification probabilities obtained\nby these methods. The ensemble method proved to reduce the number of false positives without\nincreasing the false negatives. The authors also noted that one particular model, k-Nearest\nNeighbors (kNN), did not perform well and appears unsuitable for the task of money laundering\ndetection. kNN relies on the k closest neighbours in the feature space to vote for the best class.\nHowever, due to the imbalanced dataset, the voting mechanism is highly likely to be skewed\ntowards the majority class since the numerous negative instances (licit transactions) can easily\noutweigh the small number of positive instances (illicit transactions) in the neighbourhood of\nChapter 2. The State of Money Laundering Detection 6\na suspicious transaction. Furthermore, given that kNN is based on Euclidean distances, it is\ncomputationally expensive, especially in the case of high-dimensional data.\nAt last, we also want to mention the work of Jullum et al. (2020), whose supervised XGBoost\nmodel was trained on three types of historical data from Norway\u2019s largest bank: 1) normal, legal\ntransactions, 2) transactions flagged as suspicious by the bank\u2019s internal alert system, and 3)\npotential money laundering cases reported to the authorities. Their work demonstrates that the\ncommon approach of not using normal or non-reported transactions in the training of a model can\nlead to sub-optimal results. Using a newly proposed performance measure specifically tailored for\ncomparing their method with the bank\u2019s existing AML system, they show that their supervised\nmodel can outperform the traditional rule-based systems many banks rely on.\n2.1.2 Unsupervised Learning\nWhile labelled data can be of great value for the learning algorithm, it may not always be\navailable. Certain financial institutions may lack access to labelled data sets due to privacy\nconcerns, and manually preparing and labelling large data sets can be an expensive and time\u0002consuming endeavour. Additionally, the labelled data may not truly match with the ground truth\nin the first place since 1) it is hard to know whether some alert is actually involved in money\nlaundering and not just suspicious, and 2) a high percentage of money laundering cases are missed\neven by experts. Hence, it is unsurprising that extensive research in money laundering detection\nis concerned with unsupervised learning, where the machine learning techniques rely on a model\nwithout prior knowledge of the data or human supervision. The objective of such methods is to\nidentify hidden structures and patterns as well as (dis)similarities among the data records.\nThe task of discovering rare occurrences in data is commonly known as anomaly detection.\nIn the context of money laundering, this involves identifying unusual transactions or accounts\nwhose behaviour deviates from that of typical accounts. A popular machine learning method\nemployed for outlier detection is the isolation forest. Similar to a random forest, it consists of\nan ensemble of decision trees. However, rather than splitting nodes based on information gain\nderived from class labels, the trees in the isolation forest randomly split data points along a\nfeature dimension and thus do not rely on any supervision. Isolation forests are successfully used\nas the main module for illicit transaction detection by Shokry et al. (2020) and as a subroutine\nwithin a broader detection framework by Labanca et al. (2022) and Dumitrescu et al. (2022). The\nlinear time complexity and low memory usage renders them highly suitable for large datasets.\nAn alternative approach for outlier detection is the One-Class Support Vector Machine (OC\u0002SVM). In contrast to the traditional SVM algorithm that separates the data into several classes,\nthe OC-SVM model is an extension made by Sch\u00f6lkopf et al. (2001) that only considers a single\n\"normal\" class. To detect outliers, OC-SVM creates a boundary around the normal observations\nto isolate them from the anomalous ones. While Alarab et al. (2020) showed that traditional\nSVM performs poorly when the transaction data is highly imbalanced, it is precisely under these\ncircumstances that OC-SVM shows great promise. Tang and Yin (2005) modified the OC-SVM\nalgorithm for AML using a transaction database from an agriculture bank in China. The authors\nconclude that their method is simple and rapid and can be used in real-world systems without\nmuch modification. However, they acknowledge that the model parameters were determined\nthrough trial and error and could be tuned differently for better performance. In the absence of\nlabelled data, model validation and evaluation can be challenging for unsupervised models.\nContrary to previous research, Lorenz (2021) suggest that unsupervised methods solely relying\non anomaly detection are ineffective for real-life AML. They note that in some past experiments,\ndata is synthetically generated to contain outliers by design, something that does not materialize in\nreal-world data. By applying Uniform Manifold Approximation and Projection (UMAP) (McInnes\net al., 2018) on Bitcoin transaction data to visualize the classifications of an isolation forest and\nthe ground truth, the authors show that the illicit transactions in a real-life Bitcoin transaction\nChapter 2. The State of Money Laundering Detection 7\nnetwork are not outlying at all. The observation that not all outliers are illicit and not all illicit\ntransactions are outliers is reasonable in AML, as sophisticated criminals generally attempt to\nmimic normal behaviour. This problem was previously acknowledged by Das et al. (2016) and is\nsaid to be a root cause for the high false positive and high false negative rates frequently associated\nwith these methods. In both studies, the authors overcome this by applying anomaly detection\nalgorithms in a broader active learning framework in which expert feedback is incorporated to\nadjust the detector during an interactive loop. These iterative \"analyst-in-the-loop\" approaches\ncan be classified as semi-supervised since they learn patterns from mostly unlabelled data using\nsmall inputs from human supervision.\n2.2 Graph-based Approaches for AML\nThe methods discussed in Section 2.1 learn directly from the observations specified in the data and\ndo not explicitly leverage the financial network. In this section, we discuss models and approaches\nthat do work with the relations specified by the underlying graph structure. After constructing a\nfinancial graph, with bank accounts and transactions represented by nodes and edges, respectively,\nas illustrated in Figure 2.1, one could apply one of many graph-based approaches. These models\ncan be domain-led or data-driven, and they may explicitly search for suspicious money laundering\nsubgraph patterns or not. In this section, we first discuss some domain-led approaches. Then, we\nproceed with graph-based machine learning models and discuss three promising techniques as\nseen in literature: directly using features derived from the network, generating graph embeddings\nusing random walks, and utilizing more advanced deep learning methods. The latter will be the\nmain focus of our research.\n7 JUL 1100\n3 MAY 1400\n1 JUN\n1200\n27 JUN\n2300\n18 MAY\n950\n15 MAY\n710\n14 JUL 650\n20 JUL 2500\nFigure 2.1: An example of a financial graph, where the edges include a date and an\namount of money. Alerted transactions that together form a cycle are highlighted in red.\n2.2.1 Domain-led\nWhile the primary focus of this thesis is on learning algorithms, we want to mention some notable\nalgorithms for MLD that do not exactly learn in a data-driven manner but use the graph data in\na direct and algorithmic way. These approaches are more domain-led and depend on similarity\nmeasures, database processing, and threshold modelling.\nLi et al. (2020) note a shortcoming of several general-purpose anomaly detection techniques,\nsuch as Fraudar (Hooi et al., 2016), D-Cube (Shin et al., 2017), and HoloScope (Liu et al.,\n2018), that have been developed for discovering structural anomalies in financial graphs. These\napproaches do not focus on money flow across multiple nodes, which is essential for ensuring\naccuracy and resilience against camouflage in ML activities. Instead, the authors propose a novel\nanomalousness metric that captures two money laundering specific traits, namely that 1) transfers\nChapter 2. The State of Money Laundering Detection 8\nare dense due to high volume funds that flow between few nodes, and 2) intermediate accounts\nserve as a bridge and therefore often have a zero-out balance between their weighted in-degree\nand out-degree. Their proposed FlowScope algorithm extracts the densest tripartite subgraph\nfrom the network according to this metric in near-linear time using a priority tree. In order to\nfind more suspicious groups of nodes, the densest subgraph is removed from the network, and the\nalgorithm gets rerun. FlowScope is primarily tested on tripartite subgraphs with a single middle\nlayer, although it also outperforms the previously mentioned algorithms in scenarios involving\ntwo layers of intermediate nodes.\nStarnini et al. (2021) focus on identifying two specific smurf-like motifs in time-evolving\ntransaction networks, namely the gather-scatter and scatter-gather patterns. They detect such\npatterns rapidly, using standard database joins that find common neighbours between different\npairs of nodes within the same time window. However, their approach is predominantly reliant on\na series of pre-processing and post-processing steps. Initially, trustworthy accounts or accounts\nwith activity above a certain threshold are removed, as well as transactions involving a low\namount of money. Furthermore, they ensure that each path of length two includes at least one\ncross-border transaction. They use a specific threshold for the maximum inter-transaction time\nwindow, along with constraints for the minimum total money flow and flow ratio for filtering the\nsuspicious subgraphs in post-processing. The authors extract some notable patterns, visualized\nusing flowcharts. Since this approach relies heavily on rules and thresholds, they intentionally\nleave the values non-disclosed.\nSimilar thresholds are also used in the research of Soltani et al. (2016). They incorporate the\ntemporal and amount similarity between two transactions using a single equation, which is used\nto match transactions where the receiver account of one transaction corresponds to the sender\naccount of the other. The authors subsequently construct a new graph exclusively containing these\nmatching transactions and proceed to filter the nodes based on a designated balance score. Nodes\nwith a balance score exceeding a certain threshold are considered potential money laundering\naccounts and are subjected to further analysis using a structural similarity metric. Finally, groups\nof money launderers are found by an algorithm that iteratively merges nodes that have at least\none common neighbour. Experiments conducted on synthetically generated data show that their\nframework can effectively find scatter-gather patterns without specifically injecting this type of\npattern.\nThe modelling of relationships in constructed graphs has been extensively researched in Social\nNetwork Analysis, and insight from this domain can also be applied in the context of money\nlaundering detection. Dre\u017cewski et al. (2015) construct social networks from bank statements and\nthe National Court Register and assign roles to nodes based on node centralities such as closeness\nand betweenness, page rank, authoritativeness, and other measures. The purpose of these metrics\nis to determine the associations between accounts and the strength of their connections depending\non their financial actions. The authors manage to point out leaders and vulnerabilities in the\nnetwork, paving the way for more in-depth investigations into their connections. A similar\napproach is undertaken by Colladon and Remondi (2017) and they advocate for combining the\ncentrality measures with machine learning approaches for detecting suspicious accounts.\n2.2.2 Graph-based Features\nNote that the domain-led approaches discussed in the previous section do not learn from the\ndata and are hence limited to the static implementation of the algorithms. Consequently, they\ncannot adapt to new complex money laundering patterns and rich feature information cannot be\nincorporated. To overcome this, we now return to the machine learning algorithms described in\nSection 2.1. However, instead of directly fitting some classification model to the transaction data,\nthere has been a lot of interest recently for incorporating the network structure in these learning\nChapter 2. The State of Money Laundering Detection 9\nalgorithms. While the research on graph-based machine learning models for MLD is increasing, it\nhas only been prominent in the last three years (Bakhshinejad, 2023).\nThe most obvious way to incorporate graph structure into a machine learning model is by\nextending it with features derived from the network. The benefit of specifically designed features\nis that they can be based on insights into money laundering motifs and help the machine learning\nalgorithm\u2019s findings become more easily accepted by banking experts. Note that they can help\nincrease the performance of both supervised and unsupervised models. Straightforward examples\nof such features are the incoming- and outgoing degree of a node and node centrality measures,\nsuch as the ones mentioned in Section 2.2.1.\nDumitrescu et al. (2022) expand upon previous research on egonet features for fraud detection,\nas initially explored by Akoglu et al. (2010). The egonet of a specific center node v is the induced\nsubgraph of v and all its immediate neighbours, including the ties among the neighbours. The\nauthors propose a similar subgraph, termed the reduced egonet, where the nodes connected to\nv with only a single edge are removed. It turns out that some features of the reduced egonet\nare biased towards the extreme for certain nodes in ML patterns compared to normal nodes.\nMetrics such as the (relative) out-degree of the reduced egonet are clearly informative for anomaly\ndetection and can be used as indicators for money laundering. Additionally, the authors compute\nrandom walks on the input graph to extract information on the amount of money circulated over\nlong paths, especially in the case of cycles. For each node k, they generate random walks with\ngiven maximum length r, starting or ending in k, and they keep track of the minimum amount\ntransferred along the random walk. The assumption the authors make is that in the usual case\nthere is little correlation between the transactions of the nodes along the random walk, and so\nthis amount is expected to be small. When the amount is large, it may signify money deliberately\ncirculated through many accounts in an attempt to cover their origin. The maximum of this\nminimum value over all random walks of a node k of length at most r is used together with the\nfeatures derived from the reduced egonet as the inputs for an isolation forest to detect accounts in\nML patterns such as fan-in and gather-scatter. Apart from using random walks to calculate direct\nfeatures, they can also be utilized for generating node embeddings, discussed in Section 2.2.3.\nThe streaming model proposed by Sun et al. (2022) introduces the MonLAD algorithm, which\nsequentially processes edges based on their corresponding transaction timestamps. At each step,\nstatistical features of the nodes affected by that transaction are updated. By keeping track of the\naccount residual and balance scores (relating to the amount of money residing in the account),\nthe authors model a key trait of typical money laundering accounts, namely frequently balancing:\naccounts crave to frequently reach a balanced state by fan-outs upon receiving all the money of\nmultiple fan-ins. The additional traits of fast-in and fast-out and high throughput are modelled by\nanalyzing the frequency of balancing and the magnitude of imbalances observed. The concepts of\nbalancing statistics are similar to the proposed FlowScope (Li et al., 2020) and structural similarity\n(Soltani et al., 2016) models discussed in Section 2.2.1 and thus the MonLAD algorithm can be\nconsidered domain-led. However, in contrary to those algorithms, the authors use these statistics\nas input features for their proposed anomaly detection algorithm AnoScore, that identifies outliers\nbased on statistical deviation from a generalized Pareto distribution. Experiments show that\nMonLAD surpasses baselines such as FlowScope in detecting injected ML anomalies while also\nscaling linearly with the number of edges of the stream.\nAn alternative method to incorporate the network into a set of features is by first extracting\nsmall communities of related accounts centred around a single node. Subsequently, existing\nfeatures, such as demographic and transaction features, of the parties within a specific community\nare aggregated to form community-broad features. This approach is adopted by Savage et al.\n(2016), and the resulting community features, along with dynamic features derived from time-series\nanalysis (burst analysis providing an indication of transaction regularity), serve as input for\nsupervised learning using SVM and random forest.\nChapter 2. The State of Money Laundering Detection 10\n2.2.3 Random Walk Embeddings\nWhile graph-based features for a node can be computed directly from the network, an alternative\napproach is to learn node representations. Node representations, also referred to as node\nembeddings, are low-dimensional vector representations of nodes that capture the structural\nand relational information such that it preserves the graph\u2019s topology. A classical example of\na node representation learning algorithm is DeepWalk (Perozzi et al., 2014), whose generated\nembeddings are used as input for downstream machine learning tasks for AML by Wagner (2019).\nBased on techniques from the field of Natural Language Processing, DeepWalk performs a series\nof uniform random walks in the input graph. Such a random walk is treated as a \"sentence\",\nwhere the visited nodes are the \"words\". Truncated random walks are fed into the SkipGram\nalgorithm that learns the probability distribution of the co-occurrence of nodes, from which the\nnode representations can be derived.\nThe Node2Vec algorithm (Grover and Leskovec, 2016) improves upon DeepWalk by introducing\nthe concept of biased random walks, where the walks are guided by two parameters that control\nthe level of local (BFS) and global (DFS) exploration. In the work of Yuan et al. (2020), both\nDeepWalk and Node2Vec embeddings are fed into an OC-SVM and compared in the context of\nfraud detection in Ethereum transaction networks. Their results in detecting phishing scams\nshow that the model using the node representations learned by Node2Vec yields better precision\nand recall. The effectiveness of Node2Vec is also investigated specifically for money laundering\ndetection by Bakhshinejad (2023). Using 100.000 transaction records of the synthetic PAYSIM\ndataset (Lopez-Rojas et al., 2016), the authors carry out cross-validation experiments. They\nsystematically vary parameters such as the size of the embedding vectors, the number of walks,\nand walk length to determine their impact on performance. Their findings indicate that increasing\nthe size of the embedding vectors improves performance initially, although beyond a certain value,\nit does not significantly affect accuracy and may even reduce results marginally. Nevertheless,\nincreasing the number of random walks and the length of the walks can shrink the false positive\nand false negative rates, as can be expected. However, it is important to keep in mind that\nincreasing these parameters comes at the cost of significantly longer running times. Consequently,\nconcerns arise regarding the feasibility of this approach on much larger networks, prompting a\ntrade-off between computational resources and detection accuracy.\n2.2.4 Deep Learning\nThe random walk embedding methods described in the previous section are based on the idea that\nnodes that are close in the graph have similar representations. While there are alternatives to\npurely proximity-based random walk embedding methods, such as the structural-based Struc2Vec\n(Ribeiro et al., 2017), these methods do not take any actual properties of the nodes into account.\nIn other words, rich feature information from account or transaction data is completely ignored\nwhen the classification model solely relies on the embeddings generated by Node2Vec, for instance.\nNaturally, one can include these other features alongside the embeddings to form a larger feature\nset before applying any machine learning algorithm. However, it seems more beneficial to let the\nembeddings be guided by the features in the first place.\nFortunately, such methods exist. Graph Neural Networks (GNN) can learn node and graph\nembeddings by taking both the graph structure and the node features as input. It works by\npropagating information along the edges of the graph to update the node representations. This\nmessage passing, in combination with multiple layers and non-linear activation functions, can\ncapture relationships and complex patterns in the data. In the last few years, GNNs have gained\nextreme popularity and different types of architecture variations are proposed and applied in\nmany domains, including money laundering detection. The most widely used GNN model is the\nGraph Convolutional Network (GCN) introduced by Kipf and Welling (2017), described in more\ndetail in Chapter 3.\nChapter 2. The State of Money Laundering Detection 11\nThe potential of GNNs for anti-money laundering was first demonstrated by Weber et al.\n(2018). The authors argue in favour of more advanced forensic analysis tools and state that\ndeep learning for massive, dynamic graph data is more promising than the use of suspiciousness\nheuristics and must be considered an essential addition to current graph analytic approaches.\nThey perform preliminary testing of graph neural networks applied to a large financial network\n(1M nodes, 9M edges), which is synthetically generated and injected with the basic ML patterns\nusing the AMLSim data simulator (Suzumura and Kanezashi, 2021). Unfortunately, they do\nnot provide classification results but solely report on the running times and scalability of GCN\nand FastGCN, which uses layer-wise sampling for efficiency. They are confident that with the\ndevelopment of high-performance code and memory-efficient graph representations, GNNs are\nwell suited for handling dynamic transaction data at great scale.\nIn recent follow-up research, Egressy et al. (2024) apply all kinds of GNN variations to\nsynthetic data generated by their updated data simulator AMLWorld (Altman et al., 2024). The\nmodels include additional techniques for the Graph Isomorphism Network, which is theoretically\nfound to be the most powerful GNN (Xu et al., 2019), and the Graph Attention Network,\nwhich leverages attention mechanisms. The models and their modifications show great results in\ndetecting the key ML patterns on both synthetic AML data and real-world Ethereum phishing\ndata. The techniques of ego IDs (marking a center node with a distinct binary feature), port\u0002numbering (for distinguishing multi-edges), and heterogeneous message passing (for indicating\nedge directionality), seem to broaden the expressiveness of the GNN architecture. While these\ntechniques were proposed in earlier work of others separately, the authors prove both theoretically\nand experimentally that it is the combination of the three that enables the detection of ML\npatterns in directed multi-graphs. These techniques are described in more detail in Chapter 3.\nThe mentioned models were all applied to large static graphs that contained all the transactions\nwithin a certain period. A common approach here is to use a sliding time-window to divide\nthe network into subgraphs containing the edges whose timestamp are within a certain interval.\nWeber et al. (2019) experimented with integrating the temporal aspects of the data into the GNN\nand proposed EvolveGCN: a model that consists of multiple GCNs, namely one for each time-step,\nwhich are fed into a Recurrent Neural Network to capture the system dynamics. This way, the\nweights of the GCN in a future time-step are updated based on those from the past so that it\ncaptures the evolution of money laundering patterns. However, the model is highly complicated\nand has high computational complexity, making it unsuitable for large networks. Moreover,\nexperiments with the Elliptic Dataset, using the 49 snap-shots in the dataset as time-steps, show\nthat the improvement of EvolveGCN over standard GCN was not substantial at all. Xia et al.\n(2022) and Alarab and Prakoonwit (2023) also consider the combination of GCN with a recurrent\nneural network, namely Long Short Term Memory (LSTM). They propose using a GCN to explore\nspatial structure features in a financial network and then transferring the mined features to an\nLSTM for temporal feature extraction. Although temporal features can be integrated in this way,\nthe network dynamics are not captured.\nWan and Li (2024) also note that existing literature is limited to representing node relationships\nin static graphs. Additionally, they state that performing graph convolutional operations for\nmultiple time steps can cause information leakage issues and excessive smoothing. To address\nthis, they propose the construction of dynamic graph snapshots with symmetrical spatiotemporal\nstructures based on transaction information. In these graph snapshots, each transaction is treated\nas a node and currency flows are regarded as edge relationships. At all times, only one graph\nsnapshot is retained, whose representation is updated after the transaction set of the current\ntime step is processed, achieving dynamic, iterative updates for the model. At each time step,\nmessage passing in the graph snapshot is performed to extract spatial structural features, and\nthe results are subsequently fed into an LSTM network to further extract the temporal features.\nThe novelty lies in their approach to dynamic graph convolution, which combines the embedding\nvalues from the current graph convolution layer of the previous time step and the embedding\nChapter 2. The State of Money Laundering Detection 12\noutput from the previous layer at the current time step. Both embeddings are concatenated and\nfed into a multilayer perceptron (MLP) to update the node states at the current time step.\nAt last, we want to mention two other notable studies that utilize GNNs in their AML\napproach. Instead of using GNNs directly for classifying suspicious accounts or transactions,\nthese methods perform anomaly detection in a more adversarial manner. Li et al. (2023) propose\nDiga, a guided diffusion model. Their semi-supervised model first employs a subgraph sampler,\nwhich extracts the most informative neighbours of each account based on biased PageRank and\nconstructs a subgraph surrounding it. Secondly, these subgraphs are treated as independent\ntraining samples and are fed into a guided diffusion model. This diffusion model attempts to\nrecover the input subgraph to an anomaly-free version. It first injects noise into the subgraph\nand subsequently applies GNN layers that try to reconstruct the original graph in a denoising\nprocess. Eventually, the reconstruction error is used as the anomaly score of each account.\nThe algorithm LaundroGraph by Cardoso et al. (2022) is completely self-supervised and thus\ndoes not use labelled data. Instead, it jointly trains an encoder and decoder that consist of\nmultiple graph convolutional layers by sampling positive instances, which are directed edges in the\ngraph, and non-edges as negative instances. Here, the existing edges are edges from an account\nnode to a transaction node in a bipartite graph. For each instance, the K-hop subgraph also\nserves as input. The GNN is trained using a binary cross entropy loss function in a link prediction\ntask between account-transaction pairs, which essentially corresponds to an anomaly detection\ntask. The model learns the transaction behaviour of accounts, which serves as a reference point\nof expected behaviour used to score the anomalousness of new transactions entering the system.\nThe novelty of this approach comes from the alternative graph representation used and the focus\non applying the method to score newly incoming transactions, which is overlooked by most GNN\napproaches that classify nodes already present in the network.\n13\nChapter 3\nGraph Neural Networks\nAlthough the Graph Neural Network (GNN) model was first proposed in 2005 by Gori et al. (2005)\nand subsequently generalized in 2008 by Scarselli et al. (2008), its application has only gained\nwide attention in recent years. In this chapter, we discuss two different settings for learning on\ngraphs: transductive and inductive learning. We first discuss the most prominent example of the\nformer and arguably the most influential GNN, the Graph Convolutional Network, in Section 3.2.\nThen, we focus on a general inductive framework that seems more appropriate for our problem\nand describe the popular GraphSAGE and Graph Isomorphism Network models in Section 3.3.\nFinally, in Section 3.4, we discuss specific techniques that extend these inductive GNN models for\npattern detection. For a more complete survey of GNN architectures, challenges, and applications,\nwe refer to Khemani et al. (2024).\n3.1 Transductive vs. Inductive\nWhile graph neural networks are end-to-end frameworks useful in a variety of tasks, such as node\nclassification and link prediction, they are essentially tools for generating embeddings similar\nto the random walk methods discussed in Section 2.2.3. Such approaches often require that all\nnodes in the graph are present during training, meaning that they are inherently transductive.\nWhen training the model for node classification for instance, all information is used with the\nexception of the labels of the nodes in the test set. Consequently, transductive methods can only\ngenerate embeddings for a single fixed graph and they cannot learn to generalize across different\ngraphs (Song et al., 2022). These methods are often useful in tasks where the network exhibits a\ncertain degree of homophily, meaning that similar nodes are more likely to connect than dissimilar\nnodes. Consequently, nodes of the same type tend to cluster together, a phenomenon commonly\nobserved in social network analysis (McPherson et al., 2001).\nHowever, transductive learning seems less appropriate in evolving or dynamic graphs, since\nthese methods are not able to efficiently generalize to unseen nodes; as soon as a new node is added,\nit is necessary to retrain the model. In these cases, an inductive framework seems better suited,\nwhere the model leverages node feature information to efficiently generate node embeddings for\npreviously unseen data. We argue that for money laundering detection specifically this is more\nappropriate, since new transactions are made constantly and bank accounts can be opened and\nclosed. Furthermore, it can be the case that labeled data (known money laundering cases) that\nwe want to leverage comes from a different period or dataset than the data we want to make\npredictions on. Moreover, in our endeavour to identify money laundering patterns, we assume\nthe network exhibits a certain degree of heterophily. Although suspicious nodes are connected to\nother suspicious nodes within the same ML pattern, such patterns tend to be relatively small.\nWhen we consider the suspicious nodes from distinct patterns, there is no assumption on how\nclosely they are located in the graph. In other words, the ML patterns we seek can be distributed\nacross the entire network and we must learn to recognize the structural properties of a node\u2019s\nneighbourhood that generalize between patterns. The inductive setting seems better suited to\nthis notion of heterophily. Both settings are illustrated in Figure 3.1.\nChapter 3. Graph Neural Networks 14\nTest dataset\nTest dataset Training dataset\nTransductive\nInductive\nFigure 3.1: Transductive learning versus inductive learning for node classification. Image\nrecreated from Song et al. (2022).\n3.2 Graph Convolutional Network\nThe Graph Convolutional Network (GCN) is an inherently transductive method. Similar to\nmost GNN variations that came after, GCN aims to generalize well-established neural models\nlike Recurrent Neural Networks (RNN) and Convolutional Neural Networks (CNN) to work on\narbitrarily structured graphs. They all share a somewhat general architecture where the objective\nis to learn a function on a graph G = (V, E) which takes as input\n\u2022 the adjacency matrix A, which describes the graph structure of G,\n\u2022 an N \u00d7 D feature matrix X, which summarizes a feature description xv for each node v \u2208 V\n(N is the number of nodes, D the number of input features per node),\nand produces a node-level output Z, which is an N \u00d7 F matrix with F the number of output\nfeatures per node. We can then write every neural network layer as a non-linear function f as\nfollows. For any k \u2265 1\nH(k) = f(H(k\u22121), A), (3.1)\nwith H(0) = X and H(K) = Z, where K is the total number of layers. The specific models then\nvary solely based on how f(\u00b7, \u00b7) is chosen and parameterized.\nA simplistic layer-wise propagation rule is\nH(k) = f(H(k\u22121), A) = \u03c3(AH(k\u22121)W(k)). (3.2)\nHere W(k)is the weight matrix for layer k, and \u03c3(\u00b7) is a non-linear activation function like ReLU.\nAlthough this propagation rule can already be quite powerful on its own, there are two limitations\nthat need to be fixed.\nFirst, in case there are no self-loops in the graph, the multiplication of A sums up all the\nfeature vectors of the neighbouring nodes for each node, but excludes the node itself. A simple\nfix is to add the identity matrix I to A such that self-loops are enforced.\nChapter 3. Graph Neural Networks 15\nSecondly, A must be normalized such that all rows sum to one. Otherwise, the scale of the\nfeature values will completely change after the multiplication. Normalization is often achieved by\nan additional multiplication with the inverse of the diagonal node degree matrix D. Multiplying\nwith D\u22121A in the layer propagation rule now amounts to averaging neighbouring node features.\nSymmetric normalization, i.e. D\u2212 1\n2 AD\u2212 12 , is more commonly used and provides more interesting\nresults.\nAfter applying these two modifications, we essentially get the propagation rule used by the\nGCN model:\nH(k) = \u03c3(D\u02dc \u2212 1\n2 A\u02dcD\u02dc \u2212 12 H(k\u22121)W(k)\n). (3.3)\nwhere A\u02dc = A + I and D\u02dc is the diagonal node degree matrix of A\u02dc.\nIn the training phase, the weights in the weight matrices W(1), . . . , W(K) are learned using a\nloss function. After forward propagation through the network, a sigmoid function is applied to\nthe last layer, which yields the current predicted probability outcomes for the node class labels in\ncase of node classification. For supervised learning, the cross entropy loss is then computed using\nthe actual known class labels. For binary classification, this binary cross entropy loss function is\nas follows:\nLBCE = \u2212\n1\nN\nX\nN\ni=1\n\u2212\n\nyi\u00b7 log(pi) + (1 \u2212 yi) \u00b7 log(1 \u2212 pi)\n\u0001\n, (3.4)\nwhere piis the predicted probability of class 1 and yiis the actual class label. The loss measures\nthe difference between the predicted binary outcomes and actual binary labels, which is desired\nto be as low as possible. After calculating the loss, it is back-propagated and the weight matrices\nin each layer are updated using stochastic gradient descent.\nGCN is considered a spectral GNN. In technical terms, the feature vectors of nodes are\nconsidered multi-channel graph signals, for which the model learns spectral filters in the Fourier\ndomain defined by the eigenvectors of the graphs Laplacian matrix. This means that the filters\nlearned are graph specific, which explains why GCN is transductive (Mishra et al., 2020).\n3.3 Inductive Representation Learning\nSpatial GNNs define the convolution operation directly on the structure of the graph. Instead of\nlearning individual embeddings for each node in the graph, a spatial GNN learns a function that\ngenerates embeddings for unseen nodes by aggregating features from a node\u2019s surrounding neigh\u0002bourhood. This way, it simultaneously learns the topological structure of such a neighbourhood\nas well as the distribution of the features of the nodes in it.\nA powerful, spatial graph neural network framework that uses node feature information\nto inductively generate representations for unseen data is proposed by Hamilton et al. (2017).\nPseudo-code of this embedding generation algorithm is shown in Algorithm 1. Provided as input\nare the graph G = (V, E) and a feature vector xv for each node v \u2208 V, which initializes the\nembedding vectors h\n(0)\nv as can be seen in line 1. Let k denote the current step of the outer loop\n(line 2), which coincides with the current depth or layer within the GNN, and let h\n(k)\nv denote the\nembedding of node v at this step. In each iteration, we proceed as follows for each seed node\nv \u2208 V:\n1. The representations of the nodes in the neighbourhood of v, {h\n(k\u22121)\nu | u \u2208 N (v)}, are\naggregated by the Aggregate function into a single vector a\n(k)\nv (line 4). Note that this\naggregation depends on the embeddings of the neighbouring nodes in the previous iteration,\ni.e. step k \u2212 1.\nChapter 3. Graph Neural Networks 16\nAlgorithm 1: Inductive embedding generation (Hamilton et al., 2017)\nInput :Graph G = (V, E); input features {xv, \u2200v \u2208 V}; depth/number of GNN layers K;\naggregate and update functions aggregate(k), update(k), \u2200k \u2208 {1, . . . , K};\nneighbourhood function N : v \u2192 2\nV\nOutput : Vector embeddings zv for all v \u2208 V\n1 h\n(0)\nv \u2190 xv, \u2200v \u2208 V\n2 for k = 1 . . . K do\n3 for v \u2208 V do\n4 a\n(k)\nv \u2190 Aggregate(k)\n({h\n(k\u22121)\nu | u \u2208 N (v)})\n5 h\n(k)\nv \u2190 Update(k)\n(h\n(k\u22121)\nv , a\n(k)\nv )\n6 end\n7 end\n8 zv \u2190 h\n(K)\nv , \u2200v \u2208 V\n2. The node\u2019s current representation is updated by the Update function (line 5), which takes\nas input the seed node\u2019s previous embedding h\n(k\u22121)\nv and the result of its neighbourhood\naggregation a\n(k)\nv .\nAfter repeating this for each node for K iterations, the algorithm outputs the final node embeddings\nh\n(k)\nv (line 8). To optimize these output representations zv for all v \u2208 V, we apply a loss function and\nadjust the weight matrices and parameters of the aggregator and update functions corresponding\nto each layer k, using stochastic gradient descent. This results in an end-to-end inductive\nalgorithm suitable for node classification based on the learned node embeddings. An additional\nadvantage of this inductive framework is its efficiency in terms of both memory and time. By\nconducting mini-batch training, we only consider the embedding generation for a small group of\nseed nodes (i.e. a batch) at a time, avoiding the need to process an entire, potentially massive,\nnetwork at once\u2014something that can become infeasible in transductive learning (Zhou et al.,\n2021). For each batch, a small number of nodes are randomly sampled, their neighbourhoods are\nextracted in a breadth-first manner using the neighbourhood function N , and message passing\nis conducted in the corresponding subgraphs. Consequently, the weight matrices are updated\nmore frequently (after processing each batch rather than the entire dataset), leading to faster\nconvergence. Utilizing GPUs for processing different batches in parallel further enhances the\ntraining speed.\nThe two general Aggregate and Update steps described above form the foundation of\nso-called Message Passing Neural Networks (MPNN), the most prominent type of spatial GNNs.\nThese functions are to be determined and may vary for each layer k. By inserting different\nAggregate and Update mechanisms, this general framework for inductive representation\nlearning can be adapted to accommodate different types of MPNNs, such as GraphSAGE, Graph\nIsomorphism Network (GIN), and Graph Attention Network (GAT). We discuss the former two\nin the next sections.\n3.3.1 GraphSAGE\nThe general inductive representation learning algorithm was originally proposed for the Graph\u0002SAGE model (Hamilton et al., 2017), whose goal is to learn a function that generates embeddings\nby sampling and aggregating (SAmple and aggreGatE) features from a node\u2019s local neighbour\u0002hood. The neighbourhood function N uniformly samples a fixed-size set of neighbours at each\ndepth k, which implies that not every neighbour contributes to the embedding of a node. The\nidea is that informative embeddings can be derived from only a subset of neighbours, making the\nChapter 3. Graph Neural Networks 17\n(a) Sample neighbourhood of a\nseed node (marked dark red)\naggregator 2\naggregator 1\n(b) Aggregate feature information\nfrom neighbours with depth 2\nLabel\n(c) Update the embedding of the\nseed node and predict\nFigure 3.2: The sample and aggregate approach of GraphSAGE (Hamilton et al., 2017)\nprocess more time-efficient. However, a clear drawback of such a sampling-based design is that a\nlot of neighbourhood information is lost. When complete structural information is essential, as\nin our pattern detection tasks, it is essential to utilize the full neighbourhood. The sample and\naggregate scheme of GraphSAGE is illustrated in Figure 3.2.\nThe Update step used in GraphSAGE is as follows:\nh\n(k)\nv \u2190 \u03c3\n\u0010\nW(k)\u00b7 concat(h\n(k\u22121)\nv\n, a\n(k)\nv\n)\n\u0011\n.\nWe can see that the previous embedding vector is concatenated with the aggregated neighbourhood\nvector, which is subsequently fed through a fully connected layer with nonlinear activation function\n\u03c3. Note that W(k)is the weight matrix for layer k to be optimized during stochastic gradient\ndescent. For the Aggregate step, the authors suggest three types of aggregators: mean, max\u0002pooling, and LSTM. The mean aggregator straightforwardly computes the element-wise mean\nof the embedding vectors in the neighbourhood, which is nearly equivalent to the convolutional\npropagation rule used in the GCN framework; when we skip the concatenation in the Update\nrule, we essentially get an inductive variant of the GCN model! The max-pooling aggregator feeds\nthe neighbours\u2019 embeddings through a fully connected neural network and takes the element-wise\nmaximum. Finally, the LSTM aggregator, as the name suggests, utilizes a Long Short Term\nMemory network within the aggregation mechanism to further enhance the expressive capabilities\nof the model. Since LSTMs are not inherently symmetric (i.e., they are not permutation invariant)\ndue to processing inputs as a sequence, the authors adapt the LSTMs to operate on an unordered\nset by simply applying the LSTMs to a random permutation of the node\u2019s sampled neighbours.\nThis approach disregards any sequential ordering that may persist in the data, which is correct\nfor most applications that deal with static input graphs. However, for dynamic networks it seems\nbeneficial to allow the LSTMs to learn the sequential order that persist between edges, which is\nwhat our proposed LSTM aggregator detailed in Section 4.4 aims to do.\nIn their experiments, the authors demonstrate that GraphSAGE is effective in a wide range\nof node classification tasks from multiple domains, using data of citation networks, Reddit posts,\nand protein interactions. They specifically test on such dynamic graphs, showcasing the inductive\npower of the architecture, yielding significantly better results than DeepWalk while being 10-100\ntimes faster, depending on the neighbourhood sampling size. In the experiment with the protein\ninteractions dataset, the authors explicitly test the generalization capabilities of the inductive\nlearning framework across multiple graphs.\nChapter 3. Graph Neural Networks 18\n3.3.2 Graph Isomorphism Network\nIn their attempt to understand the representational properties and limitations of GNNs, Xu\net al. (2019) developed a theoretical framework for analyzing the expressive power of GNNs in\ncapturing different graph structures. They present a MPNN architecture that is provably the most\nexpressive among the class of GNNs, namely the Graph Isomorphism Network (GIN). The GIN\nmodel generalizes the Weisfeiler-Lehman graph isomorphism test (Lehman and Weisfeiler, 1968),\na heuristic test for the existence of an isomorphism between two graphs, thus achieving maximum\ndiscriminative power among GNNs. The authors utilize multi-layer perceptrons (MLPs) to model\nand learn the functions comprising the Aggregate and Update steps in the message passing\nmechanism. Since a MLP can represent the composition of functions, the node-wise propagation\nrule can be written as a single step, as shown in Equation 3.5.\nh\n(k)\nv = MLP(k)\n\u0012\u0010\n1 + \u03f5\n(k)\n\u0011\n\u00b7 h\n(k\u22121)\nv +\nX\nu\u2208N (v)\nh\n(k\u22121)\nu\n\u0013\n, (3.5)\nwhere \u03f5 is either a learnable parameter or a fixed scalar that essentially determines the importance\nof the previous embedding of seed node v. Note that at each depth k, and so for each GNN layer,\nthere is a distinct MLP with its own set of learnable weights.\n3.4 GNN Techniques for Graph Pattern Finding\nIn their paper Provably Powerful Graph Neural Networks for Directed Multigraphs, Egressy et al.\n(2024) propose a set of simple and intuitive techniques that can transform any MPNN into powerful\ndirected multigraph neural networks with provable properties. They show both experimentally\nand theoretically that GNNs can identify any directed subgraph pattern when equipped with\n(1) ego IDs, (2) heterogeneous message passing, and (3) port numbering. The combination of\nthese three techniques applied to suitably powerful standard MPNN yields so-called universal\nGNNs \u2013 those that can distinguish any two non-isomorphic (sub-)graphs, while not mistakenly\ndistinguishing any two isomorphic (sub-)graphs.\nWe now explain these techniques. Since we will not be focussing on the multigraph setting\n(see Section 5.1), we leave out port numbering (Sato et al., 2019) from this discussion, whose\nintent is to distinguish parallel edges.\n3.4.1 Modelling Node Identity\nFirst, the authors propose to incorporate node identity into the message passing, which seems\nessential for detecting subgraph patterns that consist of (undirected) cycles. A natural approach\nwould be to assign the unique node index i \u2208 {1, . . . , n} of each node as node ID and to use\none-hot encoding vectors vi of length n, with v[i] = 1 and 0 elsewhere, as node input features.\nWhile this yields a universal GNN, it heavily relies on the initial ordering of the nodes, of which\nthere are n! possible permutations. Consequently, nodes with identical structural neighbourhoods\nfail to be mapped to the same embedding, resulting in low generalization capability (Egressy and\nWattenhofer, 2022), rendering this approach unsuitable for the inductive setting. The same issue\narises when assigning random features (Abboud et al., 2020; Sato et al., 2021) as input node\nfeatures.\nHowever, functions that can assign node ID vectors inductively have been proposed. The\nID-GNN-Fast method of You et al. (2021) injects node identity information via augmented node\nfeatures using cycle counts, efficiently computable through powers of a graph\u2019s adjacency matrix.\nA similar method is proposed by Egressy and Wattenhofer (2022), who precompute positional\nnode embeddings. Here, the input graph is embedded into a Euclidean space approximating l\u221e\nand the coordinate locations are used as node features.\nChapter 3. Graph Neural Networks 19\nThe more straightforward approach taken by Egressy et al. (2024) is to set the so-called ego\nID feature of a specific seed node to be 1, while all other nodes in its neighbourhood are assigned\nan ego ID of 0. The idea is intuitive: by \u201cmarking\u201d a \u201ccenter\u201d node with a distinct binary feature,\nthis node can recognize when a sequence of messages cycles back around to it. As a result, the\nGNN can detect the cycles a node is part of. Note how the ego ID is a scalar that can be easily\nconcatenated to already existing node features and whose value dynamically changes based on\nwhether it is sampled as a seed node, meaning it is the sampled node in mini-batch training\nwhose neighbourhood is extracted and for which we want to make a prediction. In practice, the\nimplementation of ego IDs can be seen as a preprocessing step integrated with the creation of\nbatches during mini-batch training, detailed in Section 4.6.\n3.4.2 Modelling Edge Directionality\nMost traditional graph neural network applications consider the underlying structure of the input\ngraph to be undirected. In that case, the generic aggregation and update mechanisms are as\nformulated in Algorithm 1, where the neighbourhood function N (v) simply returns the set of all\nneighbours of v, which includes both nodes connected by an incoming edge and an outgoing edge,\ni.e. N (v) = Nin(v) \u222a Nout(v). As a result, the message passing occurs in a bidirectional manner,\ntermed bidirectional message passing: messages traverse in both directions over an edge, and both\nendpoints aggregate each other\u2019s embeddings. However, a significant drawback of this approach\nis that it does not consider edge directionality, even though this can be crucial information. In\nthe domain of financial networks and money laundering, differentiating between the sender and\nthe receiver is paramount. The ML subgraph patterns we aim to identify are partly characterized\nby their suspicious combination of edge directions.\nAlternatively, one could consider a strategy where the message passing strictly follows the\ndirection of the edges, which we refer to as directional message passing. In this approach, a\nnode sends its embedding solely along its outgoing edges while aggregating messages received\nexclusively through its incoming edges, as illustrated in Equation 3.6.\na\n(k)\nv = Aggregate(k)\n\u0010\b\nh\n(k\u22121)\nu\n| u \u2208 Nin(v)\n \n\u0011\n, (3.6)\nHowever, this method may lead to a loss of information since the embedding of nodes with zero\nin-degree cannot be computed (its initial embedding of the input features remains unchanged),\nrendering the GNN unable to differentiate such nodes. Moreover, nodes with zero out-degree\ncannot contribute to the embedding of any other node.\nThe aim is to conduct message passing in both directions while still indicating the edge\ndirection in some way. Egressy et al. (2024), and simultaneously Rossi et al. (2024), propose using\na separate message-passing layer for the incoming and outgoing edges, respectively. Since this is\nequivalent to using a relational GNN with two edge types (Schlichtkrull et al., 2018) and their\nimplementation involves converting the underlying network to a heterogeneous graph, we refer to\nthis as heterogeneous message passing. The aggregation and update mechanisms are shown in\nEquation 3.7.\na\n(k)\nin,v = Aggregate(k)in \u0010\b\nh\n(k\u22121)\nu\n| u \u2208 Nin(v)\n \n\u0011\n, (3.7a)\na\n(k)\nout,v = Aggregate(k)out\u0010\b\nh\n(k\u22121)\nu\n| u \u2208 Nout(v)\n \n\u0011\n, (3.7b)\nh\n(k)\nv = Update(k)\n\u0010\b\nh\n(k\u22121)\nv\n, a\n(k)\nin,v, a\n(k)\nout,v\u0011\n, (3.7c)\nwhere ain and aout are the aggregations of incoming and outgoing neighbours, respectively. The\nupdate function now takes both these separate aggregations as inputs, along with its previous\nembedding, to compute the new embedding of a node. However, we denote one flaw of this\nChapter 3. Graph Neural Networks 20\napproach. By treating the aggregations of the different edge types separately, the aggregation\nfunction of one edge type lacks access to the embeddings of the other edge type. While this\ncertainly helps the model to discern the edge directions in ML patterns, it sacrifices the flexibility\nto learn correlations between oppositely directed edges since the aggregation procedure cannot\ncope with both edge types simultaneously. The latter is especially crucial when we want to model\ntime dependencies between incoming and outgoing transactions. To solve this issue, we introduce\na novel message passing scheme that allows the simultaneous aggregation of both edges types\nwhile preserving directionality. We refer to this approach as signed message passing and it is\ndescribed in Section 4.2.\n3.4.3 Modelling Weights\nAs is often the case in network domains, we can associate weights to the edges. Although we\ndo not specify what these weights represent, they could reflect various factors in the context\nof a financial network, such as the pair-wise similarity between two nodes (for instance, based\non account-based features, transaction behaviour, etc.), the transaction volume, the frequency\nof interactions, or a combination. A way of handling such weights is to include the weights as\nan edge feature co-embedded with the node features. Hu et al. (2020) extend the GIN model\ndescribed in Section 3.3.2 to incorporate edge features into the aggregation procedure as follows:\nh\n(k)\nv = MLP(k)\n\u0012\u0010\n1 + \u03f5\n(k)\n\u0011\n\u00b7 h\n(k\u22121)\nv +\nX\nu\u2208N (v)\nReLU\u0010h\n(k\u22121)\nu + eu,v\u0011\u0013\n. (3.8)\nHere, eu,v is a vector of the edge features of edge (u, v), possibly transformed by a linear layer\nto match the size of h\n(k\u22121)\nu . While Egressy et al. (2024) do not model edge weights explicitly,\nthey do utilize this extended GIN model to handle other kinds of edge features contained in their\nAMLWorld dataset.\n3.4.4 Modelling Time\nTo the best of our knowledge, there is no previous work that aims to use GNNs to detect subgraph\npatterns that exhibit explicit temporal characteristics. Since an edge in the financial network\nrepresents a transaction, each edge can be associated with a specific timestamp indicating when\nthe transaction occurred. While various methods for temporal modelling in AML, such as sliding\ntime windows, have been discussed in Chapter 2, a straightforward way for incorporating time is\nto include the timestamps as edge features in the model, similar to the approach for edge weights\ndescribed previously. However, this only deals with time implicitly by making the temporal\ninformation available to the model. Instead, we propose to model the temporal dependencies\nbetween transactions explicitly by utilizing LSTMs in the aggregation step. Our approach, along\nwith other modifications to these GNN techniques, are described in the next chapter.\n21\nChapter 4\nMethod\nIn the previous chapter, we discussed related work on techniques that extend GNNs for pattern\nfinding. Most notably, the work of Egressy et al. (2024), who propose the combination of ego\nIDs and heterogeneous message passing. In this chapter, we extend the pattern detection task\nto weighted and temporal settings, and propose additional modifications and techniques for\ncoping with these characteristics. In Section 4.1, we first define the subgraph patterns we aim to\ndetect. We proceed by discussing our novel message passing scheme (Section 4.2), edge weight\nmultiplication (Section 4.3), and the LSTM aggregator (Section 4.4). Finally, we present our\nmodel\u2019s architecture in Section 4.5 and describe some implementation details in Section 4.6.\n4.1 Money Laundering Patterns\nThe financial network is a directed multigraph, as can be seen in the example in Figure 2.1. Given\nsuch a graph as input, the question becomes: what type of structures are we looking for that\nmay imply money laundering? An example of such a topology is a simple cycle, which denotes a\nseries of transactions in which the money ultimately returns to the bank account it was initially\nsent from. The presence of such cycles in the financial network is a strong indicator of potential\nmoney laundering. Similarly, money launderers can use various mixing and shuffling schemes,\nwhich can be expressed in terms of subgraph structures (Granados and Vargas, 2022; He et al.,\n2021; Weber et al., 2018; Starnini et al., 2021). Suzumura and Kanezashi (2021) introduced a set\nof eight common money laundering patterns, or so-called motifs, illustrated in Figure 4.1.\n(a) Fan-out (b) Fan-in (c) Gather-scatter (d) Scatter-gather\n(e) Simple cycle (f) Random (g) Bipartite clique (h) Stack\nFigure 4.1: Eight key money laundering patterns as identified by Suzumura and\nKanezashi (2021). The nodes marked in red can be seen as key accounts and are the nodes\nto be detected in a node classification task.\nChapter 4. Method 22\nSince we perform node classification to identify nodes that are part of a ML pattern instead\nof fully extracting the patterns, we use the concept of a key node to designate a specific node\nby which a pattern is identified. To be more precise, we use the following definitions for when a\npattern is considered suspicious and what its respective key node is:\n\u2022 Fan-out: A fan-out pattern consists of a node with out-degree > 3. Naturally, this source\nnode is the key node we aim to detect.\n\u2022 Fan-in: A fan-in pattern consists of a node with in-degree > 3. This sink node is the key\nnode.\n\u2022 Gather-scatter: A gather-scatter pattern consists of a fan-in followed by a fan-out of the\nsame node. Here, the intermediate node is the key node and it must have both in- and\nout-degree \u2265 3.\n\u2022 Scatter-gather: In case a fan-out and fan-in of two separate nodes are connected to each\nother by the same set of at least two intermediate nodes, we get a scatter-gather pattern.\nWe designate the sink node to be the key node that needs to be identified.\n\u2022 Simple cycle: For a simple cycle pattern, the sequence of edges starts and ends with\nthe same node and visits each intermediate node only once. Since each node in a cycle is\nequivalent, they are all regarded as key nodes that need to be detected.\n\u2022 Bipartite clique: A bipartite clique pattern consists of a set of at least two input nodes\nthat are all connected to the same set of at least two output nodes. The sink nodes are\nconsidered key nodes.\nIn our experiments, we do not include the random and stack patterns. The key nodes of a pattern\nare marked red in Figure 4.1. Note that the thresholds (such as the minimum degree or number\nof intermediate nodes) used to define whether a pattern is suspicious are arbitrary and can be\nchanged. We selected these definitions and assignment of key nodes, although any other definition\nor assignment would also be effective as long as it is consistent.\nUnfortunately, these patterns are rather generic and also common amongst perfectly innocent\ntransactions. Therefore, we extend the definition of suspicious patterns to include weighted\nand temporal characteristics that are evident in dynamic networks. We introduce the notion\nof weighted patterns and temporal patterns by including edge weights and edge timestamps,\nrespectively. As stated in Chapter 3, edge weights can signify connection strength or pair-wise\nsimilarity between two nodes, while edge timestamps impose a temporal order. Generally, we say\nthat a weighted pattern is a pattern constrained by the edge weights, and a temporal pattern\nis a pattern constrained by the sequential order of edges imposed by the edge timestamps. The\nspecific definitions we use, along with examples, are given in Section 5.1.3.\n4.2 Modelling Edge Directionality: Signed Message Passing\nIn Section 3.4.2, we discussed how Egressy et al. (2024) and Rossi et al. (2024) proposed\nheterogeneous message passing to account for edge directionality during the message passing.\nHowever, the limitation of this approach is that by using separate message passing layers for the\nincoming and outgoing edges, relations between the two edge types cannot be learned by the\naggregator. Therefore, we propose to indicate edge direction by weighting the embeddings over the\ntwo directions differently within a single aggregation function, a method we call signed message\npassing. Instead of aggregating the embeddings over incoming and outgoing edges separately, the\naggregation function receives both as input. However, each neighbour\u2019s message is multiplied\nChapter 4. Method 23\nby a directional vector d, which is a linear embedding of 1 for incoming neighbours and \u22121 for\noutgoing neighbours, see Equation 4.1.\na\n(k)\nv = Aggregate(k)\n\u0010\b\ndu,v \u2299 h\n(k\u22121)\nu\n| u \u2208 N (v)\n \n\u0011\n, (4.1a)\nwhere\ndu,v =\n(\nLinear(1) u \u2208 Nin(v),\nLinear(\u22121) u \u2208 Nout(v).\n(4.1b)\nHere, Linear is a linear layer that transforms an input scalar into a vector the size of the node\nembeddings, and \u2299 represents element-wise multiplication. The latter is now possible because\nboth factors have the same dimension due to the linear layer. Instead of simply multiplying every\ncomponent of h\n(k\u22121)\nu with the scalar 1 or \u22121, the model can learn a separate weight factor for\neach component. This allows the model to determine how and which parts of the embedding to\ndifferentiate for the two different directions. Note that we specifically rely on the sign to discern\nbetween the two directions and that the actual scalar value of 1 is arbitrary and can be changed\nto any value w, something we demonstrate in the next section when we introduce edge weights.\n4.3 Modelling Weights: Edge Weight Multiplication\nWe include the possibility of edge weights in our model. A weight wu,v \u2208 [0, 1] is assigned to an\nedge (u, v) and can be interpreted as the strength of a connection between the two nodes. The\ngeneral idea is that we consider a ML pattern suspicious if the weights of the edges included in\nthe pattern are all high (with respect to some threshold). For more detailed information on how\nwe generate the weights, we refer to Section 5.1.3.\nLooking at Section 4.2, the extension to include edge weights to signed message passing is\nquite straightforward. Instead of using the default weight of 1 for original edges and \u22121 for\nreverse edges, we can use w and \u2212w, as follows:\ndu,v =\n(\nLinear(wu,v) u \u2208 Nin(v),\nLinear(\u2212wv,u) u \u2208 Nout(v).\n(4.2)\nAs a result, the message transferred over that edge is multiplied by the embedding of the\ncorresponding weight. This seems natural since the weight then determines the importance of that\nmessage. We argue that the integration of edge weights and signed message passing is particularly\nintuitive in financial networks, where negative weights correspond to negative transactions in the\nopposite direction.\nThis edge weight multiplication is an alternative to treating the weights as an edge feature\nco-embedded with the node features, as described in Section 3.4.3. In that case, the weight is\nalso available to the model, but the model itself must learn how to utilize it effectively.\n4.4 Modelling Time: LSTM Aggregation\nIn addition to edge weights, we explicitly model time dependencies and integrate temporal\ninformation from edge timestamps to identify ML patterns that are also suspicious with respect\nto this component. We first describe the workings of the LSTM, the primary component used to\nmodel sequential dependencies, and then explain how it integrates into our GNN as an aggregator.\nDetails on generating the edge timestamps in our synthetic networks are provided in Section 5.1.3.\nChapter 4. Method 24\ntanh\ntanh\nForget\ngate\nInput\ngate\nCandidate\nfor cell state\nupdate\nOutput\ngate\nUpdate cell state to help\ndetermine new hidden state\nFigure 4.2: LSTM recurrent unit. Here ct and ht are the cell state and hidden state\nproduced at time t, respectively. xt is the model input. Image recreated from here.\n4.4.1 Long Short-Term Memory\nThe Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) is a recurrent neural\nnetwork (RNN) variant that is specifically designed for sequence data and aims to capture long\u0002term temporal dependencies. LSTM introduces mechanisms to address the vanishing gradient\nproblem encountered by traditional RNNs, enabling the network to better handle sequence data.\nThe basic structure is illustrated in Figure 4.2. A critical component is the memory cell, which is\nresponsible for storing and transmitting information by selectively remembering or forgetting\ncertain information. This is achieved through the following three components:\n\u2022 Forget gate: determines which information is deleted from the memory cell.\n\u2022 Input gate: controls how much new information is added to the memory cell.\n\u2022 Output gate: decides how much information is output from the memory cell\nThe forget gate and input gate adjust ct, the state of the memory cell at each time step t, while\nthe output gate is used together with the updated cell state to determine the new hidden state\nht, which contains the output that is passed to the next time step. Apart from the previous cell\nstate ct\u22121 and hidden state ht\u22121, the LSTM unit takes the current feature input of the model xt\nas input. Mathematically, the gates, cell state, and hidden state are defined as follows:\nft = \u03c3(Wfxt + Ufht\u22121 + bf )\nit = \u03c3(Wixt + Uiht\u22121 + bi)\not = \u03c3(Woxt + Uoht\u22121 + bo)\nc\u00aft = tanh(Wcxt + Ucht\u22121 + bc)\nct = ft \u2299 ct\u22121 + it \u2299 c\u00aft\nht = ot \u2299 tanh(ct)\n(4.3)\nChapter 4. Method 25\nHere, Wq and Uq are weight matrices and bq a bias term, where the subscript q represents either\nthe forget gate f, the input gate i, the output gate o, or the cell state c. The operator \u2299\ndenotes the element-wise product, and \u03c3 and tanh are the sigmoid and tanh activation functions,\nrespectively. Initially, c0 = 0 and h0 = 0.\n4.4.2 LSTM Aggregator\nWe utilize the LSTM model as an aggregator in the GNN layers. As discussed in Section 3.3.1, this\nwas originally proposed by Hamilton et al. (2017) as an alternative to the default mean operator.\nHowever, instead of applying the LSTM to a random permutation of the node\u2019s neighbours, we\naim to capture the network dynamics. Since the timestamps of the edges impose a sequential\nordering between the neighbours of each node, it would be unwise to disallow the LSTM to learn\nfrom such dependencies.\nWe therefore propose to aggregate messages from neighbours in increasing order of timestamp\ncorresponding to the edge. More formally, we define the ordered sequence of neighbours of\nnode v as N T(v) = \u27e8u1, . . . , un\u27e9, where ui \u2208 N is the ith neighbour of v in the sequence, and\ntime({ui, v}) < time({uj , v}) for all i < j. Note that a neighbour u can occur multiple times in\nthe sequence N T when there are multiple edges between u and v. The aggregation formula then\nbecomes:\na\n(k)\nv = LSTM(k)\n\u0010\n\nh\n(k\u22121)\nu\n| u \u2208 N T(v)\n\u000b\n\u0011\n. (4.4)\nHere, the sequence of neighbours N T defines the input sequence in which the LSTM processes the\nneighbours\u2019 embeddings. Similar to the MLPs in the GIN model detailed in Section 3.3.2, we have\nmultiple LSTMs, one for each layer k in the GNN. This allows the model to learn from different\nsequential orderings at each depth. The LSTMs are quite simple and only consist of a single layer\nof the same size as the GNN layers. The weights of the LSTMs are updated simultaneously with\nthe other weights of the GNN during backpropagation.\n4.5 The LAS-GNN Model\nFor detecting suspicious ML patterns, we primarily rely on the techniques that extend a fundamen\u0002tally basic GNN. The overall structure of our GNN follows the inductive representation learning\nframework described in Section 3.3, consistently sampling the full three-hop neighbourhood of\nseed nodes. We refer to our ultimate GNN model, which includes ego IDs, signed message passing,\nedge weight multiplication, and LSTM aggregation, as LAS-GNN (LSTM-based Aggregation and\nSigned message passing).\nSince we do not use actual data with relevant features and instead focus on minimal structural\nembeddings in synthetic networks generated by ourselves, all nodes are initialized with a single\nfeature, the integer 1. For the ego IDs, we extend the node features by concatenating an additional\n1 for seed nodes and 0 for non-seed nodes. Edges may include a weight or timestamp, depending\non the task. Since we conduct mini-batch training, the data is divided into smaller batches, ready\nto be processed by the GNN layers.\nAn overview of the LAS-GNN architecture is provided in Figure 4.3. Once the batches are\ncreated, they are passed through the graph neural network. The GNN consists of K layers\ncorresponding to K rounds of message passing. In each layer, the previous node embeddings and\nthe edge weights are fed into the aggregator. While we have illustrated the LSTM aggregator here,\nit is not mandatory for every layer. In preliminary experiments, we found that using a default\nADD aggregator, which sums up the neighbour\u2019s embeddings element-wise, can be advantageous\nin the first GNN layer (see Section 6.1). When we utilize the LSTM aggregator and combine it\nwith signed message passing and edge weight multiplication, we get the aggregation and update\nChapter 4. Method 26\nmechanisms described in Equation 4.5.\na\n(k)\nv = LSTM(k)\n\u0010\n\ndu,v \u2299 h\n(k\u22121)\nu\n| u \u2208 N T(v)\n\u000b\n\u0011\n, (Aggregate, 4.5a)\nh\n(k)\nv = Mean\u0010\nh\n(k\u22121)\nv\n, ReLUNorm(k)(a\n(k)\nv\n)\n\u0001\n\u0011\n, (Update, 4.5b)\nwhere\ndu,v =\n(\nLinear(wu,v) u \u2208 Nin(v),\nLinear(\u2212wv,u) u \u2208 Nout(v).\n(4.5c)\nThe Update rule involves taking the mean between the previous embedding vector and the\nnormalized result of the aggregation, to which a ReLU activation function is applied. The ReLU\nactivation introduces non-linearity, helping to mitigate the vanishing gradient problem during\ntraining and enabling the neural networks to learn more complex relationships. We use batch\nnormalization (Ioffe and Szegedy, 2015) as a normalization technique, stabilizing training across\nmini-batches by re-centring and re-scaling the outputs. This update rule is quite standard and is\nalso used in the GIN implementation by Egressy et al. (2024).\nGNN layer 1 GNN layer 2 GNN layer ... Classification output\nLabels\nLinear\nSoftmax\n64\nBatchNorm ReLU\n64\n1\nGNN layer k\nGNN layer K\nMean\n64\nN\nN\nN\nN\nN\nFigure 4.3: The architecture of LAS-GNN. The GNN consists of K layers, and a single\nlayer with LSTM aggregation is detailed in the grey-filled box. We indicate embedding\nmatrices of size N \u00d7 64, where 64 is the embedding size and N is the number of nodes in\nthe batched subgraphs. The N \u00d7 N adjacency matrix W contains all edge weights w.\nChapter 4. Method 27\nAfter K rounds of message passing, the final node embeddings are transformed by a linear\nlayer to form raw output scores known as logits. The softmax activation function then normalizes\nthe logits to a probability distribution over the predicted output classes. In our case, we predict\nthe probability of the positive class, i.e., a node being the key node in a suspicious ML pattern.\nFrom these probabilities, we derive the predicted label (0 or 1) for each node by comparing it to\na certain classification threshold (see Section 5.4).\n4.6 Implementation\nWhile our model is described conceptually, several practical elements lay at the foundation of\nthe ego ID and signed message passing techniques. Due to certain limitations of existing MPNN\nimplementations, specific design choices are essential for the model to function as intended. In\nthis section, we highlight these issues and explain how to preprocess the input data accordingly.\n4.6.1 Ego IDs\nAs stated in Section 3.4.1, the ego ID is essentially a binary node feature set to 1 for certain\nnodes, namely the nodes we want to predict, and set to 0 for all other nodes. This approach\nfails when node embeddings are calculated for all nodes simultaneously since the GNN cannot\ndifferentiate between nodes that all have an ego ID of 1. However, when mini-batch training and\ninference are applied, only a small set of seed nodes are considered at a time. As long as the\nsampled neighbourhoods of these seed nodes do not overlap, a message tagged with an ego ID of 1\nremains unique to its respective seed node within its neighbourhood. Even though the likelihood\nof overlapping neighbourhoods is low when the batch size is small relative to the size of the\nnetwork, we ensure disjoint sampling of neighbourhoods: in case the extracted neighbourhoods of\ntwo seed nodes overlap, each neighbourhood is treated as a disjoint subgraph. Consequently, the\ngraph in which the message passing is conducted may differ from the original input graph, since\nthe former consists of multiple subgraphs and may contain some duplicate nodes. In that case, or\nwhen other adjustments have been made to the network, we refer to it as the computation graph.\nThe creation of batches and assignment of ego IDs is illustrated in Figure 4.4c.\n(a) Input graph containing edge\nweights and timestamps (not\nshown).\n(b) Create computation graph by\nadding reverse edges for signed\nMP.\n(c) Create batches by sampling\nsubgraphs of seed nodes (marked\nred). Here, we add the ego IDs\n{0, 1} to the node features.\nFigure 4.4: The preprocessing of the input graph in three steps. In (b), the reverse edges\nreceive the negative weight and original timestamp of their corresponding original edges.\nFor visibility, we only extract the one-hop neighbourhood of seed nodes in (c).\nChapter 4. Method 28\n4.6.2 Signed Message Passing\nIn Equation 4.5, the signed message passing is formulated for the input graph. However, in\npractice, the actual implementation of MPNN architectures used (Fey and Lenssen, 2019) conducts\nmessage passing in a directional way, as described in Section 3.4.2. For bidirectional message\npassing, the network is converted to a seemingly undirected network by adding edges in opposite\ndirection.\nA similar approach is taken for heterogeneous and signed message passing, and the imple\u0002mentation of the latter is as follows: For each edge (u, v) with weight w and timestamp t in the\ninput graph, we create an oppositely directed edge (v, u) with weight \u2212w and timestamp t and\nadd it to the computation graph along with the original edge. While conducting message passing\nover the incoming edges (as done with directional message passing) in the computation graph,\neach node also receives messages from outgoing neighbours due to the artificially created reverse\nedges. This approach mimics bidirectional message passing while indicating the direction of the\nmessages through the embedding of the signed weights.\nFigure 4.4 describes the complete preprocessing of the input graph that besides the ego ID\nfeatures and batch generation also includes adding the reverse edges to the computation graph in\nFigure 4.4b. As a result, signed message passing is now compatible with any spatial graph neural\nnetwork implementation that supports message passing on directed networks.\n29\nChapter 5\nExperimental Setup\nIn this chapter, we discuss the details of how we design our experiments for assessing the\nperformance of the LAS-GNN model and the GNN pattern finding techniques. We describe the\nsynthetic network generation model used for creating our datasets in Section 5.1. Furthermore,\nwe discuss hyperparameter tuning and other training details in Section 5.2. Model baselines are\ndescribed in Section 5.3 and description of appropriate evaluation metrics is given in Section 5.4.\nSome brief implementation details regarding software and hardware can be found in Section 5.5.\n5.1 Synthetic Network Generation\nUnfortunately, we do not have access to real-world transaction data, especially not including\nlabels for reported money laundering cases. Hence, we do not rely on rich feature sets for our\nexperiments. Instead, we turn to synthetic networks generated by ourselves, which allows us to\nhave complete control over the datasets by adjusting specific network parameters and to generate\nas much data as needed.\n5.1.1 Directed Watts-Strogatz Model\nWe adopt the Watts-Strogatz model (WSM) (Watts and Strogatz, 1998) as our preferred method\nof synthetic network generation. This random graph generation model produces graphs with\nsmall-world properties, including short average path lengths and high clustering. Such properties\nfacilitate the emergence of numerous naturally occurring patterns in the network, such as short\ncycles and scatter-gather", "embedding": [-0.14990933239459991, 0.006877725478261709, -0.022152913734316826, -0.025454675778746605, 0.065938800573349, -0.03979996591806412, 0.05686761438846588, 0.022801725193858147, -0.010928157716989517, -0.030908621847629547, -0.06862141191959381, 0.014341618865728378, 0.03785017505288124, -0.02748044580221176, -0.07503220438957214, 0.05267852544784546, 0.03354983404278755, -0.007526897359639406, -0.046456146985292435, -0.06476510316133499, 3.808757901424542e-05, -0.08326590806245804, -0.008387921378016472, -0.07770845293998718, 0.023213515058159828, 0.07422279566526413, -0.003142864443361759, -0.0786370187997818, -0.01468916516751051, -0.03285934776067734, 0.05888986214995384, 0.05115607753396034, -0.029929224401712418, 0.06620121002197266, -0.06531456857919693, 0.012574986554682255, -0.02763190120458603, 0.05639703944325447, 0.056069351732730865, 0.0692836344242096, -0.02205127291381359, 0.0004069856950081885, 0.007287400774657726, -0.0034077365417033434, 0.0593293271958828, -0.03840824216604233, 0.01355776283890009, 0.07779675722122192, -0.03841773048043251, 0.03539391607046127, -0.08762168884277344, -0.06046367436647415, 0.03466206043958664, 0.0337722972035408, -0.06370236724615097, -0.018151722848415375, 0.0728449672460556, -0.042604148387908936, -0.02575775235891342, -0.05311451107263565, 0.07404138892889023, -0.012421681545674801, -0.02861771360039711, -0.038261983543634415, 0.07647471874952316, 0.019088614732027054, -0.07727394253015518, 0.08750676363706589, -0.020870549604296684, 0.0725279450416565, 0.11841127276420593, -0.015038655139505863, -0.1050957515835762, 0.03909263014793396, 0.051847364753484726, 0.050813063979148865, 0.054318368434906006, -0.01977570168673992, 0.027412809431552887, -0.11443312466144562, -0.039421770721673965, 0.0021296278573572636, 0.021244142204523087, -0.0478375107049942, -0.020326822996139526, -0.024410763755440712, -0.03976526856422424, -0.01082103792577982, 0.04491693899035454, -0.002570096170529723, 0.03319389373064041, 0.07889431715011597, 0.015284971334040165, -0.1220175251364708, 0.05552338808774948, 0.04501504823565483, -0.011187965050339699, -0.008830815553665161, 0.02920645847916603, 0.11130797863006592, 0.0023062084801495075, 0.029935529455542564, -0.007022182457149029, -0.0811845064163208, 0.04770885780453682, -0.008939091116189957, 0.02391936630010605, 0.0484648160636425, 0.0515146404504776, -0.07231314480304718, -0.051586002111434937, 0.07133474946022034, -0.005466074217110872, -0.009591512382030487, 0.05271659418940544, -0.02432248182594776, -0.04280154034495354, 0.006755605805665255, -0.008560409769415855, 0.11028175801038742, -0.0032989413011819124, 0.07577119767665863, -0.08352132141590118, -0.02512720599770546, -0.03240980580449104, -0.024781135842204094, -0.13624690473079681, 4.968575113951829e-33, -0.049755629152059555, 0.037414323538541794, 0.03514253348112106, -0.0026638212148100138, -0.007128047291189432, 0.013566111214458942, -0.067235566675663, -0.020486922934651375, -0.005932596046477556, 0.0924575999379158, -0.12285800278186798, 0.07695302367210388, -0.039158355444669724, 0.06536398082971573, -0.011093966662883759, -0.07114232331514359, 0.03698796406388283, -0.04575950279831886, 0.04065247252583504, -0.0754474475979805, 0.06799028068780899, -0.08246367424726486, 0.025110948830842972, -0.00820764061063528, 0.03814152255654335, 0.01462849322706461, -0.007526801899075508, 0.003229292342439294, 0.14314991235733032, 0.02544822171330452, 0.043923310935497284, 0.05110219493508339, 0.00508031016215682, -0.01378364022821188, -0.03252352029085159, 0.00187196908518672, -0.07382449507713318, -0.09097887575626373, 0.05207832157611847, -0.06270910799503326, -0.049841027706861496, 0.002414396498352289, 0.025833776220679283, -0.02051381580531597, -0.07489995658397675, 0.08525779098272324, 0.05327276512980461, -0.025669844821095467, 0.037481632083654404, -0.04776201397180557, -0.03361263871192932, -0.03143520653247833, -0.02056148275732994, -0.027615275233983994, 0.013664353638887405, -0.018684012815356255, 0.025675049051642418, -0.007468111347407103, 0.03781166300177574, 0.015014007687568665, 0.05383885279297829, 0.034121766686439514, -0.04457471892237663, 0.025015784427523613, -0.04799802228808403, 0.016233369708061218, -0.0439130924642086, 0.03811727836728096, 0.09268166869878769, -0.038904380053281784, -0.028603658080101013, 0.10349081456661224, 0.053457342088222504, -0.020953524857759476, 0.014100710861384869, -0.04327455163002014, 0.018764926120638847, -0.016848275437951088, -0.08522004634141922, -0.002765750978142023, -0.10569527745246887, -0.06371540576219559, 0.05085352808237076, 0.000872067001182586, -0.03612344712018967, 0.016996679827570915, 0.0438121072947979, -0.043654683977365494, 0.02229868434369564, 0.003824109910055995, 0.0023544516880065203, -0.04026816040277481, -0.004144064150750637, 0.025479312986135483, -0.06438449025154114, -5.268451437028272e-33, -0.0787784531712532, 0.06896324455738068, 0.02414138801395893, -0.0194211695343256, -6.715930794598535e-05, 0.051728881895542145, -0.07374859601259232, -0.007323519792407751, -0.00010446164378663525, 0.07167767733335495, -0.029051294550299644, -0.04630983620882034, 0.009197634644806385, -0.03406231477856636, 0.0494934618473053, -0.06408320367336273, -0.01163762528449297, -0.0136385727673769, 0.006186101119965315, -0.06877908855676651, -0.00880511850118637, 0.07055577635765076, -0.09863927960395813, -0.019841566681861877, 0.03223840892314911, 0.024485792964696884, -0.014456206932663918, -0.0189307052642107, -0.02347295731306076, 0.07861926406621933, -0.10066036134958267, -0.009314652532339096, -0.0341583751142025, 0.02051311545073986, 0.017704440280795097, 0.01885739341378212, 0.03035355918109417, -0.030237684026360512, -0.026354048401117325, -0.01033366285264492, -0.017931034788489342, 0.03218882903456688, -0.0859069898724556, -0.05622125044465065, -0.044596973806619644, -0.01546079944819212, -0.06914037466049194, 0.08289315551519394, 0.0010426996741443872, -0.03239619731903076, 0.03318062797188759, 0.033130109310150146, 0.004932225216180086, -0.06936714798212051, -0.058048348873853683, 0.08147598803043365, 0.13138996064662933, 0.029333345592021942, 0.060269057750701904, 0.027078038081526756, -0.12057090550661087, 0.016713520511984825, -0.0037981972564011812, 0.07907470315694809, 0.004089209716767073, -0.027161702513694763, -0.0028797064442187548, 0.021627863869071007, 0.056739442050457, -0.036068517714738846, -0.011348281055688858, 0.0006448251660913229, 0.012307150289416313, -0.0055392151698470116, 0.03525865077972412, -0.012776784598827362, -0.030323751270771027, -0.053530704230070114, -0.04232510179281235, -0.014772571623325348, -0.025876428931951523, -0.02883884310722351, 0.07275369018316269, 0.06876414269208908, 0.040081050246953964, 0.03934663534164429, -0.025816012173891068, -0.022627035155892372, 0.03895287960767746, 0.043125126510858536, -0.013743112795054913, -0.016457732766866684, -0.011509629897773266, 0.018851548433303833, -0.009583339095115662, -5.8685827752924524e-08, -0.09731940925121307, -0.02704235166311264, 0.03373218700289726, 0.01812106743454933, 0.07576602697372437, -0.06047352775931358, 0.05880585312843323, 0.03429313376545906, -0.06741585582494736, 0.03508536145091057, 0.09719260036945343, -0.014314630068838596, -0.09677136689424515, -0.049828894436359406, 0.04233554005622864, -0.09056824445724487, 0.03476274386048317, -0.03153142333030701, -0.016651486977934837, 0.029804574325680733, 0.08542005717754364, 0.029565274715423584, -0.031301844865083694, 0.05894366279244423, 0.05940927565097809, -0.04822615906596184, -0.017403431236743927, 0.12114310264587402, 0.036778803914785385, 0.09161744266748428, -0.024911953136324883, 0.08509082347154617, 0.01485298853367567, -0.0008267693920060992, 0.028234951198101044, 0.06665368378162384, 0.010098838247358799, -0.029065512120723724, -0.07734991610050201, 0.12387686967849731, -0.01856025867164135, 0.04078834503889084, 0.007895730435848236, -0.0070968689396977425, 0.03999614715576172, -0.036505796015262604, 0.02238548919558525, -0.04680949077010155, 0.0816606655716896, -0.0906057208776474, -0.03879983723163605, -0.07713353633880615, 0.041213877499103546, 0.02492840401828289, 0.026448994874954224, -0.05276782810688019, -0.04104432463645935, -0.03519267588853836, -0.06300826370716095, 0.05358726158738136, 0.08389651030302048, -0.026701461523771286, -0.04816172644495964, -0.008415457792580128]}, {"id": "6951691dc1b196630562bc6e", "user_id": "CarlFristam", "title": "Finding Money Launderers Using Heterogeneous Graph ...", "text": "[2307.13499] Finding Money Launderers Using Heterogeneous Graph Neural Networks[![close this message](https://arxiv.org/static/browse/0.3.4/images/icons/close-slider.png)](#)\n![arXiv smileybones](https://arxiv.org/static/browse/0.3.4/images/icons/smileybones-pixel.png)\n## Happy Open Access Week from arXiv!\nYOU make open access possible! Tell us why you support #openaccess and give to arXiv this week to help keep science open for all.\n[**Donate!**](https://arxiv.salsalabs.org/arXivOAWeek2025)\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2307.13499\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2307.13499**(cs)\n[Submitted on 25 Jul 2023]\n# Title:Finding Money Launderers Using Heterogeneous Graph Neural Networks\nAuthors:[Fredrik Johannessen](https://arxiv.org/search/cs?searchtype=author&amp;query=Johannessen,+F),[Martin Jullum](https://arxiv.org/search/cs?searchtype=author&amp;query=Jullum,+M)\nView a PDF of the paper titled Finding Money Launderers Using Heterogeneous Graph Neural Networks, by Fredrik Johannessen and Martin Jullum\n[View PDF](https://arxiv.org/pdf/2307.13499)> > Abstract:\n> Current anti-money laundering (AML) systems, predominantly rule-based, exhibit notable shortcomings in efficiently and precisely detecting instances of money laundering. As a result, there has been a recent surge toward exploring alternative approaches, particularly those utilizing machine learning. Since criminals often collaborate in their money laundering endeavors, accounting for diverse types of customer relations and links becomes crucial. In line with this, the present paper introduces a graph neural network (GNN) approach to identify money laundering activities within a large heterogeneous network constructed from real-world bank transactions and business role data belonging to DNB, Norway&#39;s largest bank. Specifically, we extend the homogeneous GNN method known as the Message Passing Neural Network (MPNN) to operate effectively on a heterogeneous graph. As part of this procedure, we propose a novel method for aggregating messages across different edges of the graph. Our findings highlight the importance of using an appropriate GNN architecture when combining information in heterogeneous graphs. The performance results of our model demonstrate great potential in enhancing the quality of electronic surveillance systems employed by banks to detect instances of money laundering. To the best of our knowledge, this is the first published work applying GNN on a large real-world heterogeneous network for anti-money laundering purposes. Subjects:|Machine Learning (cs.LG); Machine Learning (stat.ML)|\nCite as:|[arXiv:2307.13499](https://arxiv.org/abs/2307.13499)[cs.LG]|\n|(or[arXiv:2307.13499v1](https://arxiv.org/abs/2307.13499v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2307.13499](https://doi.org/10.48550/arXiv.2307.13499)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Martin Jullum PhD [[view email](https://arxiv.org/show-email/d1324e51/2307.13499)]\n**[v1]**Tue, 25 Jul 2023 13:49:15 UTC (1,238 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Finding Money Launderers Using Heterogeneous Graph Neural Networks, by Fredrik Johannessen and Martin Jullum\n* [View PDF](https://arxiv.org/pdf/2307.13499)\n* [TeX Source](https://arxiv.org/src/2307.13499)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2307.13499&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2307.13499&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2023-07](https://arxiv.org/list/cs.LG/2023-07)\nChange to browse by:\n[cs](https://arxiv.org/abs/2307.13499?context=cs)\n[stat](https://arxiv.org/abs/2307.13499?context=stat)\n[stat.ML](https://arxiv.org/abs/2307.13499?context=stat.ML)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2307.13499)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2307.13499)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2307.13499)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)]()[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)]()\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2307.13499)|[Disable MathJax](javascript:setMathjaxCookie())([What is MathJax?](https://info.arxiv.org/help/mathjax.html))", "embedding": [-0.07766036689281464, 0.008100043050944805, -0.030231522396206856, 0.06070438027381897, 0.06834495812654495, -0.11466376483440399, -0.021517595276236534, -0.0839712843298912, -0.06944247335195541, -0.04014206305146217, 0.0070954239927232265, 0.022908715531229973, 0.007685700431466103, 0.0060821822844445705, -0.032274164259433746, 0.03903847932815552, -0.026568876579403877, -0.05319628491997719, 0.0036059010308235884, -0.026930538937449455, -0.029034962877631187, -0.07805416733026505, 0.054361652582883835, -0.11046116054058075, 0.017202602699398994, 0.02686874009668827, -0.021773267537355423, -0.021601760759949684, 0.03654858469963074, -0.06916949898004532, 0.09355837106704712, 0.032033294439315796, -0.00867774710059166, -0.015637587755918503, 0.012078369967639446, 0.044769950211048126, 0.006821433547884226, 0.04039204865694046, 0.015589354559779167, 0.058321647346019745, 0.018280204385519028, -0.03897767513990402, 0.026965200901031494, 0.014358358457684517, -0.003715748665854335, -0.04092039540410042, 0.0004998785443603992, 0.015075146220624447, 0.061646685004234314, 0.053800664842128754, -0.047023892402648926, -0.12230709195137024, 0.0011989324120804667, 0.005933172535151243, -0.044018760323524475, -0.05287845432758331, 0.029546134173870087, -0.12747830152511597, -0.046308886259794235, -0.05088307708501816, 0.0724286139011383, 0.016082217916846275, -0.06197497248649597, -0.021139029413461685, -0.022977041080594063, 0.011785594746470451, 0.01269192062318325, 0.0847277119755745, -0.044199101626873016, -0.01233445480465889, 0.06952567398548126, 0.020929737016558647, -0.0866890698671341, 0.056924108415842056, 0.09185205399990082, 0.07478746771812439, 0.028994891792535782, -0.04942568764090538, 0.06843837350606918, -0.11683668941259384, 0.026650618761777878, -0.03826408460736275, -0.009508694522082806, 0.03295190632343292, 0.0019722706638276577, 0.053525347262620926, -0.03989723324775696, 0.0170296560972929, 0.12145903706550598, -0.0536019392311573, 0.007179681211709976, 0.059593070298433304, 0.034280966967344284, -0.04508199170231819, 0.0767131969332695, -0.017386605963110924, 0.05219306796789169, 0.007638982031494379, -0.029283640906214714, 0.1282273679971695, -0.001228968845680356, -0.010250954888761044, 0.04805034399032593, 0.0029938346706330776, 0.05125248432159424, 0.06550712883472443, 0.04582279175519943, 0.10953328013420105, 0.031172651797533035, 0.009791319258511066, -0.03966952860355377, 0.049899011850357056, 0.01931663043797016, -0.0691487193107605, -0.0335269533097744, 0.0016089309938251972, -0.03196503967046738, -0.030003942549228668, 0.003966949414461851, 0.04519019275903702, 0.01255161315202713, 0.10297372937202454, -0.06999164074659348, -0.06627056747674942, 0.018733778968453407, -0.017358889803290367, -0.09577957540750504, 6.0997044712641605e-33, -0.004308491479605436, 0.07030635327100754, 0.010361927561461926, -0.0498051755130291, 0.06003493443131447, 0.02096427232027054, -0.03259272128343582, -0.028210658580064774, -0.12395665049552917, 0.02048497274518013, -0.06372695416212082, 0.09406360983848572, -0.03645307198166847, 0.039387550204992294, 0.061728376895189285, -0.048523079603910446, 0.017377067357301712, 0.052317067980766296, 0.04269462451338768, -0.03279012069106102, 0.01606971025466919, -0.11748611181974411, -0.002240609610453248, 0.03308268263936043, 0.01284480094909668, 0.02323123812675476, -0.0017841780791059136, -0.0008447500877082348, 0.12637563049793243, 0.0027400858234614134, 0.057212308049201965, 0.041853561997413635, 0.03877556696534157, 0.013697955757379532, -0.03935910016298294, -0.0064671640284359455, -0.03750816360116005, -0.055922895669937134, 0.019678937271237373, -0.08539514243602753, -0.06752454489469528, 0.039831168949604034, 0.0481608510017395, -0.040619976818561554, -0.03834064304828644, 0.008454779163002968, 0.01566833071410656, 0.003953071311116219, 0.05366497486829758, 0.006795994006097317, -0.05160108581185341, -0.0013445824151858687, -0.11301447451114655, -0.03119678422808647, -0.03225386142730713, -0.028623895719647408, 0.04807488992810249, 0.014592723920941353, 0.007233648560941219, -0.032220259308815, 0.043935440480709076, 0.052321940660476685, 0.043211400508880615, -0.03952383995056152, -0.10577017068862915, 0.011213874444365501, 0.010916372761130333, -0.006722684483975172, 0.056101202964782715, 0.058844517916440964, -0.031189249828457832, 0.08326596766710281, -0.004973516799509525, -0.03405950963497162, 0.010625571012496948, 0.017280321568250656, -0.042107198387384415, -0.033209651708602905, 0.03739575296640396, -0.022426536306738853, -0.041275881230831146, -0.08912639319896698, 0.04673387110233307, 0.03540399298071861, -0.049325987696647644, -0.004505055490881205, 0.049535639584064484, -0.03146655485033989, 0.008675715886056423, 0.007429766468703747, -0.0188288651406765, 0.02132422663271427, -0.03884344547986984, -0.03520924225449562, -0.045716434717178345, -4.6530371653606026e-33, -0.008717546239495277, 0.025271734222769737, 0.0377647839486599, 0.008596913889050484, -0.002646125154569745, 0.027407174929976463, 0.02441670373082161, -0.0008700636099092662, 0.039646878838539124, 0.10317835211753845, 0.02224571816623211, 0.035405512899160385, 0.04198499768972397, -0.04749012738466263, 0.005840343423187733, -0.05783458426594734, 0.03665892034769058, 0.005731410812586546, -0.052746448665857315, 0.04344151169061661, -0.06728556007146835, 0.09128386527299881, -0.08394689112901688, -0.00014842157543171197, 0.03161504119634628, 0.03476324304938316, 0.03795186057686806, -0.035602960735559464, -0.043263133615255356, 0.013406481593847275, -0.09167169779539108, -0.07652907073497772, -0.06856583058834076, -0.032365504652261734, 0.05704275891184807, 0.030431365594267845, 0.08531849831342697, 0.018279025331139565, -0.05730815231800079, -0.059210605919361115, 0.07510419934988022, 0.01840135268867016, -0.11269370466470718, -0.026145463809370995, -0.03233670815825462, 0.02831331267952919, -0.1369471698999405, 0.065041683614254, -0.059762679040431976, -0.05033404752612114, 0.040098920464515686, -0.023710589855909348, 0.06327930092811584, -0.04939637333154678, -0.0019583592656999826, 0.0656132623553276, 0.06154388561844826, -0.004522689152508974, -0.025053584948182106, -0.005968266166746616, -0.0706898421049118, -0.006203487515449524, -0.09817001968622208, 0.12429872900247574, 0.0009046196937561035, -0.0808979794383049, -0.03239106386899948, 0.03371002525091171, -0.08277799934148788, -0.045823633670806885, 0.00788846705108881, 0.015838298946619034, 0.041566092520952225, -0.06488664448261261, 0.037631869316101074, 0.053639862686395645, 0.0687435194849968, 0.03538183867931366, 0.0160836111754179, 0.030120359733700752, 0.005832833703607321, -0.035650745034217834, 0.07838039845228195, 0.03225982189178467, 0.019681967794895172, 0.042962901294231415, 0.025961268693208694, 0.011107107624411583, 0.052066463977098465, 0.06886188685894012, -0.0875590443611145, 0.016703244298696518, 0.014519644901156425, 0.034832343459129333, 0.08639965951442719, -5.5380329655463356e-08, -0.05886884033679962, 0.006630328483879566, -0.017900599166750908, 0.023485057055950165, 0.006211375817656517, -0.0307913888245821, 0.005584212485700846, 0.002015726175159216, 0.0005393621977418661, 0.16287203133106232, 0.05843200162053108, 0.001604389981366694, -0.07479645311832428, -0.015227662399411201, -0.05977220460772514, -0.006198438815772533, 0.01405392773449421, -0.04084531590342522, -0.021052338182926178, -0.05354679748415947, -0.014604510739445686, 0.04186709597706795, 0.039355721324682236, 0.05553317442536354, 0.010879416018724442, -0.05832255259156227, -0.050115134567022324, 0.012125853449106216, 0.0037461842875927687, 0.005407135002315044, -0.06756541877985, 0.02564276196062565, -0.01687709055840969, -0.03702187165617943, -0.010343991219997406, 0.06799592077732086, -0.035661596804857254, 0.005657527130097151, -0.017818275839090347, 0.08977688103914261, 0.02541789971292019, 0.0013005116488784552, -0.03667966276407242, -0.044318411499261856, 0.00042105879401788116, 0.029176240786910057, -0.03206590190529823, -0.058056049048900604, 0.10940047353506088, -0.07664749771356583, -0.011543335393071175, -0.09164727479219437, 0.054815247654914856, -0.06957872956991196, 0.016187261790037155, -0.02996496669948101, -0.027080046012997627, -0.05293510854244232, 0.01747002825140953, 0.0984066054224968, 0.12095245718955994, -0.09011374413967133, -0.05127714201807976, 0.05946357175707817]}, {"id": "69516a16c1b196630562bc72", "user_id": "CarlFristam", "title": "Heterogeneous Graph Auto-Encoder for CreditCard Fraud ...", "text": "[2410.08121] Heterogeneous Graph Auto-Encoder for CreditCard Fraud Detection\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2410.08121\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2410.08121**(cs)\n[Submitted on 10 Oct 2024]\n# Title:Heterogeneous Graph Auto-Encoder for CreditCard Fraud Detection\nAuthors:[Moirangthem Tiken Singh](https://arxiv.org/search/cs?searchtype=author&amp;query=Singh,+M+T),[Rabinder Kumar Prasad](https://arxiv.org/search/cs?searchtype=author&amp;query=Prasad,+R+K),[Gurumayum Robert Michael](https://arxiv.org/search/cs?searchtype=author&amp;query=Michael,+G+R),[N K Kaphungkui](https://arxiv.org/search/cs?searchtype=author&amp;query=Kaphungkui,+N+K),[N.Hemarjit Singh](https://arxiv.org/search/cs?searchtype=author&amp;query=Singh,+N)\nView a PDF of the paper titled Heterogeneous Graph Auto-Encoder for CreditCard Fraud Detection, by Moirangthem Tiken Singh and 4 other authors\n[View PDF](https://arxiv.org/pdf/2410.08121)[HTML (experimental)](https://arxiv.org/html/2410.08121v1)> > Abstract:\n> The digital revolution has significantly impacted financial transactions, leading to a notable increase in credit card usage. However, this convenience comes with a trade-off: a substantial rise in fraudulent activities. Traditional machine learning methods for fraud detection often struggle to capture the inherent interconnectedness within financial data. This paper proposes a novel approach for credit card fraud detection that leverages Graph Neural Networks (GNNs) with attention mechanisms applied to heterogeneous graph representations of financial data. Unlike homogeneous graphs, heterogeneous graphs capture intricate relationships between various entities in the financial ecosystem, such as cardholders, merchants, and transactions, providing a richer and more comprehensive data representation for fraud analysis. To address the inherent class imbalance in fraud data, where genuine transactions significantly outnumber fraudulent ones, the proposed approach integrates an autoencoder. This autoencoder, trained on genuine transactions, learns a latent representation and flags deviations during reconstruction as potential fraud. This research investigates two key questions: (1) How effectively can a GNN with an attention mechanism detect and prevent credit card fraud when applied to a heterogeneous graph? (2) How does the efficacy of the autoencoder with attention approach compare to traditional methods? The results are promising, demonstrating that the proposed model outperforms benchmark algorithms such as Graph Sage and FI-GRL, achieving a superior AUC-PR of 0.89 and an F1-score of 0.81. This research significantly advances fraud detection systems and the overall security of financial transactions by leveraging GNNs with attention mechanisms and addressing class imbalance through an autoencoder. Subjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI)|\nCite as:|[arXiv:2410.08121](https://arxiv.org/abs/2410.08121)[cs.LG]|\n|(or[arXiv:2410.08121v1](https://arxiv.org/abs/2410.08121v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2410.08121](https://doi.org/10.48550/arXiv.2410.08121)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\nJournalreference:|International Journal of Computers and Their Applications, vol. 32, no. 2, pp 123-138, 2025|\n## Submission history\nFrom: Tiken Moirangthem Mr [[view email](https://arxiv.org/show-email/f7fd3d2d/2410.08121)]\n**[v1]**Thu, 10 Oct 2024 17:05:27 UTC (1,025 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Heterogeneous Graph Auto-Encoder for CreditCard Fraud Detection, by Moirangthem Tiken Singh and 4 other authors\n* [View PDF](https://arxiv.org/pdf/2410.08121)\n* [HTML (experimental)](https://arxiv.org/html/2410.08121v1)\n* [TeX Source](https://arxiv.org/src/2410.08121)\n[![license icon](https://arxiv.org/icons/licenses/by-sa-4.0.png)view license](http://creativecommons.org/licenses/by-sa/4.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2410.08121&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2410.08121&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2024-10](https://arxiv.org/list/cs.LG/2024-10)\nChange to browse by:\n[cs](https://arxiv.org/abs/2410.08121?context=cs)\n[cs.AI](https://arxiv.org/abs/2410.08121?context=cs.AI)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2410.08121)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2410.08121)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2410.08121)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)]()[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)]()\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2410.08121)|[Disable MathJax](javascript:setMathjaxCookie())([What is MathJax?](https://info.arxiv.org/help/mathjax.html))", "embedding": [-0.12345349043607712, 0.076844722032547, -0.044659849256277084, -0.0549166165292263, 0.08581703901290894, -0.07024604082107544, -0.004111000336706638, -0.0522301010787487, 0.0017216242849826813, -0.051764171570539474, 0.01236233301460743, 0.013806221075356007, 0.06638295203447342, 0.045594628900289536, -0.09395940601825714, -0.013378296978771687, -0.07019224762916565, 0.01739247888326645, 0.023818857967853546, -0.01738123781979084, -0.03391650319099426, -0.051185961812734604, 0.015063694678246975, -0.016929613426327705, 0.05415252968668938, 0.018526088446378708, 0.011811125092208385, 0.014836043119430542, 0.01807831972837448, -0.12113812565803528, 0.05988693982362747, 0.04057248681783676, 0.1231832429766655, 0.013369445689022541, -0.025154050439596176, -0.016420403495430946, 0.020742470398545265, 0.04229568690061569, 0.02644321694970131, 0.005704422481358051, 0.05153282731771469, -0.025391817092895508, 0.00887826457619667, 0.010788284242153168, -0.03925693780183792, 0.020463498309254646, -0.038020048290491104, 0.047571390867233276, -0.02876886911690235, 0.020800933241844177, -0.016761071979999542, -0.03961043059825897, -0.020274406298995018, -0.029805012047290802, -0.021428991109132767, -0.08030129224061966, 0.027679268270730972, -0.09033416211605072, -0.015531050972640514, -0.04483902454376221, 0.10794635117053986, 0.023988667875528336, -0.03794240579009056, 0.04704941436648369, -0.0063858795911073685, 0.09089557826519012, 0.033190708607435226, 0.039360255002975464, -0.03677208721637726, 0.015932505950331688, 0.08674173057079315, -0.03463900089263916, -0.10730928927659988, 0.018622707575559616, 0.0711875632405281, 0.12744253873825073, -0.025986619293689728, -0.007192031014710665, -0.0026800893247127533, -0.08789754658937454, -3.714266495080665e-05, -0.03044513426721096, 0.06832074373960495, 0.04160671681165695, 0.05514270439743996, 0.07204043865203857, -0.10248539596796036, 0.027847260236740112, 0.009495499543845654, -0.07221916317939758, -0.03610974922776222, 0.04257441684603691, 0.087966687977314, -0.04219551756978035, 0.0058314865455031395, -0.013877799734473228, -0.010888819582760334, -0.02370803989470005, -0.006158442702144384, 0.07960433512926102, -0.0017328588292002678, 0.012210309505462646, 0.002070995979011059, -0.047275617718696594, 0.09793853759765625, 0.007508409675210714, 0.10259899497032166, 0.07769596576690674, 0.058812934905290604, -0.0034155568573623896, 0.014641164802014828, 0.08829519152641296, 0.017040012404322624, -0.05412538722157478, -0.04223320260643959, 0.04431307688355446, 0.01336317602545023, -0.002603069180622697, 0.03980259597301483, 0.04508299008011818, -0.005438894033432007, 0.02424890361726284, -0.11745073646306992, -0.05104083940386772, 0.004963368643075228, -0.0003510899841785431, -0.03950660675764084, 1.1302901645484395e-33, 0.014271539635956287, 0.10369133949279785, 0.01878870278596878, -0.04660026729106903, 0.0021328723523765802, 0.012938836589455605, -0.0785648375749588, -0.07471703737974167, -0.06446441262960434, 0.04062838852405548, -0.09841728955507278, 0.08160939812660217, 0.03453311696648598, 0.13244034349918365, -0.011291944421827793, -0.060677897185087204, -0.048580534756183624, 0.0016624253476038575, -0.0029838772024959326, -0.03358710929751396, 0.03055667132139206, -0.009539001621305943, -0.011116583831608295, 0.0208128709346056, 0.013228418305516243, 0.04055330902338028, -0.01173420436680317, 0.006401317659765482, 0.1210455596446991, -0.004376931581646204, -0.001966882962733507, 0.02797413244843483, 0.058482829481363297, 0.029172126203775406, -0.016881458461284637, 0.003946508746594191, -0.021515849977731705, -0.02228902466595173, -0.016253100708127022, -0.028931114822626114, 0.04410891607403755, 0.0374455563724041, 0.007506776601076126, -0.06883423775434494, -0.01956888660788536, -0.02067219652235508, 0.028669090941548347, -0.08048418164253235, 0.03385418280959129, 0.018422402441501617, -0.028036562725901604, 0.005659975111484528, -0.07175596058368683, -0.03379452973604202, -0.06522726267576218, -0.03971860557794571, 0.030093766748905182, 0.031133757904171944, 0.018118808045983315, -0.030316779389977455, 0.0036178252194076777, -0.015492442063987255, -0.029673147946596146, -0.055927831679582596, -0.07040313631296158, 0.002250674879178405, 0.019689463078975677, -0.07370399683713913, -0.07521062344312668, 0.05558212473988533, -0.02653145231306553, 0.10359126329421997, -0.001923335948958993, -0.041857048869132996, -0.05014006420969963, -0.021421601995825768, -0.0743495374917984, -0.0038523462135344744, -0.07457547634840012, 0.005576740950345993, -0.13804689049720764, -0.08597245812416077, 0.04189874231815338, -0.02229348011314869, -0.04791852459311485, 0.003907914739102125, 0.08601284772157669, -0.05548788607120514, -0.04115400090813637, -0.01878790743649006, 0.038443297147750854, -0.0408097505569458, 0.009547360241413116, 0.0010400805622339249, 0.05068717896938324, -2.0863840049195165e-33, -0.0009667131234891713, 0.04294179379940033, 0.09828805178403854, 0.040113549679517746, -0.007200023625046015, -0.03749823197722435, 0.048390019685029984, 0.11448779702186584, 0.007557734381407499, 0.009325777180492878, 0.024039682000875473, 0.02456183172762394, 0.047257859259843826, 0.00985153578221798, 0.043547749519348145, -0.029616577550768852, 0.01250778790563345, 0.07842295616865158, -0.03966185078024864, -0.0078536756336689, 0.039353616535663605, 0.0996941551566124, -0.07752817124128342, 0.0390414334833622, 0.006918856408447027, 0.10381825268268585, 0.0312928631901741, 0.001790262060239911, 0.0005961383576504886, -0.008501188829541206, -0.08059096336364746, -0.008351951837539673, -0.0686570554971695, 0.0014242882607504725, 0.00044405224616639316, -0.010622984729707241, 0.07605679333209991, 0.10734105855226517, -0.04515232518315315, -0.02900157868862152, 0.008451691828668118, 0.029390716925263405, -0.08682804554700851, 0.017084786668419838, -0.023294953629374504, -0.02822449803352356, -0.045818958431482315, 0.011352135799825191, -0.0325227715075016, 0.00042580999433994293, -0.06253136694431305, 0.01785842888057232, 0.016437871381640434, 0.08994674682617188, -0.019705045968294144, -0.0034625299740582705, 0.06418363749980927, 0.0663648471236229, -0.005939807742834091, 0.042701706290245056, -0.1125660389661789, -0.0033992906101047993, -0.051650214940309525, 0.027299467474222183, 0.02407272905111313, -0.06346381455659866, -0.03563221916556358, -0.015617086552083492, -0.05183975398540497, 0.021749868988990784, 0.07973189651966095, 0.03709917142987251, -0.039191607385873795, 0.004781495779752731, 0.02695436216890812, -0.043103136122226715, 0.026636524125933647, 0.02782716415822506, -0.0640975683927536, -0.04120580852031708, 0.012936458922922611, -0.02032293938100338, 0.02846168540418148, 0.15038229525089264, 0.022646861150860786, -0.0008652741671539843, 0.00545921316370368, -0.020238954573869705, 0.019373537972569466, 0.004441678989678621, -0.07449962943792343, 0.037371132522821426, 0.010651509277522564, 0.03398376703262329, 0.053389862179756165, -5.165285443808898e-08, -0.06251770257949829, 0.03028436191380024, -0.08460882306098938, -0.027822254225611687, -0.009934652596712112, 0.013461850583553314, -0.026792116463184357, -0.0036812445614486933, -0.03763493895530701, 0.04810149595141411, 0.08335556834936142, -0.009657287038862705, -0.0928751677274704, -0.09546097368001938, -0.023859940469264984, -0.06773530691862106, 0.003719630651175976, 0.018543757498264313, -0.016219044104218483, 0.0037123614456504583, -0.03622151538729668, 0.03266698494553566, -0.012530502863228321, -0.04823467135429382, -0.0586727000772953, -0.03790298104286194, 0.009950877167284489, 0.0329558402299881, 0.03030579164624214, -0.019289972260594368, -0.10317977517843246, 0.07875474542379379, 0.06122040003538132, -0.045784078538417816, -0.024437034502625465, 0.08009681850671768, -0.006526738405227661, -0.02104273810982704, -0.05140961706638336, 0.008833576925098896, 0.052336372435092926, -0.04327057674527168, -0.10104697942733765, -0.07800931483507156, 0.016024792566895485, -0.026363354176282883, 0.027356773614883423, -0.03993254527449608, 0.0937560573220253, -0.04274146258831024, -0.00048457400407642126, -0.10142070800065994, 0.016566647216677666, 0.00986382458359003, 0.034987274557352066, -0.07842348515987396, -0.04387993365526199, 0.014439927414059639, 0.13623657822608948, 0.061420828104019165, 0.15910473465919495, -0.02394862286746502, -0.01818545162677765, 0.0032572641503065825]}, {"id": "69516b44c1b196630562bc73", "user_id": "CarlFristam", "title": "Heterogeneous Graph Masked Autoencoders", "text": "Heterogeneous Graph Masked Autoencoders\n| Proceedings of the AAAI Conference on Artificial Intelligence\nOpen Menu\n[Proceedings of the AAAI Conference on Artificial Intelligence](< https://ojs.aaai.org/index.php/AAAI/index\n>)\n# Heterogeneous Graph Masked Autoencoders\n## Authors\n* Yijun TianDepartment of Computer Science and Engineering, University of Notre Dame\nLucy Family Institute for Data and Society, University of Notre Dame\n* Kaiwen DongDepartment of Computer Science and Engineering, University of Notre Dame\nLucy Family Institute for Data and Society, University of Notre Dame\n* Chunhui ZhangDepartment of Computer Science, Brandeis University\n* Chuxu ZhangDepartment of Computer Science, Brandeis University\n* Nitesh V. ChawlaDepartment of Computer Science and Engineering, University of Notre Dame\nLucy Family Institute for Data and Society, University of Notre Dame\n## DOI:\n[https://doi.org/10.1609/aaai.v37i8.26192](https://doi.org/10.1609/aaai.v37i8.26192)\n## Keywords:\nML: Graph-based Machine Learning, DMKM: Graph Mining, Social Network Analysis &amp; Community Mining, ML: Unsupervised &amp; Self-Supervised Learning, ML: Deep Generative Models &amp; Autoencoders\n## Abstract\nGenerative self-supervised learning (SSL), especially masked autoencoders, has become one of the most exciting learning paradigms and has shown great potential in handling graph data. However, real-world graphs are always heterogeneous, which poses three critical challenges that existing methods ignore: 1) how to capture complex graph structure? 2) how to incorporate various node attributes? and 3) how to encode different node positions? In light of this, we study the problem of generative SSL on heterogeneous graphs and propose HGMAE, a novel heterogeneous graph masked autoencoder model to address these challenges. HGMAE captures comprehensive graph information via two innovative masking techniques and three unique training strategies. In particular, we first develop metapath masking and adaptive attribute masking with dynamic mask rate to enable effective and stable learning on heterogeneous graphs. We then design several training strategies including metapath-based edge reconstruction to adopt complex structural information, target attribute restoration to incorporate various node attributes, and positional feature prediction to encode node positional information. Extensive experiments demonstrate that HGMAE outperforms both contrastive and generative state-of-the-art baselines on several tasks across multiple datasets. Codes are available at https://github.com/meettyj/HGMAE.\n[![AAAI-23 Proceedings Cover](https://ojs.aaai.org/public/journals/2/aaai23cover.jpg)](https://ojs.aaai.org/index.php/AAAI/issue/view/555)\n## Downloads\n* [PDF](https://ojs.aaai.org/index.php/AAAI/article/view/26192/25964)\n## Published\n2023-06-26\n## How to Cite\nTian, Y., Dong, K., Zhang, C., Zhang, C., &#38; Chawla, N. V. (2023). Heterogeneous Graph Masked Autoencoders.*Proceedings of the AAAI Conference on Artificial Intelligence*,*37*(8), 9997-10005. https://doi.org/10.1609/aaai.v37i8.26192\nMore Citation Formats\n* [ACM](https://ojs.aaai.org/index.php/AAAI/citationstylelanguage/get/acm-sig-proceedings?submissionId=26192&amp;publicationId=24472)\n* [ACS](https://ojs.aaai.org/index.php/AAAI/citationstylelanguage/get/acs-nano?submissionId=26192&amp;publicationId=24472)\n* [APA](https://ojs.aaai.org/index.php/AAAI/citationstylelanguage/get/apa?submissionId=26192&amp;publicationId=24472)\n* [ABNT](https://ojs.aaai.org/index.php/AAAI/citationstylelanguage/get/associacao-brasileira-de-normas-tecnicas?submissionId=26192&amp;publicationId=24472)\n* [Chicago](https://ojs.aaai.org/index.php/AAAI/citationstylelanguage/get/chicago-author-date?submissionId=26192&amp;publicationId=24472)\n* [Harvard](https://ojs.aaai.org/index.php/AAAI/citationstylelanguage/get/harvard-cite-them-right?submissionId=26192&amp;publicationId=24472)\n* [IEEE](https://ojs.aaai.org/index.php/AAAI/citationstylelanguage/get/ieee?submissionId=26192&amp;publicationId=24472)\n* [MLA](https://ojs.aaai.org/index.php/AAAI/citationstylelanguage/get/modern-language-association?submissionId=26192&amp;publicationId=24472)\n* [Turabian](https://ojs.aaai.org/index.php/AAAI/citationstylelanguage/get/turabian-fullnote-bibliography?submissionId=26192&amp;publicationId=24472)\n* [Vancouver](https://ojs.aaai.org/index.php/AAAI/citationstylelanguage/get/vancouver?submissionId=26192&amp;publicationId=24472)\nDownload Citation\n* [Endnote/Zotero/Mendeley (RIS)](https://ojs.aaai.org/index.php/AAAI/citationstylelanguage/download/ris?submissionId=26192&amp;publicationId=24472)\n* [BibTeX](https://ojs.aaai.org/index.php/AAAI/citationstylelanguage/download/bibtex?submissionId=26192&amp;publicationId=24472)\n## Issue\n[Vol. 37 No. 8: AAAI-23 Technical Tracks 8](https://ojs.aaai.org/index.php/AAAI/issue/view/555)\n## Section\nAAAI Technical Track on Machine Learning III\n## Information\n* [For Readers](https://ojs.aaai.org/index.php/AAAI/information/readers)\n* [For Authors](https://ojs.aaai.org/index.php/AAAI/information/authors)\n* [For Librarians](https://ojs.aaai.org/index.php/AAAI/information/librarians)\n* [![](https://ojs.aaai.org/plugins/blocks/hostedBy/icons/pkpps.svg)](https://pkpservices.sfu.ca/)\nPart of the\n[PKP Publishing Services Network](https://pkpservices.sfu.ca/)\nCopyright \u00a92024, Association for the Advancement of Artificial Intelligence\n[![More information about the publishing system, Platform and Workflow by OJS/PKP.](https://ojs.aaai.org/templates/images/ojs_brand.png)](https://ojs.aaai.org/index.php/AAAI/about/aboutThisPublishingSystem)", "embedding": [-0.052386146038770676, -0.003279253141954541, 0.029453998431563377, 0.016761306673288345, 0.052639808505773544, -0.07778394222259521, -0.05987650156021118, -0.12355635315179825, -0.027010947465896606, -0.05000802129507065, -0.011141575872898102, -0.041907332837581635, 0.07577888667583466, 0.011963430792093277, -0.03970339521765709, 0.03113642893731594, -0.041446883231401443, -0.01959466189146042, -0.03599429130554199, -0.15033702552318573, 0.04815235733985901, -0.004671681206673384, -0.07671092450618744, -0.06171729043126106, 0.10708409547805786, -0.00019595629419200122, -0.01551076490432024, -0.018082184717059135, 0.06018758937716484, -0.01937924511730671, 0.06987207382917404, -0.04987921565771103, 0.09117214381694794, 0.11707182228565216, -0.057033807039260864, -0.05412405729293823, -0.07825946807861328, 0.051574673503637314, 0.042041581124067307, 0.058553051203489304, -0.029080256819725037, 0.02374490723013878, 0.0012451234506443143, 0.007877044379711151, 0.021148407831788063, 0.04288989678025246, -0.087822325527668, -0.010705732740461826, -0.057240672409534454, -0.03449945151805878, -0.05491701886057854, 0.0036004746798425913, -0.029360180720686913, 0.0048543717712163925, -0.003803491359576583, -0.02780730463564396, 0.009775016456842422, -0.08399184048175812, 0.028623657301068306, 0.06436581164598465, 0.034376636147499084, 0.018706992268562317, 0.013505183160305023, -0.030116824433207512, 0.0037749335169792175, 0.05506839603185654, -0.05321212857961655, 0.0010083429515361786, -0.019549908116459846, 0.06639455258846283, -0.0075162616558372974, 0.06068858876824379, -0.10259271413087845, -0.005860574077814817, 0.06448235362768173, 0.06951866298913956, -0.08204583823680878, -0.02971719764173031, 0.018189020454883575, -0.07634729146957397, 0.005487947724759579, -0.06114551052451134, 0.024945106357336044, 0.06665268540382385, 0.03724822402000427, 0.006797954440116882, -0.009615162387490273, 0.00924044568091631, -0.0012707494897767901, 0.0037760392297059298, -0.10756909847259521, -0.008224021643400192, 0.024078067392110825, 0.03945547342300415, 0.029627205803990364, 0.016553135588765144, 0.07408617436885834, -0.010616138577461243, 0.03239559382200241, 0.06918370723724365, -0.05524226650595665, -0.004247920587658882, -0.0402391292154789, -0.024974605068564415, 0.02007651887834072, 0.039022017270326614, 0.0824393779039383, 0.05234922096133232, 0.03680740296840668, -0.07376499474048615, -0.010988777503371239, 0.11187168955802917, -0.05667199194431305, -0.027587125077843666, -0.03471813350915909, -0.060298334807157516, 0.029661471024155617, -0.01019193697720766, 0.04386495053768158, 0.08286771923303604, -0.0025774005334824324, -0.042760323733091354, -0.05490271747112274, 0.03503070026636124, 0.033295951783657074, -0.05394311621785164, -0.01835193857550621, 8.336720546730868e-33, -0.004685921128839254, 0.08690070360898972, -0.036910463124513626, -0.07611419260501862, 0.026559652760624886, 0.01147188525646925, -0.09282833337783813, -0.05081897974014282, -0.006573059130460024, 0.07492761313915253, -0.13375277817249298, 0.022535579279065132, -0.05284469202160835, 0.14114578068256378, 0.06251401454210281, -0.00957214180380106, 0.019317256286740303, 0.06455481797456741, -0.012585165910422802, -0.10335130989551544, 0.07832924276590347, 0.005012913141399622, -0.003980546724051237, 0.018862737342715263, 0.03627179190516472, 0.015471433289349079, -0.01593378745019436, -0.04743832349777222, 0.0616222508251667, 0.020473720505833626, -0.07046440988779068, 0.007369282189756632, 0.058033425360918045, 0.009759077802300453, 0.03072868287563324, -0.0028238166123628616, 0.06982361525297165, -0.01817850023508072, 0.03908366337418556, -0.008944325149059296, 0.05533679202198982, 0.011044208891689777, 0.02270638197660446, -0.06947097182273865, -0.0339907631278038, 0.003519923659041524, -0.03502875939011574, 0.013700023293495178, -0.0773499459028244, -0.038917578756809235, 0.007458149455487728, 0.006286507472395897, -0.08945146948099136, -0.02508130483329296, 0.0017061153193935752, -0.05803744122385979, 0.07745802402496338, 0.0474860817193985, 0.05404477193951607, 0.05800330638885498, -0.041744161397218704, -0.008875039406120777, 0.003983504604548216, 0.0017408807761967182, 0.017106523737311363, 0.024700064212083817, 0.034341245889663696, -0.06450747698545456, 0.007885867729783058, 0.04550308734178543, 0.004842313472181559, 0.06334111839532852, -0.019690342247486115, -0.0471569299697876, 0.005161055363714695, -0.028100453317165375, -0.027355432510375977, -0.07803735882043839, -0.05872015282511711, -0.015788447111845016, -0.07151005417108536, -0.06264962255954742, -0.02860121615231037, -0.06660859286785126, -0.060199327766895294, -0.05259612202644348, 0.06711575388908386, 0.007639471907168627, -0.07262320071458817, -0.027086947113275528, -0.00419959519058466, -0.070228211581707, 0.03878466784954071, -0.011644272133708, 0.023181946948170662, -9.656281281138027e-33, -0.03920789808034897, 0.13751724362373352, 0.06155981495976448, 0.09292858839035034, 0.03467041999101639, -0.05011393874883652, 0.012279585003852844, 0.013392713852226734, -0.005386390723288059, 0.02696833945810795, -0.0634130910038948, -0.0429261289536953, 0.025073913857340813, -0.016008898615837097, 0.010950553230941296, -0.014668450690805912, -0.01519304234534502, 0.06106143817305565, -0.0383281484246254, 0.04812925308942795, -0.02975495159626007, 0.07028473168611526, -0.08221634477376938, 0.03949068486690521, 0.10669935494661331, 0.07483244687318802, -0.02020735666155815, 0.0721765086054802, 0.0068459962494671345, 0.02632197178900242, -0.07943152636289597, 0.047457288950681686, -0.04838945344090462, -0.04257803410291672, 0.025785835459828377, 0.02866171859204769, 0.03141958639025688, 0.06709305942058563, -0.039542943239212036, 0.023328706622123718, -0.006668240297585726, -0.004417821299284697, -0.12147250026464462, 0.04462730512022972, 0.02879922278225422, 0.01695001684129238, -0.08293034881353378, 0.10835117101669312, 0.010025394149124622, -0.05465692654252052, -0.04027363657951355, 0.07611091434955597, 0.003620039438828826, -0.004791745450347662, 0.0017423293320462108, -0.00013396514987107366, 0.027058469131588936, 0.015952490270137787, -0.006926017813384533, 0.005725338123738766, -0.10238635540008545, -0.1300366073846817, 0.029413321986794472, 0.007986719720065594, 0.01208146195858717, -0.07294652611017227, -0.0293890368193388, -0.0339517816901207, -0.0371142253279686, 0.01539942342787981, 0.11011205613613129, 0.0066151125356554985, -0.01997482031583786, 0.015927854925394058, 0.04412683844566345, -0.028211340308189392, 0.013097777962684631, 0.046817924827337265, -0.0030166858341544867, 0.06386373192071915, -0.04377533495426178, -0.0002636434801388532, 0.03127027675509453, 0.11799639463424683, 0.01794404722750187, 0.02892589569091797, -0.042613156139850616, -0.024867717176675797, 0.01979157328605652, 0.038733839988708496, -0.021286457777023315, 0.018066290766000748, -0.04887661710381508, -0.011901634745299816, -0.020227156579494476, -5.2868340816303316e-08, -0.08210834860801697, -0.010265135206282139, -0.0359785370528698, -0.021573442965745926, 0.03586198389530182, -0.024104926735162735, 0.013186144642531872, 0.04512462764978409, -0.002725005615502596, -0.02399596758186817, 0.13081565499305725, -0.058763980865478516, -0.001323965727351606, -0.04186016321182251, -0.013446442782878876, 0.0508061982691288, -0.009162266738712788, -0.03423326089978218, 0.022177930921316147, 0.029164394363760948, -0.08528780937194824, 0.03791692852973938, -0.06455711275339127, -0.0012889951467514038, -0.020700603723526, -0.10567474365234375, -0.044928938150405884, 0.049417950212955475, 0.0025996342301368713, 0.147925466299057, -0.027247117832303047, 0.06028233468532562, 0.07964803278446198, -0.00013576734636444598, 0.03377813845872879, 0.08119581639766693, 0.01702185906469822, -0.047495778650045395, -0.09125103056430817, -0.028244897723197937, 0.028095873072743416, -0.0075408415868878365, -0.09679259359836578, -0.04062127694487572, 0.04404044523835182, 0.014974545687437057, 0.08667013794183731, -0.07191388309001923, 0.013086771592497826, -0.042845360934734344, 0.026816748082637787, -0.07884055376052856, -0.06811230629682541, 0.0051798210479319096, 0.03956775367259979, -0.027003729715943336, -0.024927835911512375, -0.06755097210407257, 0.09478067606687546, 0.03280266746878624, -0.008993438445031643, 0.02238287217915058, -0.030255118384957314, -0.059363145381212234]}]